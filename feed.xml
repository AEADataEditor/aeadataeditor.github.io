<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://aeadataeditor.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://aeadataeditor.github.io/" rel="alternate" type="text/html" /><updated>2024-04-09T15:46:49-04:00</updated><id>https://aeadataeditor.github.io/feed.xml</id><title type="html">Office of the AEA Data Editor</title><subtitle>(current: Lars Vilhuber)</subtitle><author><name>AEA Data Editor</name></author><entry><title type="html">AEJ Best Papers 2024 and replication packages</title><link href="https://aeadataeditor.github.io/posts/2024-04-10-aej-best-papers-2024" rel="alternate" type="text/html" title="AEJ Best Papers 2024 and replication packages" /><published>2024-04-10T00:00:00-04:00</published><updated>2024-04-10T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/aej-best-papers-2024</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2024-04-10-aej-best-papers-2024"><![CDATA[<p>The annual <strong>American Economic Journal (AEJ) Best Paper Awards</strong> highlight the best paper published in each of the American Economic Journals: Applied Economics, Economic Policy, Macroeconomics, and Microeconomics over the last three years. Nominations are provided by AEA members, and winners are selected by the journals’ Boards of Editors. More information, including links to the papers, at  <a href="https://www.aeaweb.org/about-aea/honors-awards/aej-best-papers">https://www.aeaweb.org/about-aea/honors-awards/aej-best-papers</a>.</p>

<p>The decision process is on the overall scientific merit. On this page, I list the replication packages for each of these.</p>

<!-- more -->

<p><!-- manually constructing table -->
  <!-- "Journal","Title","Authors","DOI","Date","Package DOI","Requires confidential or proprietary data","Data Editor ran","Notes" --></p>

<h2 id="aej-applied-economics">AEJ Applied Economics</h2>

<blockquote>
  <p>Manasi Deshpande, Tal Gross, and Yalun Su. “Disability and Distress: The Effect of Disability Programs on Financial Outcomes” <em>AEJ Applied Economics</em> (April 2021). <a href="https://doi.org/10.1257/app.20190709">10.1257/app.20190709</a></p>
</blockquote>

<ul>
  <li>Replication package: <a href="https://doi.org/10.3886/E118462V1">10.3886/E118462V1</a></li>
  <li>Does the replication package require confidential or proprietary data? <strong>Yes</strong></li>
  <li>Did the Data Editor run the package? <strong>Partially</strong></li>
  <li>Additional notes:    <em>Requires ZTRAX data, which are no longer accessible.</em></li>
</ul>

<h2 id="aej-economic-policy">AEJ Economic Policy</h2>

<blockquote>
  <p>Barbara Biasi. “The Labor Market for Teachers under Different Pay Schemes” <em>AEJ Economic Policy</em> (August 2021). <a href="https://doi.org/10.1257/pol.20200295">10.1257/pol.20200295</a></p>
</blockquote>

<ul>
  <li>Replication package: <a href="https://doi.org/10.3886/E119844V1">10.3886/E119844V1</a></li>
  <li>Does the replication package require confidential or proprietary data? <strong>Yes</strong></li>
  <li>Did the Data Editor run the package? <strong>No</strong></li>
  <li>Additional notes:    <em>Uses restricted data from the Wisconsin Department of Public Instruction and New York City Department of Education.</em></li>
</ul>

<h2 id="aej-macroeconomics">AEJ Macroeconomics</h2>

<blockquote>
  <p>Silvia Miranda-Agrippino, and Giovanni Ricco. “The Transmission of Monetary Policy Shocks” <em>AEJ Macroeconomics</em> (July 2021). <a href="https://doi.org/10.1257/mac.20180124">10.1257/mac.20180124</a></p>
</blockquote>

<ul>
  <li>Replication package: <a href="https://doi.org/10.3886/E116841V1">10.3886/E116841V1</a></li>
  <li>Does the replication package require confidential or proprietary data? <strong>Yes</strong></li>
  <li>Did the Data Editor run the package? <strong>Yes</strong></li>
  <li>Additional notes:    <em>Only a small fraction of the data are proprietary, but can be accessed from the typical business school library. The remaining data are included.</em></li>
</ul>

<h2 id="aej-microeconomics">AEJ Microeconomics</h2>

<blockquote>
  <p>Board and Meyer-ter-Vehn. “A Reputational Theory of Firm Dynamics” <em>AEJ Microeconomics</em> (May 2022). <a href="https://doi.org/10.1257/mic.20190376">10.1257/mic.20190376</a></p>
</blockquote>

<ul>
  <li>Replication package: <a href="https://doi.org/10.3886/E118970V1">10.3886/E118970V1</a></li>
  <li>Does the replication package require confidential or proprietary data? <strong>No</strong></li>
  <li>Did the Data Editor run the package? <strong>Yes</strong></li>
  <li>Additional notes:    <em>Only uses (creates) simulated data.</em></li>
</ul>]]></content><author><name>AEA Data Editor</name></author><category term="best papers" /><category term="replication packages" /><summary type="html"><![CDATA[The annual American Economic Journal (AEJ) Best Paper Awards highlight the best paper published in each of the American Economic Journals: Applied Economics, Economic Policy, Macroeconomics, and Microeconomics over the last three years. Nominations are provided by AEA members, and winners are selected by the journals’ Boards of Editors. More information, including links to the papers, at https://www.aeaweb.org/about-aea/honors-awards/aej-best-papers. The decision process is on the overall scientific merit. On this page, I list the replication packages for each of these.]]></summary></entry><entry><title type="html">Examples of replication packages for research conducted in FSRDCs</title><link href="https://aeadataeditor.github.io/posts/2024-04-09-census-packages" rel="alternate" type="text/html" title="Examples of replication packages for research conducted in FSRDCs" /><published>2024-04-09T00:00:00-04:00</published><updated>2024-04-09T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/census-packages</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2024-04-09-census-packages"><![CDATA[<p>I have been asked a few times about guidance for replication packages that use confidential data in research data centers, e.g., the  Federal Statistical Research Data Centers (FSRDCs) and others. Here are some examples and guidance.</p>

<!-- more -->

<h2 id="the-problem">The problem</h2>

<p>The data, and sometimes (only sometimes) pieces of code, are confidential. If this is something you encounter, read on.</p>

<h2 id="this-is-not-new">This is not new</h2>

<p>See my <a href="https://aeadataeditor.github.io/posts/2022-04-13-coding-confidential">earlier post almost exactly two years ago</a> and this <a href="https://larsvilhuber.github.io/reproducibility-confidential-fsrdc/">2022 tutorial</a> that I developed from that.</p>

<h2 id="general-guidance">General Guidance</h2>

<ul>
  <li>https://social-science-data-editors.github.io/guidance/DCAS_Restricted_data.html#us-census-bureau-and-fsrdc</li>
  <li>https://social-science-data-editors.github.io/guidance/Requested_information_hosting.html#self-generated-repositories</li>
</ul>

<h2 id="examples">Examples!</h2>

<p>Two excellent examples:</p>

<h3 id="example-1-berger-herkenhoof-and-mongey-2022">Example 1: Berger, Herkenhoof, and Mongey (2022)</h3>

<blockquote>
  <p>Berger, David, Herkenhoff, Kyle, and Mongey, Simon. Data and Code for: Labor Market Power. Nashville, TN: American Economic Association [publisher], 2022. Ann Arbor, MI: Inter-university Consortium for Political and Social Research [distributor], 2022-12-07. <a href="https://doi.org/10.3886/E154241V2">https://doi.org/10.3886/E154241V2</a></p>
</blockquote>

<p>Not only code, but faces the problem that IRS data cannot have variables revealed. Workarounds galore.</p>

<h3 id="example-2-yeh-macoluso-and-hershbein-2022">Example 2: Yeh, Macoluso, and Hershbein (2022)</h3>

<blockquote>
  <p>Yeh, Chen, Macaluso, Claudia, and Hershbein, Brad. Code for: “Monopsony in the U.S. Labor Market.” Nashville, TN: American Economic Association [publisher], 2022. Ann Arbor, MI: Inter-university Consortium for Political and Social Research [distributor], 2022-11-28. https://doi.org/10.3886/E162581V1</p>
</blockquote>

<h3 id="example-3-fort-2017">Example 3: Fort (2017)</h3>

<p>This replication package is a bit older, but is an excellent example that I have repurposed as guidance for others:</p>

<blockquote>
  <p>Teresa C. Fort, Technology and Production Fragmentation: Domestic versus Foreign Sourcing, The Review of Economic Studies, Volume 84, Issue 2, April 2017, Pages 650–687, <a href="https://doi.org/10.1093/restud/rdw057">https://doi.org/10.1093/restud/rdw057</a></p>
</blockquote>

<p>and the <a href="https://social-science-data-editors.github.io/guidance/copies/Fort2016-Readme.pdf">copy of the README</a>.</p>

<p>Note that this package was created before the installation of the current generation of data editors, so relied on none of that (official) expertise!</p>

<p>Many more out there.</p>

<h2 id="ask-the-research-data-center">Ask the research data center</h2>

<p>The US Census Bureau has procedures in place to review code (it’s actually part of the release system), as do many other systems. Some parts of the code will need to be redacted, but you can get very functional code released (see the <a href="https://larsvilhuber.github.io/reproducibility-confidential-fsrdc/">2022 tutorial</a> on how to set this up from the start).</p>

<h2 id="but-dont-take-no-for-an-answer">But: Don’t take “No” for an answer!</h2>

<p>There are sometimes some old practices in place in restricted-access environments that do not have 100s of researchers flowing through (for instance, smaller countries, places with newer centers, etc.). Sometimes, you need to push back. You can rely on the Data Editors - me, others - to help you do that. I have successfully educated data custodians, who justifiably fear releasing too much confidential data, on what can be done reliably and robustly, at least with code.</p>

<h2 id="dotting-the-is-and-crossing-the-ts">Dotting the i’s and crossing the t’s</h2>

<p>We usually require that an <strong>internal</strong> archive be created at the institution holding the data, so that regardless of how much or how little is released, internally, a fully reproducible archive exists, accessible for those with permission to access. The permissions necessary , and permission granted in the replication package so that others, with appropriate access, can access those files. See the first example above for an excellent example of that, and <a href="https://social-science-data-editors.github.io/guidance/Requested_information_hosting.html#self-generated-repositories">this guidance</a> on how to do so in the absence of a formal internal archive.</p>]]></content><author><name>AEA Data Editor</name></author><category term="confidential data" /><category term="complex projects" /><summary type="html"><![CDATA[I have been asked a few times about guidance for replication packages that use confidential data in research data centers, e.g., the Federal Statistical Research Data Centers (FSRDCs) and others. Here are some examples and guidance.]]></summary></entry><entry><title type="html">NDAs, NDAs, and NDAs: How to describe access to data that cannot be published</title><link href="https://aeadataeditor.github.io/posts/2024-03-15-nda-redux" rel="alternate" type="text/html" title="NDAs, NDAs, and NDAs: How to describe access to data that cannot be published" /><published>2024-03-15T00:00:00-04:00</published><updated>2024-03-15T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/nda-redux</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2024-03-15-nda-redux"><![CDATA[<p>I was recently forwarded a question from a data librarian discussion list, and invited to respond to the question of “example language” for a data access description when data were obtained via a non-disclosure agreement (NDA):</p>

<blockquote>
  <p>[…] the data are from a commercial company under a non-disclosure agreement […] asked to include “data sharing plans (for all data, documentation, and code used in analysis)”. […] Can you think of any example language that the researcher could borrow from to include in the data sharing plan?</p>
</blockquote>

<p>(paraphrased)</p>

<!-- more -->

<p>The use of some sort of data access restriction is quite common in economics. We have a few examples listed <a href="https://social-science-data-editors.github.io/guidance/Requested_information_dcas.html">here</a>. 
None of those directly address when an NDA is required, but the generic “<a href="https://social-science-data-editors.github.io/guidance/Requested_information_dcas.html#example-for-confidential-data">confidential data</a>” example is straightforward to adapt.</p>

<blockquote>
  <p>The data for this project are confidential, but may be obtained with Data Use Agreements with the Massachusetts Department of Elementary and Secondary Education (DESE). Researchers interested in access to the data may contact [NAME] at [EMAIL], also see www.doe.mass.edu/research/contact.html. It can take some months to negotiate data use agreements and gain access to the data. The author will assist with any reasonable replication attempts for two years following publication.</p>
</blockquote>

<p>As general guidance, journal (data) editors seek the following information:</p>

<ul>
  <li>how did the author access the data? (describe how the initial contact was made, what type of agreements, such as NDAs, were signed, and what they restrict and why)</li>
  <li>how can others​ access the data? (“Contact the vice president of academic interaction, and request “data on gooble-dee-gooks” from 2002-2022.”) Importantly, the author should address whether the exact data can be obtained by others, or if this was a pull from a dynamic database, and while generically the same data might be available in a few years’ time, the exact data will never be obtainable. Or that after 10 years, regulatory requirements force the data provider to delete the data. Or whatever is needed to assess the likelihood of being able to access such data. Costs and delays are also important.</li>
  <li>In some cases, authors may already know that the regime within the data provider has changed in such a fashion that the data are no longer available to anybody going forward - that may not be an impediment for the paper being published, but it is important to know (the data are fundamentally unverifiable)</li>
</ul>

<p>This is summarized in the Data and Code Availability Standard, that many econ journals now adhere to: <a href="https://datacodestandard.org/">https://datacodestandard.org/</a></p>

<h2 id="examples">Examples</h2>

<p>Here are some examples (not all exactly corresponding to a single-entity NDA):</p>

<h3 id="gross--sampat-2023">Gross &amp; Sampat (2023)</h3>

<blockquote>
  <p>Gross, Daniel P., and Bhaven N. Sampat. 2023. “America, Jump-Started: World War II R&amp;D and the Takeoff of the US Innovation System.” American Economic Review, 113 (12): 3323-56. https://doi.org/10.1257/aer.20221365</p>
</blockquote>

<ul>
  <li><a href="https://doi.org/10.1257/aer.20221365">Article</a></li>
  <li>
    <p><a href="https://doi.org/10.3886/E192375V1">Replication package</a></p>
  </li>
  <li>Some data are included, others are not, because subject to redistribution restrictions, but are obtainable under various agreement, and others are commercially available for payment (thus a variety of DUA types)</li>
  <li>For instance, they state “<em>Derwent Innovation (2018), EPO (2017) PATSTAT, and the Dun &amp;Bradstreet (1980) data were obtained through institutional subscriptions.</em>”</li>
  <li>Excellent data availability statements in the README.</li>
</ul>

<h3 id="cullen--perez-truglia-2023">Cullen &amp; Perez-Truglia (2023)</h3>

<blockquote>
  <p>Cullen, Zoë, and Ricardo Perez-Truglia. 2023. “The Old Boys’ Club: Schmoozing and the Gender Gap.” American Economic Review, 113 (7): 1703-40. https://doi.org/10.1257/aer.20210863</p>
</blockquote>

<ul>
  <li><a href="https://doi.org/10.1257/aer.20210863">Article</a></li>
  <li>
    <p><a href="https://doi.org/10.3886/E182243V1">Replication package</a></p>
  </li>
  <li>Data were collected at a company that the first author was an employee of. The company cannot be named (and is pruned from the author’s CV!)</li>
  <li>README states “The data was collected by the authors in collaboration with a large financial institution via surveys. Zoe Cullen was an employee of the institution, which remains unnamed to protect the confidentially of the firm, at the time of data collection.”</li>
  <li>An extreme form of NDA, which happens a few times.</li>
</ul>

<h3 id="zussman-2023">Zussman (2023)</h3>

<blockquote>
  <p>Zussman, Asaf. 2023. “Discrimination in Times of Crises and the Role of the Media.” American Economic Journal: Applied Economics, 15 (4): 422-51. https://doi.org/10.1257/app.20210732</p>
</blockquote>

<ul>
  <li><a href="https://doi.org/10.1257/app.20210732">Article</a></li>
  <li>
    <p><a href="https://doi.org/10.3886/E175242V1">Replication package</a></p>
  </li>
  <li>The data were scraped from a (named) public website, but contain names of doctors. The data were not made available due to ethical concerns, but the access procedure (repeatable by anybody) is described in detail.</li>
  <li>The author explains that  “<em>The project received approval from the Ethics Committee of the Faculty of Social Sciences at the Hebrew University and from the University Ethics Committee (IRB) under the condition that identifying information about the doctors, most importantly doctor license numbers and names, will not become publicly available.</em>”</li>
  <li>Similar:  Cage et al (2023) <a href="https://doi.org/10.1257/aer.20211509">https://doi.org/10.1257/aer.20211509</a> which contains names of Nazi collaborators.</li>
</ul>

<h3 id="kuhn---shen-2023">Kuhn &amp;  Shen (2023)</h3>

<blockquote>
  <p>Kuhn, Peter, and Kailing Shen. 2023. “What Happens When Employers Can No Longer Discriminate in Job Ads?” American Economic Review, 113 (4): 1013-48. https://doi.org/10.1257/aer.20211127</p>
</blockquote>

<ul>
  <li><a href="https://doi.org/10.1257/aer.20211127">Article</a></li>
  <li>
    <p><a href="https://doi.org/10.3886/E183021V1">Replication package</a></p>
  </li>
  <li>Internal data from a named Chinese company (XMRC.com) are used, but not published, in “<em>accordance with XMRC’s wishes</em>” (read: NDA/DUA). This is how the authors obtained the data.</li>
  <li>But the limited data used for the analysis are deposited in the Research Data Center of the IZA (a German research center) and can be analyzed on a remote computing platform</li>
</ul>

<h2 id="summary">Summary</h2>

<p>In all of the above, focus was on transparency of the two components of the data availability statement: original access, and subsequent access.</p>

<h2 id="postscript-access-by-the-journal-is-not-the-same-as-public-access">Postscript: Access by the journal is not the same as public access</h2>

<p>I will note that in many of these cases, the files were made available to the journal’s Data Editor (=me) under a derivative or implicit NDA, allowing the journal to verify veracity of the analysis, despite the data not being publishable. In cases where the source cannot be named, the Data Editor may enter into an NDA with the author to learn the name of the source, to verify plausibility, without revealing the information publicly. While all of these are second-best access methods, they are far better than obscurity and opacity.</p>

<h2 id="additional-readings">Additional readings</h2>

<ul>
  <li><a href="https://aeadataeditor.github.io/posts/2023-11-01-ndas.html">2023 post on NDAs</a></li>
  <li><a href="https://aeadataeditor.github.io/aea-de-guidance/2021-10-28-reproducibility-restricted-france.html">2021 post on example of checking confidential data</a></li>
  <li><a href="https://www.aeaweb.org/journals/data/policy-third-party">AEA policy on third-party replicators</a></li>
  <li><a href="https://aeadataeditor.github.io/aea-de-guidance/sharing-restricted-data">AEA process for obtaining not-for-distribution data</a></li>
  <li>Vilhuber, Lars. 2023. “<a href="https://doi.org/10.1016/j.jeconom.2023.05.001">Reproducibility and transparency versus privacy and confidentiality: Reflections from a data editor</a>, Journal of Econometrics, Volume 235, Issue 2, <a href="https://doi.org/10.1016/j.jeconom.2023.05.001">https://doi.org/10.1016/j.jeconom.2023.05.001</a> (<a href="https://doi.org/10.48550/arXiv.2305.14478">OA version on arXiv</a>)</li>
</ul>]]></content><author><name>AEA Data Editor</name></author><category term="NDA" /><category term="DUA" /><category term="confidential" /><category term="DCAS" /><category term="access" /><summary type="html"><![CDATA[I was recently forwarded a question from a data librarian discussion list, and invited to respond to the question of “example language” for a data access description when data were obtained via a non-disclosure agreement (NDA): […] the data are from a commercial company under a non-disclosure agreement […] asked to include “data sharing plans (for all data, documentation, and code used in analysis)”. […] Can you think of any example language that the researcher could borrow from to include in the data sharing plan? (paraphrased)]]></summary></entry><entry><title type="html">NDAs, DUAs in the verification process</title><link href="https://aeadataeditor.github.io/posts/2023-11-01-ndas" rel="alternate" type="text/html" title="NDAs, DUAs in the verification process" /><published>2023-11-01T00:00:00-04:00</published><updated>2023-11-01T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/ndas</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2023-11-01-ndas"><![CDATA[<p>Toni Whited (EIC of Journal of Financial Economics) had the following question on the <a href="https://twitter.com/toniwhited/status/1718011879480787363">ex-bird site</a>:</p>

<blockquote>
  <p>Econ and finance journals are getting their acts together wrt reproducibility.  A bigger issue now is data acquired via NDAs. I wish it were normal for NDAs to have a clause letting third parties replicate results on an air-gapped machine.</p>

  <p>Don’t know how to make it happen.</p>
</blockquote>

<p>A few thoughts.</p>

<!-- more -->

<h2 id="ndas-with-clauses">NDAs with clauses</h2>

<p>I have started to see researchers incorporate such clauses into NDAs. Very rare, but possible. More generally, certain NDAs allow to add “third parties” to an existing contract - no special clause necessary, but researchers must be aware of the possibility.</p>

<h2 id="ndas-without-clauses">NDAs without clauses</h2>

<p>In some cases, no additional clause is needed. Read the NDA carefully: can you assign a new member of the research team (e.g., a new RA at your co-author’s university) to the contract, with minor hassles (simple notification)? Yes? Then you can probably also assign a journal verifier to the contract! Verifiers can be the “RA” on the contract, and can obtain the data (compliant with any other access restrictions). In many cases, authors have then been able to provide us with a non-publishable extract of the same data, for the duration of the verification process. We can sign a NDA with the authors, if needed, but most are fine with an email promise to delete the data. Our process is outlined <a href="https://aeadataeditor.github.io/aea-de-guidance/sharing-restricted-data">here</a>.</p>

<h2 id="journal-verifiers-with-access">Journal verifiers with access</h2>

<p>Another thing is that in some cases, as long as both the authors and the verifiers are (separately) subscribers, data may be able to be shared. But caution: not every “subscription” is the same. For instance, when researchers use WRDS data, they cannot directly share the data. In principle, I should be able to access the same data sources - as <a href="https://johnson.library.cornell.edu/database/wharton-research-data-services-wrds/">Cornell is also a subscriber</a>. But WRDS subscriptions have a huge menu of sub-options. The researcher may be able to access WRDS <a href="https://github.com/chrisconlon/CommonOwnerReplication/blob/master/code/1_Download_WRDS_Data.py">via the Python API</a>, but as it turns out, my subscription does not extend to that!<sup id="fnref:conlon" role="doc-noteref"><a href="#fn:conlon" class="footnote" rel="footnote">1</a></sup></p>

<h2 id="journal-verifiers-acquiring-access">Journal verifiers acquiring access</h2>

<p>In some cases, there is a <strong>generalized access mechanism</strong>. Thus, while the researcher cannot share the data with us, because the DUA or NDA does not allow for it, it is relatively straightforward for the journal verifier to obtain access. For instance,</p>

<ul>
  <li><a href="https://psidonline.isr.umich.edu/default.aspx">PSID</a> (see <a href="https://simba.isr.umich.edu/U/CondUse.aspx">Conditions of use</a>)</li>
  <li><a href="https://www.worldvaluessurvey.org/wvs.jsp">World Values Survey</a> (WVS)</li>
  <li><a href="https://dhsprogram.com/">Demographic and Health Surveys</a> (DHS) (note banner at <a href="https://dhsprogram.com/data/dataset_admin/login_main.cfm">Data Download site</a>)</li>
  <li><a href="https://www.diw.de/en/diw_01.c.678568.en/research_data_center_soep.html">German Socio-Economic Panel</a> (SOEP) (see <a href="https://www.diw.de/en/diw_01.c.601584.en/data_access.html#c_741347">Data Access rules</a>)</li>
</ul>

<p>all do not allow for redistribution of the data, even of their “publicly accessible” data.</p>

<blockquote>
  <p>Hint: if there is a login, a checkbox, or something else you need to click on in order to download the data, it is very likely that you cannot simply re-publish (distribute, post) the data (but that is neither a sufficient nor a necessary condition).</p>
</blockquote>

<p>But in all three cases, the journal verifier can obtain access to the data, and verify the replication package.</p>

<p>Some of these mechanisms have easy ways for researchers to make re-acquiring the data easy:</p>

<ul>
  <li>PSID offers both the ability to <a href="https://simba.isr.umich.edu/DC/c.aspx">share “carts”</a> and to deposit extracts in a compliant way at the <a href="">PSID repository</a></li>
  <li>SOEP assigns DOI to datasets, allowing to ask for the exact same dataset. See <a href="https://doi.org/10.5684/soep.v35.1">https://doi.org/10.5684/soep.v35.1</a> for an example.</li>
</ul>

<p>While a bit of a hassle, this does allow journals to obtain the same data. Note that this is not always easy or possible: for instance, if the original author used the SOEP data in Europe, they will have had a different access than my US-based team will have, because non-European users only get access to a 95% sample.</p>

<p>Also, Cornell has so far not been able to agree to the terms of use required to even sign a data use agreement, something about GDPR etc… So what do we do then?</p>

<h2 id="using-third-party-verifiers-with-access">Using third party verifiers with access</h2>

<p>When NDAs or DUAs cannot be quickly adjusted, or no parallel data access exists, one can reach out to other verifiers. The AEA has a <a href="https://www.aeaweb.org/journals/data/policy-third-party">policy</a> on that, and we regularly reach out to folks who we know have access. That would be the case for the SOEP above: reach out to a replicator in Europe (for instance, a fellow Europe-based data editor).</p>

<p>More generally, this will be true for data that have complicated and long-winding access procedures, and where simply it is completely out-of-scope (because illegal) for researchers to provide journals with access to the data. This was the case for the <a href="https://www.casd.eu/en/sources/french-customs-data/">French customs data</a> that we used in the <a href="https://aeadataeditor.github.io/aea-de-guidance/2021-10-28-reproducibility-restricted-france.html">Piveteau (2021) replication</a>. The data are available through <a href="https://www.casd.eu/">CASD</a>, the French data access center, and the <a href="https://www.cascad.tech/">cascad</a> replicators have access to CASD, quickly, on a case-by-case basis. We can reach out to them for access to these data. Sometimes, agency or data custodian staff themselves can help out - we’ve had pilot projects with the German IAB, with the Bureau of Labor Statistics, and with the World Bank. This will not always work - volunteering time may be fine in academia, but is not always feasible when working with government or supra-national agencies.</p>

<p>But back to Toni’s point: in principle, if we applied that principle to the journal-centric process, one solution is to have external referees, selected because they have access to the data, conduct the verification, in accordance with some basic principles.</p>

<h2 id="taking-the-computations-to-the-data-instead-of-the-data-to-my-computer">Taking the computations to the data, instead of the data to “my” computer</h2>

<p>Toni also wanted to “replicate results on an air-gapped machine.” While that specific security protocol almost certainly won’t satisfy many data providers these days (they want encrypted hard drives, secure login processes, etc., and want the whole thing documented), this does also suggest another process: rather than bring the data to “my” computer, take the computation to “their” computer (or some other authorized system). In a few cases, we have been granted (legitimate, documented) computer access to servers that are authorized to access the restricted data, always remaining in compliance with the authors’ data access protocol. We have so far been granted legitimate and documented access to computers at UC San Diego, the NBER, Harvard Business School, and University of Uppsala, to name a few (thank you!). This not only solves the data access problem, in some cases it also solves the computational resource problem - sufficient parallel cores, licensed software, etc. This is different from the third-party verification process, above, because in this case, we (the journal verifiers) access the data, and run the code that the authors provided elsewhere.</p>

<h2 id="the-big-caveat">The big caveat</h2>

<p>Of course, none of the above will work if the original NDA and data access is idiosyncratic. In all of the above processes, a secondary outcome is that we can improve the authors’ description of how <strong>somebody</strong> (not just the editorial folks) can get access to the data, and restrictions limiting this. In some cases, the only possible documentation is “<strong>this will not work for anybody else.</strong>” Getting access to firm-specific data is often heavily dependent on interpersonal relationships, and while that might work to simply extending an NDA, it only works if the original relationship continues to exist. So none of these methods will work in all cases. The fallback is then something that Toni’s journal, and a few other econ journals, but not the AEA (!), require: provide some synthetic or simulated data, that at least allows to assess that the code would in principle run. But at least the fact that access <strong>is</strong> idiosyncratic should be made clear.</p>

<h2 id="some-data-from-us">Some data from us</h2>

<p>So how does this work at the AEA in practice? I pulled some stats today from our tracking system. Over the past 12 months, <a href="https://www.aeaweb.org/journals/forms/data-code-availability">authors have identified</a> <strong>112 times</strong> that they might be able to provide us privately access to the data, through one of the mechanisms above. In <strong>86 cases</strong>, after review of conditions, cost, and availability of resources, we pursued those offers in some fashion. That includes figuring out NDAs or privately shared data. It does not cover when we requested data ourselves from third parties, which happened in <strong>22 cases</strong> (some of those cases overlap). In <strong>84 cases</strong>, one of those methods culminated with us coming to terms with whoever controlled the data, and  obtaining access to the data.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Accessing confidential data as part of the verification process is not easy, but it is possible. Ensuring that others can re-use the data is sometimes easier, especially for researchers in the same field, in others harder, when a special clause in the NDA allowed the journal access, but cannot be extended to arbitrary future researchers. And the process must be allowed to fail, because interesting and illuminating research can be conducted with data that cannot be shared. In fact, an update to one of those NDAs negotiations just hit my inbox as I am writing this, and is likely to fail, due to the data provider not being willing to grant an exception or an extension in line with Toni’s original hope and request. That’s life, and is fine - it will not hold up the rest of the verification process that we are conducting, and will still ultimately lead to the publication of the paper.</p>

<p>I see our goal as (data) editors to make these kind of constraints as clear as possible, for all future readers, for a very long time. After all, somebody might still want to correct the record in 100 years, or review what we knew now. It’s not like those articles are going anywhere, even if the data just might disappear! See one of the first “<strong>data corrections</strong>” I’m aware of, by Irving Fisher, 1911.<sup id="fnref:irving" role="doc-noteref"><a href="#fn:irving" class="footnote" rel="footnote">2</a></sup></p>

<h2 id="additional-readings">Additional readings</h2>

<ul>
  <li><a href="https://aeadataeditor.github.io/aea-de-guidance/2021-10-28-reproducibility-restricted-france.html">2021 post on example of checking confidential data</a></li>
  <li><a href="https://www.aeaweb.org/journals/data/policy-third-party">AEA policy on third-party replicators</a></li>
  <li><a href="https://aeadataeditor.github.io/aea-de-guidance/sharing-restricted-data">AEA process for obtaining not-for-distribution data</a></li>
  <li>Vilhuber, Lars. 2023. “<a href="https://doi.org/10.1016/j.jeconom.2023.05.001">Reproducibility and transparency versus privacy and confidentiality: Reflections from a data editor</a>, Journal of Econometrics, Volume 235, Issue 2, <a href="https://doi.org/10.1016/j.jeconom.2023.05.001">https://doi.org/10.1016/j.jeconom.2023.05.001</a> (<a href="https://doi.org/10.48550/arXiv.2305.14478">OA version on arXiv</a>)</li>
</ul>

<h2 id="footnotes">Footnotes!</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:conlon" role="doc-endnote">
      <p>We ultimately used a <a href="https://www.aeaweb.org/journals/data/policy-third-party">third-party replicator</a> with access to the Python API to verify the article. The replication package was found to be perfectly reproducible. See <a href="https://doi.org/10.1257/aer.20191302">Conlon, Chris, and Eric So. 2021. “Common Ownership and Corporate Control.” <em>American Economic Review</em>, 111 (3): 1012-48.</a> for the article, and <a href="https://doi.org/10.3886/E120083V1">https://doi.org/10.3886/E120083V1</a> for the replication package. <a href="#fnref:conlon" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:irving" role="doc-endnote">
      <p>Fisher, Irving. “‘The Equation of Exchange,’ 1896-1910.” The American Economic Review, vol. 1, no. 2, 1911, pp. 296–305. JSTOR, http://www.jstor.org/stable/1804304. Accessed 1 Nov. 2023. <a href="#fnref:irving" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>AEA Data Editor</name></author><category term="NDA" /><category term="DUA" /><category term="confidential" /><summary type="html"><![CDATA[Toni Whited (EIC of Journal of Financial Economics) had the following question on the ex-bird site: Econ and finance journals are getting their acts together wrt reproducibility. A bigger issue now is data acquired via NDAs. I wish it were normal for NDAs to have a clause letting third parties replicate results on an air-gapped machine. Don’t know how to make it happen. A few thoughts.]]></summary></entry><entry><title type="html">RESOLVED - Access to replication packages retrieval and deposit interrupted</title><link href="https://aeadataeditor.github.io/posts/2023-08-29-notice-downtime" rel="alternate" type="text/html" title="RESOLVED - Access to replication packages retrieval and deposit interrupted" /><published>2023-08-29T00:00:00-04:00</published><updated>2023-08-29T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/notice-downtime</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2023-08-29-notice-downtime"><![CDATA[<blockquote>
  <p>THIS HAS BEEN RESOLVED. Please <a href="https://aeadataeditor.github.io/aea-de-guidance/data-deposit-aea.html">deposit as usual</a>!</p>
</blockquote>

<p>The AEA uses the openICPSR repository for the deposit and dissemination of replication packages. On Sunday, <a href="https://umich.edu/announcements/">Aug 27 2023, the University of Michigan, the home institution for openICPSR, had to take all of their systems offline for an undetermined time period</a>. The AEA Code and Data Repository is therefore not accessible at this time, for both authors seeking to deposit their required replication package, and for interested readers to obtain published replication packages. A few operational notes from us follow.</p>

<!-- more -->

<p><img src="/images/umich-down-20230829.png" alt="Screenshot of Umich website" /></p>

<h2 id="for-depositors">For depositors</h2>

<p>Authors who just received a conditional acceptance from an AEA journal are required to deposit their replication package at openICPSR. New depositors will receive a message with temporary instructions (see below). Authors who received their notification in recent weeks, and who are still working on completing their deposit, will also be contacted.</p>

<blockquote>
  <p>“The deposit of replication packages at openICPSR is temporarily interrupted (see https://umich.edu/announcements/). As a temporary measure, you can satisfy your deposit requirement by following these instructions:</p>

  <ul>
    <li>create a ZIP file of your replication package, as you would deposit it on openICPSR. <strong>DO NOT INCLUDE ANY CONFIDENTIAL DATA.</strong></li>
    <li>name the ZIP file “{manuscript number}.zip” (e.g., “AER-2023-0000.zip”)</li>
    <li>upload it at the URL (provided))</li>
  </ul>

  <p>The temporary upload URL is xxxxx. It will only be open as a long as the openICPSR website is inaccessible. Once openICPSR is back online, you will need to complete the normal upload process as outlined at https://aeadataeditor.github.io/aea-de-guidance/data-deposit-aea.html.
“</p>
</blockquote>

<p>The URL will be contained in the email message that depositors will receive.</p>

<p>IMPORTANT: This only delays, but does not replace the usual deposit process. Authors will ultimately still need to complete the deposit, once openICPSR is back online.</p>

<h2 id="for-interested-readers">For interested readers</h2>

<p>Unfortunately, there is no short-term replacement for access to published replication packages. ICPSR has a robust preservation strategy, and we expect no long-term impact on availability of replication packages. We hope that they are able to resolve the issues affecting their network as soon as possible.</p>

<h2 id="any-concerns">Any concerns</h2>

<p>If you have any concerns regarding a specific replication package, please contact the Data Editor by email.</p>]]></content><author><name>AEA Data Editor</name></author><category term="openICPSR" /><category term="problem" /><category term="notice" /><summary type="html"><![CDATA[THIS HAS BEEN RESOLVED. Please deposit as usual! The AEA uses the openICPSR repository for the deposit and dissemination of replication packages. On Sunday, Aug 27 2023, the University of Michigan, the home institution for openICPSR, had to take all of their systems offline for an undetermined time period. The AEA Code and Data Repository is therefore not accessible at this time, for both authors seeking to deposit their required replication package, and for interested readers to obtain published replication packages. A few operational notes from us follow.]]></summary></entry><entry><title type="html">Details on how to update a replication package post-publication</title><link href="https://aeadataeditor.github.io/posts/2023-08-20-examples-of-updates" rel="alternate" type="text/html" title="Details on how to update a replication package post-publication" /><published>2023-08-20T00:00:00-04:00</published><updated>2023-08-20T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/examples-of-updates</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2023-08-20-examples-of-updates"><![CDATA[<p>I have previously posted about <a href="https://aeadataeditor.github.io/posts/2022-11-09-updating-post-publication">how to update a replication package, after initial publication</a>. We do get more than a dozen such updates a year (see my <a href="https://aeadataeditor.github.io/publications/">annual reports</a>). I’ll describe the process and give a few examples here.</p>

<!-- more -->

<h2 id="when-to-update">When to update</h2>

<p>You should update your replication package if</p>

<ul>
  <li>there is an error in one of the code or data files that was detected subsequent to publication.</li>
  <li>you are aware of an improvement in accessibility of the replication package (data in more robust data formats, additional data documentation, more efficient code)</li>
  <li>you are made aware of some other issue with the replication package that needs to be addressed</li>
</ul>

<p>Only the original authors can make these changes, but anybody can detect such changes. We field change requests coming from students attempting to replicate a package, researchers with access to restricted data that we did not have access to, or authors themselves who noticed, or were made aware of, issues with their deposit. In all cases where the initial notice does not involve the author, the Data Editor, or the Co-editor responsible for the article, will contact the author.</p>

<h2 id="whom-to-contact">Whom to contact</h2>

<p>For changes that do not affect the results in the actual manuscript, it is sufficient to contact the Data Editor (I may still reach out to the Editor in charge). For any corrections that affect manuscript or online appendix tables, figure, results, or conclusions, please contact the Editor in charge first, as these may require a corrigendum, erratum, or other corrections.</p>

<blockquote>
  <p>The remainder of this post will only address the changes made to the replication package, not to any other published materials.</p>
</blockquote>

<h2 id="how-to-update">How to update</h2>

<p>In a nutshell, this is described in the <a href="https://www.aeaweb.org/journals/data/policy-revisions">policy</a>, you should</p>

<ul>
  <li>Do <strong>NOT</strong> make a new deposit; edit the old deposit (<a href="mailto:dataeditor@aeapubs.org">contact us</a> if you don’t remember who  last accessed the deposit, or if your email has changed), creating a new version (if you didn’t use openICPSR, refer to the relevant repository’s instructions on how to create a new <strong>version</strong>):</li>
</ul>

<p><img src="/images/icpsr-create-new-version.png" alt="Create a new version on openICPSR" /></p>

<ul>
  <li>Prepare the changes: Download the <strong>published</strong> archive (not your private copy of it), and make changes to code and/or data.</li>
  <li>Edit the README and possibly create a “Changes.txt” or “Changelog.txt”.</li>
  <li>In the deposit, delete the INDIVIDUAL files that need to be changed, then re-upload them (openICPSR does not allow you to simply replace by uploading… sorry)</li>
  <li>Make changes to <strong>NO</strong> other files.</li>
  <li><a href="https://aeadataeditor.github.io/aea-de-guidance/data-deposit-aea.html#submitting-to-the-data-editor">Re-submit</a> to the Data Editor.</li>
</ul>

<h2 id="what-happens-after-update">What happens after update</h2>

<p>After you have submitted the update to the replication package,</p>

<ul>
  <li>the Data Editor will review the deposit for compliance with the  <a href="https://www.aeaweb.org/journals/data/policy-revisions">policy</a>. Changes may be requested.</li>
  <li>the Data Editor will publish the revised replication package (usually, this becomes <strong>V2</strong>). A new DOI is assigned.</li>
  <li>Depending on the type of change being made, the “version of record” (linked from the article page) is adjusted (see <a href="https://www.aeaweb.org/journals/data/policy-revisions#version">what the policy has to say about that</a>). NOTE: Usually, the version of record is NOT modified.</li>
  <li>In all cases, accessing the original deposit (<strong>V1</strong>) will show a banner at the top, directing interested parties to the new version.</li>
</ul>

<p><img src="/images/icpsr-version2-banner.png" alt="Redirect on openICPSR page" /></p>

<h2 id="examples">Examples</h2>

<ul>
  <li>
    <p><a href="https://www.aeaweb.org/journals/data/policy-revisions#version">https://doi.org/10.3886/E148361V1</a> - <a href="https://doi.org/10.3886/E148361V2">https://doi.org/10.3886/E148361V2</a> - only the README was updated (clarified), see top of the (revised) README. For this one, we updated the version of record - see link at <a href="https://doi.org/10.1257/aeri.20210201">https://doi.org/10.1257/aeri.20210201</a> - because no code was impacted, and the change was a clarification. The change was initiated by the authors.</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.3886/E172902V1">https://doi.org/10.3886/E172902V1</a> - <a href="https://doi.org/10.3886/E172902V2">https://doi.org/10.3886/E172902V2</a> - A (small) piece of code was corrected. Since this affected the functionality of the code (though no output from the code), this did NOT change version of record - see the link to the replication package at <a href="https://doi.org/10.1257/aer.20200961">https://doi.org/10.1257/aer.20200961</a>. A researcher contacted the Data Editor, who then contacted the authors.</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.3886/E184461V1">https://doi.org/10.3886/E184461V1</a> - <a href="https://doi.org/10.3886/E184461V2">https://doi.org/10.3886/E184461V2</a> - A data-related issue (copyright and terms of use) required us to remove some data files from the deposit. This is one of the few cases where a replication package was “de-accessioned” – the original deposit is still viewable (the list of files is still there), but cannot be downloaded. In this case, <strong>V2</strong> became the version of record because (a) <strong>V1</strong> is no longer functional (b) the impact does not affect the results of the (successful) reproduction, though it is now clear that part of the package needs proprietary data.</p>
  </li>
</ul>

<h2 id="some-helpful-links">Some helpful links</h2>

<ul>
  <li><a href="https://www.aeaweb.org/journals/data/policy-revisions">The replication package revision policy at the AEA</a></li>
  <li><a href="https://aeadataeditor.github.io/aea-de-guidance/data-deposit-aea.html#submitting-to-the-data-editor">Guidance on how to re-submit</a> (hint: it’s much like the initial submission…)</li>
</ul>]]></content><author><name>AEA Data Editor</name></author><category term="updating" /><category term="improvement" /><category term="reproducibility" /><summary type="html"><![CDATA[I have previously posted about how to update a replication package, after initial publication. We do get more than a dozen such updates a year (see my annual reports). I’ll describe the process and give a few examples here.]]></summary></entry><entry><title type="html">Some remarks on challenges and solutions when conducting reproducibility checking for two recent AEJ:Applied articles</title><link href="https://aeadataeditor.github.io/posts/2023-03-29-challenges-aejapplied-202304" rel="alternate" type="text/html" title="Some remarks on challenges and solutions when conducting reproducibility checking for two recent AEJ:Applied articles" /><published>2023-03-29T00:00:00-04:00</published><updated>2023-03-29T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/challenges-aejapplied-202304</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2023-03-29-challenges-aejapplied-202304"><![CDATA[<p>I wanted to briefly discuss the challenges when conducting data provenance and reproducibility checks, for complex and highly interesting articles, with the example of two articles in the most recent (<a href="https://www.aeaweb.org/issues/715">April 2023</a>) issue of the American Economic Journal: Applied Economics. The solutions involved online compute capsules and alternative repositories.</p>

<!-- more -->

<p>The two articles are</p>

<ul>
  <li>
    <p><a href="https://doi.org/10.1257/app.20200398">Infrastructure Costs</a> (Leah Brooks and Zachary Liscow)</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1257/app.20200196">DETER-ing Deforestation in the Amazon: Environmental Monitoring and Law Enforcement</a> (Juliano Assunção, Clarissa Gandour and Romero Rocha)</p>
  </li>
</ul>

<p>Each of these articles posed a different challenge to my team. In all cases, they are highly complex analyses with large, sometimes very large, data sources.</p>

<h2 id="using-zenodo-to-augment-primary-replication-packages">Using Zenodo to augment primary replication packages</h2>

<p>First, let me consider the impressive work by 
Leah Brooks and Zachary Liscow, “<a href="https://doi.org/10.1257/app.20200398">Infrastructure Costs</a>”.</p>

<p><img src="/images/aejapplied-715-2.png" alt="Brooks and Liscow paper" /></p>

<p>The paper conducts an investigation of the cost of building the US Interstate Highway System, from the 60s to the 80s. There are a lot of miles in the Highway system (about 49,000 miles or 79,000 kilometers), and their data covers a long time period in which much data was not necessarily easily available as digital records. As they so blithely say, “we digitize annual state-level spending data from 1956 to the present… first to use more than a few years of these data…”. While that’s already a lot, they also use the “USGS National Map 3DEP 1-Arc-second Digital Elevation Models” and “National Wetlands Inventory of the United States - State and Substate Shapefiles” (among others) in the analysis. Each of these sources have several hundred files and several dozen gigabytes of data:</p>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Size (GB)</th>
      <th>Count (files)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>USGS National Map 3DEP 1-Arc-second Digital Elevation Models</td>
      <td>83.8</td>
      <td>3449</td>
    </tr>
    <tr>
      <td>National Wetlands Inventory of the United States - State and Substate Shapefiles</td>
      <td>49.3</td>
      <td>150</td>
    </tr>
    <tr>
      <td>Remainder of the <a href="https://doi.org/10.3886/E144281V1">replication package</a></td>
      <td>18.53</td>
      <td>940</td>
    </tr>
  </tbody>
</table>

<p>While both of these sources are in the public domain, they are large, and were, in fact, augmented by the authors.</p>

<p>Two problems arose for us: how do we make these data available to others, and how do we highlight the value-added that the authors have contributed?</p>

<p>The first problem arises because openICPSR, the repository used as the primary deposit for AEA replication packages, does not handle deposits of more than 20GB gracefully. As of 2023, it is slow to create such deposits, and very slow for others to re-use these packages. There also appear to be hard limits around 30GB and 1,000 files.</p>

<p>The second problem is a more philosophical one. While anybody can go back to USGS or the US. Fish and Wildlife Service to obtain these data, most US government agencies do not properly curate or preserve their data. These data may not be there, or they may no longer be there in this format. In fact, for the USGS data, the authors used DVDs that were originally purchased from the US government, augmented by targeted downloads from an interactive, non-scriptable downloader, to fill in missing rasters.</p>

<p>We addressed both of these problems by creating two auxiliary deposits on Zenodo, and removing the data from the primary replication package on openICPSR. The resulting two Zenodo archives are part of the (growing) <a href="https://zenodo.org/communities/aeajournals/">American Economic Association community on Zenodo</a>:</p>

<p><img src="/images/aejapplied-715-2-zenodo-1.png" alt="one of the Zenodo deposits" /></p>

<ul>
  <li>U.S. Geological Survey, &amp; Brooks, Leah. (2022). “USGS National Map 3DEP 1 Arc-second Digital Elevation Models (DEMs): Full Coverage for U.S. Interstate Highway System [Data set].” Zenodo. <a href="https://doi.org/10.5281/zenodo.5830968">https://doi.org/10.5281/zenodo.5830968</a></li>
  <li>U.S. Fish &amp; Wildlife Service. (2022). “National Wetlands Inventory of the United States - State and Substate Shapefiles (Version v2018) [Data set].” Zenodo. <a href="https://doi.org/10.5281/zenodo.5823387">https://doi.org/10.5281/zenodo.5823387</a></li>
</ul>

<p>While downloading nearly 130GB of data from any repository can still be challenging in time and robustness, these data resources are now available.</p>

<h3 id="tools-that-we-used">Tools that we used</h3>

<ul>
  <li><a href="https://github.com/AEADataEditor/Upload-to-Zenodo">Zenodo uploader via API</a>, originally written by a former RA, to upload all files.</li>
  <li><a href="https://github.com/dvolgyes/zenodo_get"><code class="language-plaintext highlighter-rouge">zenodo_get</code></a> to re-download thousands of files.</li>
</ul>

<p>Oh, and because it still takes over 250GB of local disk space and substantial processing time to reproduce the replication package, this is one of the replication packages that we inspected (deeply), but which we did NOT actually run. However, we are confident that a replicator with sufficient resources (including time) can do so. Nevertheless, should a replicator encounter issues, please do contact us, and we will, in turn, contact the authors, if appropriate, to update their replication package as per our <a href="https://www.aeaweb.org/journals/data/policy-revisions">revision policy</a>.</p>

<h2 id="using-compute-capsules-for-easy-reproduction">Using compute capsules for easy reproduction</h2>

<p>I have previously discussed the <a href="https://aeadataeditor.github.io/posts/2021-11-16-docker">use of Docker in economics</a>. In “<a href="https://doi.org/10.1257/app.20200196">DETER-ing Deforestation in the Amazon: Environmental Monitoring and Law Enforcement</a>”, Juliano Assunção, Clarissa Gandour and Romero Rocha collect a whole lot of publicly available Brazilian data, clean it all, and for this article, analyze a particular aspect of it (cloud cover preventing the DETER system from working in a particular area). Because this is a part of what their home institution (the <a href="https://cpiglobal.org">Climate Policy Initiative</a>) does regularly, the data cleaning is part of a data processing pipeline, and run in R. The analysis, as with so many analyses created by economists, runs in Stata.</p>

<p>While it is possible to create a pipeline using both R and Stata, either by combining multiple containers in sequence, or <a href="https://github.com/AEADataEditor/docker-stata-R-example">by combining Stata and R in the same container</a>, this is typically not possible (or very hard) in the easy-to-use online interfaces to Docker such as <a href="https://codeocean.com">CodeOcean</a> and <a href="https://wholetale.org">Wholetale</a>. However, in this case, we wanted to make the analysis easily accessible to others. That also argued against combining the two parts into a single compute capsule: the data processing takes about three weeks, while the core analysis only takes a few minutes.</p>

<p>So in coordination with me, the authors (corresponding author Clarissa Gandour) split the analysis out in a self-standing “capsule” (<a href="https://doi.org/10.24433/CO.5098352.v1">https://doi.org/10.24433/CO.5098352.v1</a>), while the whole processing pipeline is made available in the main replication package on openICPSR (<a href="https://doi.org/10.3886/E132281V1">https://doi.org/10.3886/E132281V1</a>). Interested replicators can go through the whole data cleaning process (as required by <a href="https://www.aeaweb.org/journals/data/data-code-policy">our policy</a>), but if instead they want to focus on the analysis, they can do so with a couple of clicks in CodeOcean.</p>

<p><img src="/images/aejapplied-715-6-codeocean.png" alt="Copy a capsule" /></p>

<p>They can, of course, also run the analysis on their own computer, either following the instructions in the README while running with their own copy of Stata, or running it on their own computer through Docker, using the CodeOcean-provided container combined with their own license.</p>

<p>In this case, we did not run the final version of the data cleaning pipeline, because we inspected the code, ran parts of it, and assessed that it was reproducible (we had run the first draft of the data cleaning pipeline, and sent the authors our feedback). We <em>also</em> did not run the analysis part - not because it’s not feasible, but because the authors ran the analysis on CodeOcean to produce the output in the manuscript. It is that output - together with a screen capture of Stata as it is chugging along - which is visible in the CodeOcean interface:</p>

<p><img src="/images/aejapplied-715-6-codeocean-run.png" alt="Results from run" /></p>

<p>We thus did not <em>need</em> to run it, because the authors had run it in an environment which we know is fundamentally reproducible.</p>

<h3 id="tools-that-we-used-1">Tools that we used</h3>

<ul>
  <li><a href="https://codeocean.com">CodeOcean</a> - academic users have 10 free hours per month</li>
  <li><a href="https://docs.docker.com/engine/install/ubuntu/">Docker</a> on local machines, to test the independent reproducibility of the package
    <ul>
      <li>including the <a href="https://hub.docker.com/r/dataeditors/stata17">Docker Stata image</a> that <a href="https://github.com/AEADataEditor/docker-stata">I prepare</a></li>
    </ul>
  </li>
</ul>

<h2 id="what-are-still-unsolved-issues-in-these-scenarios">What are still unsolved issues in these scenarios</h2>

<p>The two articles illustrate a few key points when it comes to larger-than-usual analyses. First, despite the size of the data, it is feasible to archive and preserve the data in ways that makes it usable for others. However, neither article is fully integrated, when theoretically that is possible. In the Brooks and Liscow article, the current version of the code does not dynamically download the Zenodo-hosted data - that is a manual process. In the Assunção, Gandour, and Rocha article, the data cleaning pipeline is not in CodeOcean, because in the end, the authors would still have needed to copy the output from their data cleaning into the analysis capsule.</p>

<p>Would it be possible to chain two CodeOcean capsules - one running the “DETER” three-week data cleaning pipeline, the other the 5 minute data analysis code?</p>

<p><img src="/images/chained-analysis.png" alt="Chained capsules" /></p>

<p>As of 2023, it is not, at least not in the public product (it is a feature of CodeOcean’s on-premise solutions, however). Could the Brooks and Liscow article have integrated data storage on Zenodo from the start? Solutions that do so exist (see <a href="https://snakemake.readthedocs.io/en/v7.6.2/snakefiles/remote_files.html">Snakemake</a> and one of its front-ends <a href="https://show-your.work/en/latest/">show your work!</a>), but are rarely seen in economics (and come with their own reproducibility demons).</p>

<p>The Assunção, Gandour, and Rocha capsule is, however, an example of how porting the analysis code for the article, and then using it as the primary interface for the final versions is feasible.</p>

<p>While time-consuming, the upload of some of the key value-added files from the Brooks and Liscow article have already proven useful to others - while the original replication package has had 34 unique visitors, the Zenodo-hosted data have had 173 and 103 unique visitors as of this writing! Whether this ultimately leads to more citations (another metric that apparently some folks care about) remains to be seen in the future.</p>

<h2 id="disclosures">Disclosures</h2>

<p>As noted, CodeOcean currently offers academics 10 hours of compute time per month for free. They have also supported the Data Editor’s work with a generous compute quota (which allows us to run weeks-long analyses). I am neither paid, nor do I detain any shares in CodeOcean, nor do I receive a commission for any new customers signing up for a CodeOcean account (which in fact is free). Docker is a commercial company, and I am a paying individual subscriber in order to host container images that the AEA uses. Running containers on personal computers remains free, and running containers on most Linux servers is also free (there are many ways to run containers, not just using Docker’s runtime). Wholetale is an academic infrastructure funded by the National Science Foundation. I have been part of such funding in the past through a <a href="https://nsf.gov/awardsearch/showAward?AWD_ID=1541450&amp;HistoricalAwards=false">subaward</a>, and am currently collaborating with the maintainers of Wholetale on a <a href="https://nsf.gov/awardsearch/showAward?AWD_ID=2209629&amp;HistoricalAwards=false">project</a> that, if successful, would be beneficial to Wholetale. And CodeOcean. And a bunch of other computing infrastructures around the world. Wholetale is free to use, without limitations.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="6e56ee69-5af9-4291-94f1-5d6927775bc5">Assunção, Juliano, Clarissa Gandour, and Romero Rocha. 2021. “Replication Capsule for: DETERring Deforestation in the Amazon: Environmental Monitoring and Law Enforcement.” <i>American Economic Journal: Applied Economics</i>. https://doi.org/10.24433/CO.5098352.v1.</span></li>
<li><span id="10.1257/app.20200196">———. 2023. “DETER-Ing Deforestation in the Amazon: Environmental Monitoring and Law Enforcement.” <i>American Economic Journal: Applied Economics</i> 15 (2): 125–56. https://doi.org/10.1257/app.20200196.</span></li>
<li><span id="brooks-liscow-package">Brooks, Leah, and Zachary Liscow. 2023. “Data and Code for: Infrastructure Costs.” [Replication package]. American Economic Association [publisher], 2023. Ann Arbor, MI: Inter-university Consortium for Political and Social Research [distributor]. https://doi.org/10.3886/E144281V1.</span></li>
<li><span id="10.1257/app.20200398">———. 2023. “Infrastructure Costs.” <i>American Economic Journal: Applied Economics</i> 15 (2): 1–30. https://doi.org/10.1257/app.20200398.</span></li>
<li><span id="u_s_fish_wildlife_service_2022_5823387">U.S. Fish &amp; Wildlife Service. 2022. “National Wetlands Inventory of the United States - 
                   State and Substate Shapefiles.” Zenodo. https://doi.org/10.5281/zenodo.5823387.</span></li>
<li><span id="u_s_geological_survey_2022_5830968">U.S. Geological Survey, and Leah Brooks. 2022. “USGS National Map 3DEP 1 Arc-Second Digital 
                   Elevation Models (DEMs): Full Coverage for U.S.
                   Interstate Highway System.” Zenodo. https://doi.org/10.5281/zenodo.5830968.</span></li></ol>
<p>.</p>]]></content><author><name>AEA Data Editor</name></author><category term="big data" /><category term="complex projects" /><category term="AEJ:Applied" /><summary type="html"><![CDATA[I wanted to briefly discuss the challenges when conducting data provenance and reproducibility checks, for complex and highly interesting articles, with the example of two articles in the most recent (April 2023) issue of the American Economic Journal: Applied Economics. The solutions involved online compute capsules and alternative repositories.]]></summary></entry><entry><title type="html">The oldest replication package, overall?</title><link href="https://aeadataeditor.github.io/posts/2023-02-02-oldest-replication-package-jae" rel="alternate" type="text/html" title="The oldest replication package, overall?" /><published>2023-02-02T00:00:00-05:00</published><updated>2023-02-02T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/oldest-replication-package-jae</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2023-02-02-oldest-replication-package-jae"><![CDATA[<p>After our recent discussion about the oldest <strong>AEA</strong> replication package, I navigated over to the <strong>really</strong> old archive at the Journal of Applied Econometrics. Surprise!</p>

<!-- more -->

<p>After all these years of loving maintenance by James MacKinnon, pioneer of data archives, it has migrated from old-style web pages (<a href="https://en.wikipedia.org/wiki/Gopher_(protocol)">gopher pages</a>, originally, I think!)</p>

<p>The new JAE archive is now at ZBW in Germany.</p>

<h2 id="old-pages">Old pages</h2>

<p>The <a href="http://qed.econ.queensu.ca/jae/legacy.html">old pages</a> were at Queen’s University, Kingston, ON, Canada.</p>

<p><img src="/images/jae-old-2022.png" alt="old JAE Data Archive pages" /></p>

<h2 id="new-pages">New pages</h2>

<p>The <a href="https://journaldata.zbw.eu/journals/jae">new pages</a> are at the ZBW in Germany.</p>

<p><img src="/images/jae-new-2023.png" alt="new JAE Archive pages" /></p>

<h2 id="oldest-replication-package">Oldest replication package</h2>

<p>The honors of the oldest replication package should probably go to … Roger Koenker!</p>

<blockquote>
  <p>Koenker, Roger (1988): Asymptotic theory and econometric practice (replication data). Version: 1. Journal of Applied Econometrics. Dataset. http://dx.doi.org/10.15456/jae.2022313.1129100068</p>
</blockquote>

<blockquote>
  <p>Koenker, R. (1988), Asymptotic Theory And Econometric Practice, Journal of Applied Econometrics, 3(2), 139-147. https://doi.org/10.1002/jae.3950030205</p>
</blockquote>]]></content><author><name>AEA Data Editor</name></author><category term="migration" /><category term="reproducibility" /><summary type="html"><![CDATA[After our recent discussion about the oldest AEA replication package, I navigated over to the really old archive at the Journal of Applied Econometrics. Surprise!]]></summary></entry><entry><title type="html">The oldest AEA replication package</title><link href="https://aeadataeditor.github.io/posts/2023-01-26-oldest-replication-package" rel="alternate" type="text/html" title="The oldest AEA replication package" /><published>2023-01-26T00:00:00-05:00</published><updated>2023-01-26T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/oldest-replication-package</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2023-01-26-oldest-replication-package"><![CDATA[<p>We were recently discussing among data editors what the oldest replication package (in Econ and Political Science) might be.</p>

<!-- more -->

<p>I actually don’t know the answer to that. But the oldest replication package we have in the (migrated) AEA archives is:</p>

<blockquote>
  <p>Frankel, Jeffrey A., and Romer, David H. Replication data for: Does Trade Cause Growth? Nashville, TN: American Economic Association [publisher], 1999. Ann Arbor, MI: Inter-university Consortium for Political and Social Research [distributor], 2019-10-12. <a href="https://doi.org/10.3886/E113211V1">https://doi.org/10.3886/E113211V1</a>.</p>
</blockquote>

<p>which accompanies this article:</p>

<blockquote>
  <p>Frankel, Jeffrey A, and David Romer. “Does Trade Cause Growth?” American Economic Review 89, no. 3 (June 1999): 379–99. <a href="https://doi.org/10.1257/aer.89.3.379">https://doi.org/10.1257/aer.89.3.379</a>.</p>
</blockquote>

<p>Find out yourself: a (fully reproducible) way to verify this (there are better ways, of course)</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">readr</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span><span class="w"> </span><span class="c1"># I'm lazy</span><span class="w">

</span><span class="n">baseurl</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"https://github.com/AEADataEditor/aea-supplement-migration/raw/master/data/acquired"</span><span class="w">
</span><span class="c1"># alternatively, if running locally</span><span class="w">
</span><span class="c1"># baseurl &lt;- "data/acquired"</span><span class="w">
</span><span class="n">aea_article_data</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read_csv</span><span class="p">(</span><span class="n">file.path</span><span class="p">(</span><span class="n">baseurl</span><span class="p">,</span><span class="w">
                                        </span><span class="s2">"aea_article_data.csv.gz"</span><span class="p">))</span><span class="w">
</span><span class="n">aea_issue_data</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read_csv</span><span class="p">(</span><span class="n">file.path</span><span class="p">(</span><span class="n">baseurl</span><span class="p">,</span><span class="w">
                                        </span><span class="s2">"aea_issue_data.csv.gz"</span><span class="p">))</span><span class="w">
</span><span class="n">aea_icpsr_mapping</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read_csv</span><span class="p">(</span><span class="n">file.path</span><span class="p">(</span><span class="n">baseurl</span><span class="p">,</span><span class="w">
                                        </span><span class="s2">"aea_icpsr_mapping.20191014.txt"</span><span class="p">),</span><span class="w">
                              </span><span class="n">col_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"icpsr_doi"</span><span class="p">,</span><span class="s2">"zipfile"</span><span class="p">))</span><span class="w">  </span><span class="o">%&gt;%</span><span class="w"> 
                    </span><span class="n">mutate</span><span class="p">(</span><span class="n">zipfile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">str_remove</span><span class="p">(</span><span class="n">zipfile</span><span class="p">,</span><span class="w">
                                                </span><span class="n">fixed</span><span class="p">(</span><span class="s2">"Original Zip: "</span><span class="p">)))</span><span class="w">
</span><span class="n">aea_deposits</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">left_join</span><span class="p">(</span><span class="n">aea_article_data</span><span class="p">,</span><span class="n">aea_icpsr_mapping</span><span class="p">,</span><span class="w">
                          </span><span class="n">by</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s2">"icpsr_package_name"</span><span class="o">=</span><span class="s2">"zipfile"</span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
  </span><span class="n">left_join</span><span class="p">(</span><span class="n">aea_issue_data</span><span class="p">,</span><span class="n">by</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s2">"issue_id"</span><span class="p">))</span><span class="w">
</span><span class="c1"># oldest package</span><span class="w">
</span><span class="n">aea_deposits</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">filter</span><span class="p">(</span><span class="n">year</span><span class="o">==</span><span class="nf">min</span><span class="p">(</span><span class="n">aea_deposits</span><span class="o">$</span><span class="n">year</span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
  </span><span class="n">select</span><span class="p">(</span><span class="n">doi</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">journal</span><span class="p">,</span><span class="n">volume</span><span class="p">,</span><span class="n">issue</span><span class="p">,</span><span class="w"> </span><span class="n">year</span><span class="p">,</span><span class="n">icpsr_doi</span><span class="p">)</span><span class="w">

</span></code></pre></div></div>

<p>(<a href="https://github.com/AEADataEditor/aea-supplement-migration/blob/ab235cbf1e0e1965a71263d15e1d0f3983fdba9c/programs/oldest-package.R">source</a>)</p>]]></content><author><name>AEA Data Editor</name></author><category term="migration" /><category term="reproducibility" /><summary type="html"><![CDATA[We were recently discussing among data editors what the oldest replication package (in Econ and Political Science) might be.]]></summary></entry><entry><title type="html">DCAS v1.0 Compliance Self-Assessment</title><link href="https://aeadataeditor.github.io/posts/2023-01-25-dcas-compliance" rel="alternate" type="text/html" title="DCAS v1.0 Compliance Self-Assessment" /><published>2023-01-25T00:00:00-05:00</published><updated>2023-01-25T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/dcas-compliance</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2023-01-25-dcas-compliance"><![CDATA[<p><img src="https://datacodestandard.org/assets/img/logo-800.png" alt="DCAS Logo" />
On 2022-12-15, various data editors, including myself, <a href="2022-12-15-launching-dcas">launched the Data and Code Availability Standard (DCAS)</a>.  In this post, I will do a self-assessment of my claim that the AEA’s Data and Code Availability Policy (DCAP) complies with DCAS. The assessment is based on <a href="https://github.com/social-science-data-editors/DCAS/blob/4b68868d3ecd9ac331f9add6813dae4ffe9b8d87/_data/rules.csv">DCAS V1.0 rules</a>, compared to the <a href="https://www.aeaweb.org/journals/data/data-code-policy">DCAP as of January 2023</a>.</p>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<hr />

<h2 id="section-data">Section: Data</h2>

<h3 id="data-availability-statement">Data Availability Statement</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">A Data Availability Statement is provided with detailed enough information such that an independent researcher can replicate the steps needed to access the original data, including any limitations and the expected monetary and time cost of data access.</td>
<td>§ 2: "Authors ... must provide ... information about the data, ... sufficient to permit replication, as well as information about access to data ....

§ 6: "the replication materials shall include... (b) description sufficient to access all data at their original source location,"

§ 9: "...The data availability statement shall provide detailed information on how, where, and under what conditions an independent researcher can access the original source data, as well as author-generated derivative data, and must be explicit and accurate about any restrictions, requirements, payments, and processing delays. The data availability statement shall provide information to assure the reader that the data are available for a sufficiently long period of time."</td>

</table>

<blockquote>
  <p>Comment: The AEA policy is expressed more generally, but de facto, we interpret the policy to require information about limitations - time, location, person type - and cost - time, money - to be crucial, and generally request that information from authors if not provided.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="raw-data">Raw data</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Raw data used in the research (primary data collected by the author and secondary data not otherwise available) is made publicly accessible. Exceptions are explained under Rule 1.</td>
<td>§ 6: "the replication materials shall include (a) the data set(s), "</td>

</table>

<blockquote>
  <p>Comment: The AEA policy is not explicit about providing both raw and derivative data.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="analysis-data">Analysis data</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Analysis data is provided as part of the replication package unless they can be fully reproduced from accessible data within a reasonable time frame. Exceptions are explained under Rule 1.</td>
<td>§ 6: "the replication materials shall include (a) the data set(s), "</td>

</table>

<blockquote>
  <p>Comment: In practice, raw data must always be provided. If the Data Editor observes that processing times are very long to generate derivative data, or that derivative data can be provided when raw data is confidential, then the Data Editor will request that analysis data be provided. It is NOT sufficient to ONLY provide the analysis data, when raw data are available and can be provided.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="format">Format</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">The data files are provided in any format compatible with commonly used statistical package or software. Some journals require data files in open, non-proprietary formats.</td>
<td>§ 11: Formats/Data: The data files may be provided in any format compatible with any commonly used statistical package or software. Authors are encouraged to provide data files in open, non-proprietary formats.</td>

</table>

<blockquote>
  <p>Comment: We do not (yet) require that data (also) be provided in non-proprietary formats. In general, source data are rarely in proprietary formats, but analysis data may be. We interpret “non-proprietary format” to mean that open source (free) software can read the provided data. This is not the same as requiring explicitly open, archive-friendly formats (Library of Congress). For instance, Stata data can be reliably read by Python and R code, and we will accept that. We will generally push back on MATLAB-formatted data, since they are hard to read with such software.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="metadata">Metadata</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Description of variables and their allowed values are publicly accessible.</td>
<td>§ 11: Formats/Data: Authors should ensure that a meaningful name or description (label) is available for every variable in the provided datasets. Codebooks or similar metadata should describe the allowed values and their meaning for each variable. It is acceptable to reference publicly available documentation for these items.</td>

</table>

<blockquote>
  <p>Comment: This requirement can intersect with the data format. It is acceptable to have data formats (compliant with the previous DCAS rule) that include meaningful value and variable labels. When the data format itself does not support such self-documentation, separate codebooks, or references (citations!) to codebooks, are requested. This is somewhat difficult to enforce, and compliance may not be fully in line with the policy in all cases.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="citation">Citation</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">All data used in the paper are cited.</td>
<td>§ 8: All source data used in the paper shall be cited, following the AEA Sample References.</td>

</table>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<hr />

<h2 id="section-code">Section: Code</h2>

<h3 id="data-transformation">Data transformation</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Programs used to create any final and analysis data sets from raw data are included.</td>
<td>§ 2: "Authors ... must provide ... information about the ... programs, and other details of the computations sufficient to permit replication ....

§ 6: "the replication materials shall include... (c) the programs used to create any final and analysis data sets from raw data,"</td>

</table>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="analysis">Analysis</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Programs producing the computational results (estimation, simulation, model solution, visualization) are included.</td>
<td>§ 2: (as before)

§ 6: "the replication materials shall include... (d) programs used to run the final models,"</td>

</table>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="format-1">Format</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Code is provided in source format that can be directly interpreted or compiled by appropriate software.</td>
<td>§ 12: Formats/Code: The programs may be provided in any format compatible with commonly used statistical package or software. </td>

</table>

<blockquote>
  <p>Comment: While the AEA policy does not explicitly specify “directly interpreted… by software”, it is understood that “compatible” means it must both work, and be readable. A PDF of a Python program cannot be (easily) interpreted by a Python interpreter. A Word document of Stata code cannot be directly read by Stata.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<hr />

<h2 id="section-supporting-materials">Section: Supporting materials</h2>

<h3 id="instruments">Instruments</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">If collecting original data through surveys or experiments, survey instruments or experiment instructions as well as details on subject selection are included.</td>
<td>§ 7: For papers collecting original data through surveys or experiments, the replication materials shall also include (f) survey instruments or experiment instructions, (g) computer code for experiment or survey collection mechanisms, and (h) original instructions and details on subject selection. See the supplementary Policy on Experimental and Survey Papers.</td>

</table>

<blockquote>
  <p>Comment: Some of this information may also be provided in Online appendices. The AEA policy is a bit more stringent in that we explicitly treat “experiment instructions” as code when the experiment was conducted using software, though that is, in fact, in line with the overall requirement to have code when code was used.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="ethics">Ethics</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">If applicable, details are shared about ethics approval.</td>
<td>§ 16: If applicable, approval by ethics boards—the Institutional Review Board (IRB) in the United States and equivalent institutions elsewhere—should be demonstrated by including the name of the ethics board and any approval or exemption record number in the title footnote and the author disclosure statement(s). See the Disclosure Policy.</td>

</table>

<blockquote>
  <p>Comment: The AEA policy is a bit more stringent, in that it specifies exactly what to share about the ethics approval. It is both listed as part of the Disclosure Policy, and mentioned in the “title footnote.”</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="pre-registration">Pre-registration</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">If applicable, pre-registration of the research is identified and cited.</td>
<td>§ 15: It is the policy of the AEA that randomized control trials must be registered on the RCT Registry. All such registrations shall be cited in the title footnote and elsewhere in the paper as appropriate. Please see the RCT Registry policy.</td>

</table>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="documentation">Documentation</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">A README document is included, containing a Data Availability Statement, listing all software and hardware dependencies and requirements (including the expected run time), and explaining how to reproduce the research results. The README follows the schema provided by the [Social Science Data Editors’ template README](https://social-science-data-editors.github.io/template_README/).</td>
<td>§ 13: As part of the archive, authors must provide a README file listing all included files and documenting the purpose, format, and provenance of each file provided, as well as instructing a user on how replication can be conducted. The README shall contain the data availability statement and proper citations for all data used. The README shall follow the schema provided by the Social Science Data Editors' template README.</td>

</table>

<blockquote>
  <p>Comment: While the policy does not explicitly mention “software and hardware dependency and requirements (… run time…)”, it directly references the template README, which does specify those elements.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<hr />

<h2 id="section-sharing">Section: Sharing</h2>

<h3 id="location">Location</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Data and programs are archived by the authors in the repositories deemed acceptable by the journal.</td>
<td>§ 3: Data and programs should be archived in the AEA Data and Code Repository. Footnote: Other repositories and archives may be acceptable, as long as these are 
considered to be "trusted" archives or repositories, see guidance. The AEA Data Editor will assess suitability of any such repositories and archives.</td>

</table>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="license">License</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">A license specifies the terms of use of code and data in the replication package. The license allows for replication by researchers unconnected to the original parties.</td>
<td>§ 13: ... The README shall follow the schema provided by the Social Science Data Editors' template README.</td>

</table>

<blockquote>
  <p>Comment: This rule is included by reference - the License is an element for both data and code in the template README - as well as implicitly. The AEA Data and Code Repository defaults to a CC-BY license, and any deviation is scrutinized by the Data Editor to allow researchers unconnected to the original parties to access maximum information, while remaining compliant with restrictions and terms of use.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="omissions">Omissions</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">The README clearly indicates any omission of the required parts of the package due to legal requirements or limitations or other approved agreements.</td>
<td>§ 3: The Editor should be notified at the time of submission if access to the  data used in a paper is restricted or limited, or if, for some other reason, the requirements above cannot be met.

§4: If data or programs cannot be published in an openly accessible trusted data repository, authors must commit to preserving data and code for a period of no less than five years following publication of the manuscript, and to providing reasonable assistance to requests for clarification and replication.

§ 6: "the replication materials shall include... (b) description sufficient to access all data at their original source location,"</td>

</table>

<blockquote>
  <p>Comment: This rule is implicit in several different paragraphs of the AEA policy. The policy explicitly calls out situations where data may not be accessible or publishable. Authors must explicitly (publicly) commit to preserving materials, and supporting replication attempts. Deviations from the minimum duration are documented in the README. Implicit in 6(b) is the fact that a full description of how to access the data will generally also state that the data cannot be re-published. Finally, the license should be clear about this as well.</p>
</blockquote>

<h2 id="a-few-last-notes">A few last notes</h2>

<p>The current AEA policy was created before the release of the Data and Code Availability Standard. As the AEA and other journals align on a common standard, we will likely more closely adjust how our policy is expressed with the standard, making compliance by authors less well versed in these things easier.</p>

<p>I welcome any feedback.</p>]]></content><author><name>AEA Data Editor</name></author><category term="standards" /><category term="reproducibility" /><category term="provenance" /><category term="dcas" /><summary type="html"><![CDATA[On 2022-12-15, various data editors, including myself, launched the Data and Code Availability Standard (DCAS). In this post, I will do a self-assessment of my claim that the AEA’s Data and Code Availability Policy (DCAP) complies with DCAS. The assessment is based on DCAS V1.0 rules, compared to the DCAP as of January 2023. Section: Data Data Availability Statement What the DCAS saysWhat the AEA DCAP says A Data Availability Statement is provided with detailed enough information such that an independent researcher can replicate the steps needed to access the original data, including any limitations and the expected monetary and time cost of data access. § 2: "Authors ... must provide ... information about the data, ... sufficient to permit replication, as well as information about access to data .... § 6: "the replication materials shall include... (b) description sufficient to access all data at their original source location," § 9: "...The data availability statement shall provide detailed information on how, where, and under what conditions an independent researcher can access the original source data, as well as author-generated derivative data, and must be explicit and accurate about any restrictions, requirements, payments, and processing delays. The data availability statement shall provide information to assure the reader that the data are available for a sufficiently long period of time." Comment: The AEA policy is expressed more generally, but de facto, we interpret the policy to require information about limitations - time, location, person type - and cost - time, money - to be crucial, and generally request that information from authors if not provided. Raw data What the DCAS saysWhat the AEA DCAP says Raw data used in the research (primary data collected by the author and secondary data not otherwise available) is made publicly accessible. Exceptions are explained under Rule 1. § 6: "the replication materials shall include (a) the data set(s), " Comment: The AEA policy is not explicit about providing both raw and derivative data. Analysis data What the DCAS saysWhat the AEA DCAP says Analysis data is provided as part of the replication package unless they can be fully reproduced from accessible data within a reasonable time frame. Exceptions are explained under Rule 1. § 6: "the replication materials shall include (a) the data set(s), " Comment: In practice, raw data must always be provided. If the Data Editor observes that processing times are very long to generate derivative data, or that derivative data can be provided when raw data is confidential, then the Data Editor will request that analysis data be provided. It is NOT sufficient to ONLY provide the analysis data, when raw data are available and can be provided. Format What the DCAS saysWhat the AEA DCAP says The data files are provided in any format compatible with commonly used statistical package or software. Some journals require data files in open, non-proprietary formats. § 11: Formats/Data: The data files may be provided in any format compatible with any commonly used statistical package or software. Authors are encouraged to provide data files in open, non-proprietary formats. Comment: We do not (yet) require that data (also) be provided in non-proprietary formats. In general, source data are rarely in proprietary formats, but analysis data may be. We interpret “non-proprietary format” to mean that open source (free) software can read the provided data. This is not the same as requiring explicitly open, archive-friendly formats (Library of Congress). For instance, Stata data can be reliably read by Python and R code, and we will accept that. We will generally push back on MATLAB-formatted data, since they are hard to read with such software. Metadata What the DCAS saysWhat the AEA DCAP says Description of variables and their allowed values are publicly accessible. § 11: Formats/Data: Authors should ensure that a meaningful name or description (label) is available for every variable in the provided datasets. Codebooks or similar metadata should describe the allowed values and their meaning for each variable. It is acceptable to reference publicly available documentation for these items. Comment: This requirement can intersect with the data format. It is acceptable to have data formats (compliant with the previous DCAS rule) that include meaningful value and variable labels. When the data format itself does not support such self-documentation, separate codebooks, or references (citations!) to codebooks, are requested. This is somewhat difficult to enforce, and compliance may not be fully in line with the policy in all cases. Citation What the DCAS saysWhat the AEA DCAP says All data used in the paper are cited. § 8: All source data used in the paper shall be cited, following the AEA Sample References. Section: Code Data transformation What the DCAS saysWhat the AEA DCAP says Programs used to create any final and analysis data sets from raw data are included. § 2: "Authors ... must provide ... information about the ... programs, and other details of the computations sufficient to permit replication .... § 6: "the replication materials shall include... (c) the programs used to create any final and analysis data sets from raw data," Analysis What the DCAS saysWhat the AEA DCAP says Programs producing the computational results (estimation, simulation, model solution, visualization) are included. § 2: (as before) § 6: "the replication materials shall include... (d) programs used to run the final models," Format What the DCAS saysWhat the AEA DCAP says Code is provided in source format that can be directly interpreted or compiled by appropriate software. § 12: Formats/Code: The programs may be provided in any format compatible with commonly used statistical package or software. Comment: While the AEA policy does not explicitly specify “directly interpreted… by software”, it is understood that “compatible” means it must both work, and be readable. A PDF of a Python program cannot be (easily) interpreted by a Python interpreter. A Word document of Stata code cannot be directly read by Stata. Section: Supporting materials Instruments What the DCAS saysWhat the AEA DCAP says If collecting original data through surveys or experiments, survey instruments or experiment instructions as well as details on subject selection are included. § 7: For papers collecting original data through surveys or experiments, the replication materials shall also include (f) survey instruments or experiment instructions, (g) computer code for experiment or survey collection mechanisms, and (h) original instructions and details on subject selection. See the supplementary Policy on Experimental and Survey Papers. Comment: Some of this information may also be provided in Online appendices. The AEA policy is a bit more stringent in that we explicitly treat “experiment instructions” as code when the experiment was conducted using software, though that is, in fact, in line with the overall requirement to have code when code was used. Ethics What the DCAS saysWhat the AEA DCAP says If applicable, details are shared about ethics approval. § 16: If applicable, approval by ethics boards—the Institutional Review Board (IRB) in the United States and equivalent institutions elsewhere—should be demonstrated by including the name of the ethics board and any approval or exemption record number in the title footnote and the author disclosure statement(s). See the Disclosure Policy. Comment: The AEA policy is a bit more stringent, in that it specifies exactly what to share about the ethics approval. It is both listed as part of the Disclosure Policy, and mentioned in the “title footnote.” Pre-registration What the DCAS saysWhat the AEA DCAP says If applicable, pre-registration of the research is identified and cited. § 15: It is the policy of the AEA that randomized control trials must be registered on the RCT Registry. All such registrations shall be cited in the title footnote and elsewhere in the paper as appropriate. Please see the RCT Registry policy. Documentation What the DCAS saysWhat the AEA DCAP says A README document is included, containing a Data Availability Statement, listing all software and hardware dependencies and requirements (including the expected run time), and explaining how to reproduce the research results. The README follows the schema provided by the [Social Science Data Editors’ template README](https://social-science-data-editors.github.io/template_README/). § 13: As part of the archive, authors must provide a README file listing all included files and documenting the purpose, format, and provenance of each file provided, as well as instructing a user on how replication can be conducted. The README shall contain the data availability statement and proper citations for all data used. The README shall follow the schema provided by the Social Science Data Editors' template README. Comment: While the policy does not explicitly mention “software and hardware dependency and requirements (… run time…)”, it directly references the template README, which does specify those elements. Section: Sharing Location What the DCAS saysWhat the AEA DCAP says Data and programs are archived by the authors in the repositories deemed acceptable by the journal. § 3: Data and programs should be archived in the AEA Data and Code Repository. Footnote: Other repositories and archives may be acceptable, as long as these are considered to be "trusted" archives or repositories, see guidance. The AEA Data Editor will assess suitability of any such repositories and archives. License What the DCAS saysWhat the AEA DCAP says A license specifies the terms of use of code and data in the replication package. The license allows for replication by researchers unconnected to the original parties. § 13: ... The README shall follow the schema provided by the Social Science Data Editors' template README. Comment: This rule is included by reference - the License is an element for both data and code in the template README - as well as implicitly. The AEA Data and Code Repository defaults to a CC-BY license, and any deviation is scrutinized by the Data Editor to allow researchers unconnected to the original parties to access maximum information, while remaining compliant with restrictions and terms of use. Omissions What the DCAS saysWhat the AEA DCAP says The README clearly indicates any omission of the required parts of the package due to legal requirements or limitations or other approved agreements. § 3: The Editor should be notified at the time of submission if access to the data used in a paper is restricted or limited, or if, for some other reason, the requirements above cannot be met. §4: If data or programs cannot be published in an openly accessible trusted data repository, authors must commit to preserving data and code for a period of no less than five years following publication of the manuscript, and to providing reasonable assistance to requests for clarification and replication. § 6: "the replication materials shall include... (b) description sufficient to access all data at their original source location," Comment: This rule is implicit in several different paragraphs of the AEA policy. The policy explicitly calls out situations where data may not be accessible or publishable. Authors must explicitly (publicly) commit to preserving materials, and supporting replication attempts. Deviations from the minimum duration are documented in the README. Implicit in 6(b) is the fact that a full description of how to access the data will generally also state that the data cannot be re-published. Finally, the license should be clear about this as well. A few last notes The current AEA policy was created before the release of the Data and Code Availability Standard. As the AEA and other journals align on a common standard, we will likely more closely adjust how our policy is expressed with the standard, making compliance by authors less well versed in these things easier. I welcome any feedback.]]></summary></entry></feed>