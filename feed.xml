<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://aeadataeditor.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://aeadataeditor.github.io/" rel="alternate" type="text/html" /><updated>2023-05-24T08:02:45-04:00</updated><id>https://aeadataeditor.github.io/feed.xml</id><title type="html">Office of the AEA Data Editor</title><subtitle>(current: Lars Vilhuber)</subtitle><author><name>AEA Data Editor</name></author><entry><title type="html">Some remarks on challenges and solutions when conducting reproducibility checking for two recent AEJ:Applied articles</title><link href="https://aeadataeditor.github.io/posts/2023-03-29-challenges-aejapplied-202304" rel="alternate" type="text/html" title="Some remarks on challenges and solutions when conducting reproducibility checking for two recent AEJ:Applied articles" /><published>2023-03-29T00:00:00-04:00</published><updated>2023-03-29T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/challenges-aejapplied-202304</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2023-03-29-challenges-aejapplied-202304"><![CDATA[<p>I wanted to briefly discuss the challenges when conducting data provenance and reproducibility checks, for complex and highly interesting articles, with the example of two articles in the most recent (<a href="https://www.aeaweb.org/issues/715">April 2023</a>) issue of the American Economic Journal: Applied Economics. The solutions involved online compute capsules and alternative repositories.</p>

<!-- more -->

<p>The two articles are</p>

<ul>
  <li>
    <p><a href="https://doi.org/10.1257/app.20200398">Infrastructure Costs</a> (Leah Brooks and Zachary Liscow)</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1257/app.20200196">DETER-ing Deforestation in the Amazon: Environmental Monitoring and Law Enforcement</a> (Juliano Assunção, Clarissa Gandour and Romero Rocha)</p>
  </li>
</ul>

<p>Each of these articles posed a different challenge to my team. In all cases, they are highly complex analyses with large, sometimes very large, data sources.</p>

<h2 id="using-zenodo-to-augment-primary-replication-packages">Using Zenodo to augment primary replication packages</h2>

<p>First, let me consider the impressive work by 
Leah Brooks and Zachary Liscow, “<a href="https://doi.org/10.1257/app.20200398">Infrastructure Costs</a>”.</p>

<p><img src="/images/aejapplied-715-2.png" alt="Brooks and Liscow paper" /></p>

<p>The paper conducts an investigation of the cost of building the US Interstate Highway System, from the 60s to the 80s. There are a lot of miles in the Highway system (about 49,000 miles or 79,000 kilometers), and their data covers a long time period in which much data was not necessarily easily available as digital records. As they so blithely say, “we digitize annual state-level spending data from 1956 to the present… first to use more than a few years of these data…”. While that’s already a lot, they also use the “USGS National Map 3DEP 1-Arc-second Digital Elevation Models” and “National Wetlands Inventory of the United States - State and Substate Shapefiles” (among others) in the analysis. Each of these sources have several hundred files and several dozen gigabytes of data:</p>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Size (GB)</th>
      <th>Count (files)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>USGS National Map 3DEP 1-Arc-second Digital Elevation Models</td>
      <td>83.8</td>
      <td>3449</td>
    </tr>
    <tr>
      <td>National Wetlands Inventory of the United States - State and Substate Shapefiles</td>
      <td>49.3</td>
      <td>150</td>
    </tr>
    <tr>
      <td>Remainder of the <a href="https://doi.org/10.3886/E144281V1">replication package</a></td>
      <td>18.53</td>
      <td>940</td>
    </tr>
  </tbody>
</table>

<p>While both of these sources are in the public domain, they are large, and were, in fact, augmented by the authors.</p>

<p>Two problems arose for us: how do we make these data available to others, and how do we highlight the value-added that the authors have contributed?</p>

<p>The first problem arises because openICPSR, the repository used as the primary deposit for AEA replication packages, does not handle deposits of more than 20GB gracefully. As of 2023, it is slow to create such deposits, and very slow for others to re-use these packages. There also appear to be hard limits around 30GB and 1,000 files.</p>

<p>The second problem is a more philosophical one. While anybody can go back to USGS or the US. Fish and Wildlife Service to obtain these data, most US government agencies do not properly curate or preserve their data. These data may not be there, or they may no longer be there in this format. In fact, for the USGS data, the authors used DVDs that were originally purchased from the US government, augmented by targeted downloads from an interactive, non-scriptable downloader, to fill in missing rasters.</p>

<p>We addressed both of these problems by creating two auxiliary deposits on Zenodo, and removing the data from the primary replication package on openICPSR. The resulting two Zenodo archives are part of the (growing) <a href="https://zenodo.org/communities/aeajournals/">American Economic Association community on Zenodo</a>:</p>

<p><img src="/images/aejapplied-715-2-zenodo-1.png" alt="one of the Zenodo deposits" /></p>

<ul>
  <li>U.S. Geological Survey, &amp; Brooks, Leah. (2022). “USGS National Map 3DEP 1 Arc-second Digital Elevation Models (DEMs): Full Coverage for U.S. Interstate Highway System [Data set].” Zenodo. <a href="https://doi.org/10.5281/zenodo.5830968">https://doi.org/10.5281/zenodo.5830968</a></li>
  <li>U.S. Fish &amp; Wildlife Service. (2022). “National Wetlands Inventory of the United States - State and Substate Shapefiles (Version v2018) [Data set].” Zenodo. <a href="https://doi.org/10.5281/zenodo.5823387">https://doi.org/10.5281/zenodo.5823387</a></li>
</ul>

<p>While downloading nearly 130GB of data from any repository can still be challenging in time and robustness, these data resources are now available.</p>

<h3 id="tools-that-we-used">Tools that we used</h3>

<ul>
  <li><a href="https://github.com/AEADataEditor/Upload-to-Zenodo">Zenodo uploader via API</a>, originally written by a former RA, to upload all files.</li>
  <li><a href="https://github.com/dvolgyes/zenodo_get"><code class="language-plaintext highlighter-rouge">zenodo_get</code></a> to re-download thousands of files.</li>
</ul>

<p>Oh, and because it still takes over 250GB of local disk space and substantial processing time to reproduce the replication package, this is one of the replication packages that we inspected (deeply), but which we did NOT actually run. However, we are confident that a replicator with sufficient resources (including time) can do so. Nevertheless, should a replicator encounter issues, please do contact us, and we will, in turn, contact the authors, if appropriate, to update their replication package as per our <a href="https://www.aeaweb.org/journals/data/policy-revisions">revision policy</a>.</p>

<h2 id="using-compute-capsules-for-easy-reproduction">Using compute capsules for easy reproduction</h2>

<p>I have previously discussed the <a href="https://aeadataeditor.github.io/posts/2021-11-16-docker">use of Docker in economics</a>. In “<a href="https://doi.org/10.1257/app.20200196">DETER-ing Deforestation in the Amazon: Environmental Monitoring and Law Enforcement</a>”, Juliano Assunção, Clarissa Gandour and Romero Rocha collect a whole lot of publicly available Brazilian data, clean it all, and for this article, analyze a particular aspect of it (cloud cover preventing the DETER system from working in a particular area). Because this is a part of what their home institution (the <a href="https://cpiglobal.org">Climate Policy Initiative</a>) does regularly, the data cleaning is part of a data processing pipeline, and run in R. The analysis, as with so many analyses created by economists, runs in Stata.</p>

<p>While it is possible to create a pipeline using both R and Stata, either by combining multiple containers in sequence, or <a href="https://github.com/AEADataEditor/docker-stata-R-example">by combining Stata and R in the same container</a>, this is typically not possible (or very hard) in the easy-to-use online interfaces to Docker such as <a href="https://codeocean.com">CodeOcean</a> and <a href="https://wholetale.org">Wholetale</a>. However, in this case, we wanted to make the analysis easily accessible to others. That also argued against combining the two parts into a single compute capsule: the data processing takes about three weeks, while the core analysis only takes a few minutes.</p>

<p>So in coordination with me, the authors (corresponding author Clarissa Gandour) split the analysis out in a self-standing “capsule” (<a href="https://doi.org/10.24433/CO.5098352.v1">https://doi.org/10.24433/CO.5098352.v1</a>), while the whole processing pipeline is made available in the main replication package on openICPSR (<a href="https://doi.org/10.3886/E132281V1">https://doi.org/10.3886/E132281V1</a>). Interested replicators can go through the whole data cleaning process (as required by <a href="https://www.aeaweb.org/journals/data/data-code-policy">our policy</a>), but if instead they want to focus on the analysis, they can do so with a couple of clicks in CodeOcean.</p>

<p><img src="/images/aejapplied-715-6-codeocean.png" alt="Copy a capsule" /></p>

<p>They can, of course, also run the analysis on their own computer, either following the instructions in the README while running with their own copy of Stata, or running it on their own computer through Docker, using the CodeOcean-provided container combined with their own license.</p>

<p>In this case, we did not run the final version of the data cleaning pipeline, because we inspected the code, ran parts of it, and assessed that it was reproducible (we had run the first draft of the data cleaning pipeline, and sent the authors our feedback). We <em>also</em> did not run the analysis part - not because it’s not feasible, but because the authors ran the analysis on CodeOcean to produce the output in the manuscript. It is that output - together with a screen capture of Stata as it is chugging along - which is visible in the CodeOcean interface:</p>

<p><img src="/images/aejapplied-715-6-codeocean-run.png" alt="Results from run" /></p>

<p>We thus did not <em>need</em> to run it, because the authors had run it in an environment which we know is fundamentally reproducible.</p>

<h3 id="tools-that-we-used-1">Tools that we used</h3>

<ul>
  <li><a href="https://codeocean.com">CodeOcean</a> - academic users have 10 free hours per month</li>
  <li><a href="https://docs.docker.com/engine/install/ubuntu/">Docker</a> on local machines, to test the independent reproducibility of the package
    <ul>
      <li>including the <a href="https://hub.docker.com/r/dataeditors/stata17">Docker Stata image</a> that <a href="https://github.com/AEADataEditor/docker-stata">I prepare</a></li>
    </ul>
  </li>
</ul>

<h2 id="what-are-still-unsolved-issues-in-these-scenarios">What are still unsolved issues in these scenarios</h2>

<p>The two articles illustrate a few key points when it comes to larger-than-usual analyses. First, despite the size of the data, it is feasible to archive and preserve the data in ways that makes it usable for others. However, neither article is fully integrated, when theoretically that is possible. In the Brooks and Liscow article, the current version of the code does not dynamically download the Zenodo-hosted data - that is a manual process. In the Assunção, Gandour, and Rocha article, the data cleaning pipeline is not in CodeOcean, because in the end, the authors would still have needed to copy the output from their data cleaning into the analysis capsule.</p>

<p>Would it be possible to chain two CodeOcean capsules - one running the “DETER” three-week data cleaning pipeline, the other the 5 minute data analysis code?</p>

<p><img src="/images/chained-analysis.png" alt="Chained capsules" /></p>

<p>As of 2023, it is not, at least not in the public product (it is a feature of CodeOcean’s on-premise solutions, however). Could the Brooks and Liscow article have integrated data storage on Zenodo from the start? Solutions that do so exist (see <a href="https://snakemake.readthedocs.io/en/v7.6.2/snakefiles/remote_files.html">Snakemake</a> and one of its front-ends <a href="https://show-your.work/en/latest/">show your work!</a>), but are rarely seen in economics (and come with their own reproducibility demons).</p>

<p>The Assunção, Gandour, and Rocha capsule is, however, an example of how porting the analysis code for the article, and then using it as the primary interface for the final versions is feasible.</p>

<p>While time-consuming, the upload of some of the key value-added files from the Brooks and Liscow article have already proven useful to others - while the original replication package has had 34 unique visitors, the Zenodo-hosted data have had 173 and 103 unique visitors as of this writing! Whether this ultimately leads to more citations (another metric that apparently some folks care about) remains to be seen in the future.</p>

<h2 id="disclosures">Disclosures</h2>

<p>As noted, CodeOcean currently offers academics 10 hours of compute time per month for free. They have also supported the Data Editor’s work with a generous compute quota (which allows us to run weeks-long analyses). I am neither paid, nor do I detain any shares in CodeOcean, nor do I receive a commission for any new customers signing up for a CodeOcean account (which in fact is free). Docker is a commercial company, and I am a paying individual subscriber in order to host container images that the AEA uses. Running containers on personal computers remains free, and running containers on most Linux servers is also free (there are many ways to run containers, not just using Docker’s runtime). Wholetale is an academic infrastructure funded by the National Science Foundation. I have been part of such funding in the past through a <a href="https://nsf.gov/awardsearch/showAward?AWD_ID=1541450&amp;HistoricalAwards=false">subaward</a>, and am currently collaborating with the maintainers of Wholetale on a <a href="https://nsf.gov/awardsearch/showAward?AWD_ID=2209629&amp;HistoricalAwards=false">project</a> that, if successful, would be beneficial to Wholetale. And CodeOcean. And a bunch of other computing infrastructures around the world. Wholetale is free to use, without limitations.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="6e56ee69-5af9-4291-94f1-5d6927775bc5">Assunção, Juliano, Clarissa Gandour, and Romero Rocha. 2021. “Replication Capsule for: DETERring Deforestation in the Amazon: Environmental Monitoring and Law Enforcement.” <i>American Economic Journal: Applied Economics</i>. https://doi.org/10.24433/CO.5098352.v1.</span></li>
<li><span id="10.1257/app.20200196">———. 2023. “DETER-Ing Deforestation in the Amazon: Environmental Monitoring and Law Enforcement.” <i>American Economic Journal: Applied Economics</i> 15 (2): 125–56. https://doi.org/10.1257/app.20200196.</span></li>
<li><span id="brooks-liscow-package">Brooks, Leah, and Zachary Liscow. 2023. “Data and Code for: Infrastructure Costs.” [Replication package]. American Economic Association [publisher], 2023. Ann Arbor, MI: Inter-university Consortium for Political and Social Research [distributor]. https://doi.org/10.3886/E144281V1.</span></li>
<li><span id="10.1257/app.20200398">———. 2023. “Infrastructure Costs.” <i>American Economic Journal: Applied Economics</i> 15 (2): 1–30. https://doi.org/10.1257/app.20200398.</span></li>
<li><span id="u_s_fish_wildlife_service_2022_5823387">U.S. Fish &amp; Wildlife Service. 2022. “National Wetlands Inventory of the United States - 
                   State and Substate Shapefiles.” Zenodo. https://doi.org/10.5281/zenodo.5823387.</span></li>
<li><span id="u_s_geological_survey_2022_5830968">U.S. Geological Survey, and Leah Brooks. 2022. “USGS National Map 3DEP 1 Arc-Second Digital 
                   Elevation Models (DEMs): Full Coverage for U.S.
                   Interstate Highway System.” Zenodo. https://doi.org/10.5281/zenodo.5830968.</span></li></ol>
<p>.</p>]]></content><author><name>AEA Data Editor</name></author><category term="big data" /><category term="complex projects" /><category term="AEJ:Applied" /><summary type="html"><![CDATA[I wanted to briefly discuss the challenges when conducting data provenance and reproducibility checks, for complex and highly interesting articles, with the example of two articles in the most recent (April 2023) issue of the American Economic Journal: Applied Economics. The solutions involved online compute capsules and alternative repositories.]]></summary></entry><entry><title type="html">The oldest replication package, overall?</title><link href="https://aeadataeditor.github.io/posts/2023-02-02-oldest-replication-package-jae" rel="alternate" type="text/html" title="The oldest replication package, overall?" /><published>2023-02-02T00:00:00-05:00</published><updated>2023-02-02T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/oldest-replication-package-jae</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2023-02-02-oldest-replication-package-jae"><![CDATA[<p>After our recent discussion about the oldest <strong>AEA</strong> replication package, I navigated over to the <strong>really</strong> old archive at the Journal of Applied Econometrics. Surprise!</p>

<!-- more -->

<p>After all these years of loving maintenance by James MacKinnon, pioneer of data archives, it has migrated from old-style web pages (<a href="https://en.wikipedia.org/wiki/Gopher_(protocol)">gopher pages</a>, originally, I think!)</p>

<p>The new JAE archive is now at ZBW in Germany.</p>

<h2 id="old-pages">Old pages</h2>

<p>The <a href="http://qed.econ.queensu.ca/jae/legacy.html">old pages</a> were at Queen’s University, Kingston, ON, Canada.</p>

<p><img src="/images/jae-old-2022.png" alt="old JAE Data Archive pages" /></p>

<h2 id="new-pages">New pages</h2>

<p>The <a href="https://journaldata.zbw.eu/journals/jae">new pages</a> are at the ZBW in Germany.</p>

<p><img src="/images/jae-new-2023.png" alt="new JAE Archive pages" /></p>

<h2 id="oldest-replication-package">Oldest replication package</h2>

<p>The honors of the oldest replication package should probably go to … Roger Koenker!</p>

<blockquote>
  <p>Koenker, Roger (1988): Asymptotic theory and econometric practice (replication data). Version: 1. Journal of Applied Econometrics. Dataset. http://dx.doi.org/10.15456/jae.2022313.1129100068</p>
</blockquote>

<blockquote>
  <p>Koenker, R. (1988), Asymptotic Theory And Econometric Practice, Journal of Applied Econometrics, 3(2), 139-147. https://doi.org/10.1002/jae.3950030205</p>
</blockquote>]]></content><author><name>AEA Data Editor</name></author><category term="migration" /><category term="reproducibility" /><summary type="html"><![CDATA[After our recent discussion about the oldest AEA replication package, I navigated over to the really old archive at the Journal of Applied Econometrics. Surprise!]]></summary></entry><entry><title type="html">The oldest AEA replication package</title><link href="https://aeadataeditor.github.io/posts/2023-01-26-oldest-replication-package" rel="alternate" type="text/html" title="The oldest AEA replication package" /><published>2023-01-26T00:00:00-05:00</published><updated>2023-01-26T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/oldest-replication-package</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2023-01-26-oldest-replication-package"><![CDATA[<p>We were recently discussing among data editors what the oldest replication package (in Econ and Political Science) might be.</p>

<!-- more -->

<p>I actually don’t know the answer to that. But the oldest replication package we have in the (migrated) AEA archives is:</p>

<blockquote>
  <p>Frankel, Jeffrey A., and Romer, David H. Replication data for: Does Trade Cause Growth? Nashville, TN: American Economic Association [publisher], 1999. Ann Arbor, MI: Inter-university Consortium for Political and Social Research [distributor], 2019-10-12. <a href="https://doi.org/10.3886/E113211V1">https://doi.org/10.3886/E113211V1</a>.</p>
</blockquote>

<p>which accompanies this article:</p>

<blockquote>
  <p>Frankel, Jeffrey A, and David Romer. “Does Trade Cause Growth?” American Economic Review 89, no. 3 (June 1999): 379–99. <a href="https://doi.org/10.1257/aer.89.3.379">https://doi.org/10.1257/aer.89.3.379</a>.</p>
</blockquote>

<p>Find out yourself: a (fully reproducible) way to verify this (there are better ways, of course)</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">readr</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span><span class="w"> </span><span class="c1"># I'm lazy</span><span class="w">

</span><span class="n">baseurl</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s2">"https://github.com/AEADataEditor/aea-supplement-migration/raw/master/data/acquired"</span><span class="w">
</span><span class="c1"># alternatively, if running locally</span><span class="w">
</span><span class="c1"># baseurl &lt;- "data/acquired"</span><span class="w">
</span><span class="n">aea_article_data</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read_csv</span><span class="p">(</span><span class="n">file.path</span><span class="p">(</span><span class="n">baseurl</span><span class="p">,</span><span class="w">
                                        </span><span class="s2">"aea_article_data.csv.gz"</span><span class="p">))</span><span class="w">
</span><span class="n">aea_issue_data</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read_csv</span><span class="p">(</span><span class="n">file.path</span><span class="p">(</span><span class="n">baseurl</span><span class="p">,</span><span class="w">
                                        </span><span class="s2">"aea_issue_data.csv.gz"</span><span class="p">))</span><span class="w">
</span><span class="n">aea_icpsr_mapping</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read_csv</span><span class="p">(</span><span class="n">file.path</span><span class="p">(</span><span class="n">baseurl</span><span class="p">,</span><span class="w">
                                        </span><span class="s2">"aea_icpsr_mapping.20191014.txt"</span><span class="p">),</span><span class="w">
                              </span><span class="n">col_names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"icpsr_doi"</span><span class="p">,</span><span class="s2">"zipfile"</span><span class="p">))</span><span class="w">  </span><span class="o">%&gt;%</span><span class="w"> 
                    </span><span class="n">mutate</span><span class="p">(</span><span class="n">zipfile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">str_remove</span><span class="p">(</span><span class="n">zipfile</span><span class="p">,</span><span class="w">
                                                </span><span class="n">fixed</span><span class="p">(</span><span class="s2">"Original Zip: "</span><span class="p">)))</span><span class="w">
</span><span class="n">aea_deposits</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">left_join</span><span class="p">(</span><span class="n">aea_article_data</span><span class="p">,</span><span class="n">aea_icpsr_mapping</span><span class="p">,</span><span class="w">
                          </span><span class="n">by</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s2">"icpsr_package_name"</span><span class="o">=</span><span class="s2">"zipfile"</span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
  </span><span class="n">left_join</span><span class="p">(</span><span class="n">aea_issue_data</span><span class="p">,</span><span class="n">by</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s2">"issue_id"</span><span class="p">))</span><span class="w">
</span><span class="c1"># oldest package</span><span class="w">
</span><span class="n">aea_deposits</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">filter</span><span class="p">(</span><span class="n">year</span><span class="o">==</span><span class="nf">min</span><span class="p">(</span><span class="n">aea_deposits</span><span class="o">$</span><span class="n">year</span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> 
  </span><span class="n">select</span><span class="p">(</span><span class="n">doi</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">journal</span><span class="p">,</span><span class="n">volume</span><span class="p">,</span><span class="n">issue</span><span class="p">,</span><span class="w"> </span><span class="n">year</span><span class="p">,</span><span class="n">icpsr_doi</span><span class="p">)</span><span class="w">

</span></code></pre></div></div>

<p>(<a href="https://github.com/AEADataEditor/aea-supplement-migration/blob/ab235cbf1e0e1965a71263d15e1d0f3983fdba9c/programs/oldest-package.R">source</a>)</p>]]></content><author><name>AEA Data Editor</name></author><category term="migration" /><category term="reproducibility" /><summary type="html"><![CDATA[We were recently discussing among data editors what the oldest replication package (in Econ and Political Science) might be.]]></summary></entry><entry><title type="html">DCAS v1.0 Compliance Self-Assessment</title><link href="https://aeadataeditor.github.io/posts/2023-01-25-dcas-compliance" rel="alternate" type="text/html" title="DCAS v1.0 Compliance Self-Assessment" /><published>2023-01-25T00:00:00-05:00</published><updated>2023-01-25T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/dcas-compliance</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2023-01-25-dcas-compliance"><![CDATA[<p><img src="https://datacodestandard.org/assets/img/logo-800.png" alt="DCAS Logo" />
On 2022-12-15, various data editors, including myself, <a href="2022-12-15-launching-dcas">launched the Data and Code Availability Standard (DCAS)</a>.  In this post, I will do a self-assessment of my claim that the AEA’s Data and Code Availability Policy (DCAP) complies with DCAS. The assessment is based on <a href="https://github.com/social-science-data-editors/DCAS/blob/4b68868d3ecd9ac331f9add6813dae4ffe9b8d87/_data/rules.csv">DCAS V1.0 rules</a>, compared to the <a href="https://www.aeaweb.org/journals/data/data-code-policy">DCAP as of January 2023</a>.</p>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<hr />

<h2 id="section-data">Section: Data</h2>

<h3 id="data-availability-statement">Data Availability Statement</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">A Data Availability Statement is provided with detailed enough information such that an independent researcher can replicate the steps needed to access the original data, including any limitations and the expected monetary and time cost of data access.</td>
<td>§ 2: "Authors ... must provide ... information about the data, ... sufficient to permit replication, as well as information about access to data ....

§ 6: "the replication materials shall include... (b) description sufficient to access all data at their original source location,"

§ 9: "...The data availability statement shall provide detailed information on how, where, and under what conditions an independent researcher can access the original source data, as well as author-generated derivative data, and must be explicit and accurate about any restrictions, requirements, payments, and processing delays. The data availability statement shall provide information to assure the reader that the data are available for a sufficiently long period of time."</td>

</table>

<blockquote>
  <p>Comment: The AEA policy is expressed more generally, but de facto, we interpret the policy to require information about limitations - time, location, person type - and cost - time, money - to be crucial, and generally request that information from authors if not provided.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="raw-data">Raw data</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Raw data used in the research (primary data collected by the author and secondary data not otherwise available) is made publicly accessible. Exceptions are explained under Rule 1.</td>
<td>§ 6: "the replication materials shall include (a) the data set(s), "</td>

</table>

<blockquote>
  <p>Comment: The AEA policy is not explicit about providing both raw and derivative data.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="analysis-data">Analysis data</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Analysis data is provided as part of the replication package unless they can be fully reproduced from accessible data within a reasonable time frame. Exceptions are explained under Rule 1.</td>
<td>§ 6: "the replication materials shall include (a) the data set(s), "</td>

</table>

<blockquote>
  <p>Comment: In practice, raw data must always be provided. If the Data Editor observes that processing times are very long to generate derivative data, or that derivative data can be provided when raw data is confidential, then the Data Editor will request that analysis data be provided. It is NOT sufficient to ONLY provide the analysis data, when raw data are available and can be provided.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="format">Format</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">The data files are provided in any format compatible with commonly used statistical package or software. Some journals require data files in open, non-proprietary formats.</td>
<td>§ 11: Formats/Data: The data files may be provided in any format compatible with any commonly used statistical package or software. Authors are encouraged to provide data files in open, non-proprietary formats.</td>

</table>

<blockquote>
  <p>Comment: We do not (yet) require that data (also) be provided in non-proprietary formats. In general, source data are rarely in proprietary formats, but analysis data may be. We interpret “non-proprietary format” to mean that open source (free) software can read the provided data. This is not the same as requiring explicitly open, archive-friendly formats (Library of Congress). For instance, Stata data can be reliably read by Python and R code, and we will accept that. We will generally push back on MATLAB-formatted data, since they are hard to read with such software.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="metadata">Metadata</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Description of variables and their allowed values are publicly accessible.</td>
<td>§ 11: Formats/Data: Authors should ensure that a meaningful name or description (label) is available for every variable in the provided datasets. Codebooks or similar metadata should describe the allowed values and their meaning for each variable. It is acceptable to reference publicly available documentation for these items.</td>

</table>

<blockquote>
  <p>Comment: This requirement can intersect with the data format. It is acceptable to have data formats (compliant with the previous DCAS rule) that include meaningful value and variable labels. When the data format itself does not support such self-documentation, separate codebooks, or references (citations!) to codebooks, are requested. This is somewhat difficult to enforce, and compliance may not be fully in line with the policy in all cases.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="citation">Citation</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">All data used in the paper are cited.</td>
<td>§ 8: All source data used in the paper shall be cited, following the AEA Sample References.</td>

</table>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<hr />

<h2 id="section-code">Section: Code</h2>

<h3 id="data-transformation">Data transformation</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Programs used to create any final and analysis data sets from raw data are included.</td>
<td>§ 2: "Authors ... must provide ... information about the ... programs, and other details of the computations sufficient to permit replication ....

§ 6: "the replication materials shall include... (c) the programs used to create any final and analysis data sets from raw data,"</td>

</table>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="analysis">Analysis</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Programs producing the computational results (estimation, simulation, model solution, visualization) are included.</td>
<td>§ 2: (as before)

§ 6: "the replication materials shall include... (d) programs used to run the final models,"</td>

</table>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="format-1">Format</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Code is provided in source format that can be directly interpreted or compiled by appropriate software.</td>
<td>§ 12: Formats/Code: The programs may be provided in any format compatible with commonly used statistical package or software. </td>

</table>

<blockquote>
  <p>Comment: While the AEA policy does not explicitly specify “directly interpreted… by software”, it is understood that “compatible” means it must both work, and be readable. A PDF of a Python program cannot be (easily) interpreted by a Python interpreter. A Word document of Stata code cannot be directly read by Stata.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<hr />

<h2 id="section-supporting-materials">Section: Supporting materials</h2>

<h3 id="instruments">Instruments</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">If collecting original data through surveys or experiments, survey instruments or experiment instructions as well as details on subject selection are included.</td>
<td>§ 7: For papers collecting original data through surveys or experiments, the replication materials shall also include (f) survey instruments or experiment instructions, (g) computer code for experiment or survey collection mechanisms, and (h) original instructions and details on subject selection. See the supplementary Policy on Experimental and Survey Papers.</td>

</table>

<blockquote>
  <p>Comment: Some of this information may also be provided in Online appendices. The AEA policy is a bit more stringent in that we explicitly treat “experiment instructions” as code when the experiment was conducted using software, though that is, in fact, in line with the overall requirement to have code when code was used.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="ethics">Ethics</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">If applicable, details are shared about ethics approval.</td>
<td>§ 16: If applicable, approval by ethics boards—the Institutional Review Board (IRB) in the United States and equivalent institutions elsewhere—should be demonstrated by including the name of the ethics board and any approval or exemption record number in the title footnote and the author disclosure statement(s). See the Disclosure Policy.</td>

</table>

<blockquote>
  <p>Comment: The AEA policy is a bit more stringent, in that it specifies exactly what to share about the ethics approval. It is both listed as part of the Disclosure Policy, and mentioned in the “title footnote.”</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="pre-registration">Pre-registration</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">If applicable, pre-registration of the research is identified and cited.</td>
<td>§ 15: It is the policy of the AEA that randomized control trials must be registered on the RCT Registry. All such registrations shall be cited in the title footnote and elsewhere in the paper as appropriate. Please see the RCT Registry policy.</td>

</table>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="documentation">Documentation</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">A README document is included, containing a Data Availability Statement, listing all software and hardware dependencies and requirements (including the expected run time), and explaining how to reproduce the research results. The README follows the schema provided by the [Social Science Data Editors’ template README](https://social-science-data-editors.github.io/template_README/).</td>
<td>§ 13: As part of the archive, authors must provide a README file listing all included files and documenting the purpose, format, and provenance of each file provided, as well as instructing a user on how replication can be conducted. The README shall contain the data availability statement and proper citations for all data used. The README shall follow the schema provided by the Social Science Data Editors' template README.</td>

</table>

<blockquote>
  <p>Comment: While the policy does not explicitly mention “software and hardware dependency and requirements (… run time…)”, it directly references the template README, which does specify those elements.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<hr />

<h2 id="section-sharing">Section: Sharing</h2>

<h3 id="location">Location</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">Data and programs are archived by the authors in the repositories deemed acceptable by the journal.</td>
<td>§ 3: Data and programs should be archived in the AEA Data and Code Repository. Footnote: Other repositories and archives may be acceptable, as long as these are 
considered to be "trusted" archives or repositories, see guidance. The AEA Data Editor will assess suitability of any such repositories and archives.</td>

</table>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="license">License</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">A license specifies the terms of use of code and data in the replication package. The license allows for replication by researchers unconnected to the original parties.</td>
<td>§ 13: ... The README shall follow the schema provided by the Social Science Data Editors' template README.</td>

</table>

<blockquote>
  <p>Comment: This rule is included by reference - the License is an element for both data and code in the template README - as well as implicitly. The AEA Data and Code Repository defaults to a CC-BY license, and any deviation is scrutinized by the Data Editor to allow researchers unconnected to the original parties to access maximum information, while remaining compliant with restrictions and terms of use.</p>
</blockquote>

<p><!-- group,topic,description,Relate to AEA DCAP,Comment by Data Editor --></p>

<h3 id="omissions">Omissions</h3>

<table>
<thead>
<tr><td>What the DCAS says</td><td>What the AEA DCAP says</td>
</tr></thead>

<td width="35%">The README clearly indicates any omission of the required parts of the package due to legal requirements or limitations or other approved agreements.</td>
<td>§ 3: The Editor should be notified at the time of submission if access to the  data used in a paper is restricted or limited, or if, for some other reason, the requirements above cannot be met.

§4: If data or programs cannot be published in an openly accessible trusted data repository, authors must commit to preserving data and code for a period of no less than five years following publication of the manuscript, and to providing reasonable assistance to requests for clarification and replication.

§ 6: "the replication materials shall include... (b) description sufficient to access all data at their original source location,"</td>

</table>

<blockquote>
  <p>Comment: This rule is implicit in several different paragraphs of the AEA policy. The policy explicitly calls out situations where data may not be accessible or publishable. Authors must explicitly (publicly) commit to preserving materials, and supporting replication attempts. Deviations from the minimum duration are documented in the README. Implicit in 6(b) is the fact that a full description of how to access the data will generally also state that the data cannot be re-published. Finally, the license should be clear about this as well.</p>
</blockquote>

<h2 id="a-few-last-notes">A few last notes</h2>

<p>The current AEA policy was created before the release of the Data and Code Availability Standard. As the AEA and other journals align on a common standard, we will likely more closely adjust how our policy is expressed with the standard, making compliance by authors less well versed in these things easier.</p>

<p>I welcome any feedback.</p>]]></content><author><name>AEA Data Editor</name></author><category term="standards" /><category term="reproducibility" /><category term="provenance" /><category term="dcas" /><summary type="html"><![CDATA[On 2022-12-15, various data editors, including myself, launched the Data and Code Availability Standard (DCAS). In this post, I will do a self-assessment of my claim that the AEA’s Data and Code Availability Policy (DCAP) complies with DCAS. The assessment is based on DCAS V1.0 rules, compared to the DCAP as of January 2023. Section: Data Data Availability Statement What the DCAS saysWhat the AEA DCAP says A Data Availability Statement is provided with detailed enough information such that an independent researcher can replicate the steps needed to access the original data, including any limitations and the expected monetary and time cost of data access. § 2: "Authors ... must provide ... information about the data, ... sufficient to permit replication, as well as information about access to data .... § 6: "the replication materials shall include... (b) description sufficient to access all data at their original source location," § 9: "...The data availability statement shall provide detailed information on how, where, and under what conditions an independent researcher can access the original source data, as well as author-generated derivative data, and must be explicit and accurate about any restrictions, requirements, payments, and processing delays. The data availability statement shall provide information to assure the reader that the data are available for a sufficiently long period of time." Comment: The AEA policy is expressed more generally, but de facto, we interpret the policy to require information about limitations - time, location, person type - and cost - time, money - to be crucial, and generally request that information from authors if not provided. Raw data What the DCAS saysWhat the AEA DCAP says Raw data used in the research (primary data collected by the author and secondary data not otherwise available) is made publicly accessible. Exceptions are explained under Rule 1. § 6: "the replication materials shall include (a) the data set(s), " Comment: The AEA policy is not explicit about providing both raw and derivative data. Analysis data What the DCAS saysWhat the AEA DCAP says Analysis data is provided as part of the replication package unless they can be fully reproduced from accessible data within a reasonable time frame. Exceptions are explained under Rule 1. § 6: "the replication materials shall include (a) the data set(s), " Comment: In practice, raw data must always be provided. If the Data Editor observes that processing times are very long to generate derivative data, or that derivative data can be provided when raw data is confidential, then the Data Editor will request that analysis data be provided. It is NOT sufficient to ONLY provide the analysis data, when raw data are available and can be provided. Format What the DCAS saysWhat the AEA DCAP says The data files are provided in any format compatible with commonly used statistical package or software. Some journals require data files in open, non-proprietary formats. § 11: Formats/Data: The data files may be provided in any format compatible with any commonly used statistical package or software. Authors are encouraged to provide data files in open, non-proprietary formats. Comment: We do not (yet) require that data (also) be provided in non-proprietary formats. In general, source data are rarely in proprietary formats, but analysis data may be. We interpret “non-proprietary format” to mean that open source (free) software can read the provided data. This is not the same as requiring explicitly open, archive-friendly formats (Library of Congress). For instance, Stata data can be reliably read by Python and R code, and we will accept that. We will generally push back on MATLAB-formatted data, since they are hard to read with such software. Metadata What the DCAS saysWhat the AEA DCAP says Description of variables and their allowed values are publicly accessible. § 11: Formats/Data: Authors should ensure that a meaningful name or description (label) is available for every variable in the provided datasets. Codebooks or similar metadata should describe the allowed values and their meaning for each variable. It is acceptable to reference publicly available documentation for these items. Comment: This requirement can intersect with the data format. It is acceptable to have data formats (compliant with the previous DCAS rule) that include meaningful value and variable labels. When the data format itself does not support such self-documentation, separate codebooks, or references (citations!) to codebooks, are requested. This is somewhat difficult to enforce, and compliance may not be fully in line with the policy in all cases. Citation What the DCAS saysWhat the AEA DCAP says All data used in the paper are cited. § 8: All source data used in the paper shall be cited, following the AEA Sample References. Section: Code Data transformation What the DCAS saysWhat the AEA DCAP says Programs used to create any final and analysis data sets from raw data are included. § 2: "Authors ... must provide ... information about the ... programs, and other details of the computations sufficient to permit replication .... § 6: "the replication materials shall include... (c) the programs used to create any final and analysis data sets from raw data," Analysis What the DCAS saysWhat the AEA DCAP says Programs producing the computational results (estimation, simulation, model solution, visualization) are included. § 2: (as before) § 6: "the replication materials shall include... (d) programs used to run the final models," Format What the DCAS saysWhat the AEA DCAP says Code is provided in source format that can be directly interpreted or compiled by appropriate software. § 12: Formats/Code: The programs may be provided in any format compatible with commonly used statistical package or software. Comment: While the AEA policy does not explicitly specify “directly interpreted… by software”, it is understood that “compatible” means it must both work, and be readable. A PDF of a Python program cannot be (easily) interpreted by a Python interpreter. A Word document of Stata code cannot be directly read by Stata. Section: Supporting materials Instruments What the DCAS saysWhat the AEA DCAP says If collecting original data through surveys or experiments, survey instruments or experiment instructions as well as details on subject selection are included. § 7: For papers collecting original data through surveys or experiments, the replication materials shall also include (f) survey instruments or experiment instructions, (g) computer code for experiment or survey collection mechanisms, and (h) original instructions and details on subject selection. See the supplementary Policy on Experimental and Survey Papers. Comment: Some of this information may also be provided in Online appendices. The AEA policy is a bit more stringent in that we explicitly treat “experiment instructions” as code when the experiment was conducted using software, though that is, in fact, in line with the overall requirement to have code when code was used. Ethics What the DCAS saysWhat the AEA DCAP says If applicable, details are shared about ethics approval. § 16: If applicable, approval by ethics boards—the Institutional Review Board (IRB) in the United States and equivalent institutions elsewhere—should be demonstrated by including the name of the ethics board and any approval or exemption record number in the title footnote and the author disclosure statement(s). See the Disclosure Policy. Comment: The AEA policy is a bit more stringent, in that it specifies exactly what to share about the ethics approval. It is both listed as part of the Disclosure Policy, and mentioned in the “title footnote.” Pre-registration What the DCAS saysWhat the AEA DCAP says If applicable, pre-registration of the research is identified and cited. § 15: It is the policy of the AEA that randomized control trials must be registered on the RCT Registry. All such registrations shall be cited in the title footnote and elsewhere in the paper as appropriate. Please see the RCT Registry policy. Documentation What the DCAS saysWhat the AEA DCAP says A README document is included, containing a Data Availability Statement, listing all software and hardware dependencies and requirements (including the expected run time), and explaining how to reproduce the research results. The README follows the schema provided by the [Social Science Data Editors’ template README](https://social-science-data-editors.github.io/template_README/). § 13: As part of the archive, authors must provide a README file listing all included files and documenting the purpose, format, and provenance of each file provided, as well as instructing a user on how replication can be conducted. The README shall contain the data availability statement and proper citations for all data used. The README shall follow the schema provided by the Social Science Data Editors' template README. Comment: While the policy does not explicitly mention “software and hardware dependency and requirements (… run time…)”, it directly references the template README, which does specify those elements. Section: Sharing Location What the DCAS saysWhat the AEA DCAP says Data and programs are archived by the authors in the repositories deemed acceptable by the journal. § 3: Data and programs should be archived in the AEA Data and Code Repository. Footnote: Other repositories and archives may be acceptable, as long as these are considered to be "trusted" archives or repositories, see guidance. The AEA Data Editor will assess suitability of any such repositories and archives. License What the DCAS saysWhat the AEA DCAP says A license specifies the terms of use of code and data in the replication package. The license allows for replication by researchers unconnected to the original parties. § 13: ... The README shall follow the schema provided by the Social Science Data Editors' template README. Comment: This rule is included by reference - the License is an element for both data and code in the template README - as well as implicitly. The AEA Data and Code Repository defaults to a CC-BY license, and any deviation is scrutinized by the Data Editor to allow researchers unconnected to the original parties to access maximum information, while remaining compliant with restrictions and terms of use. Omissions What the DCAS saysWhat the AEA DCAP says The README clearly indicates any omission of the required parts of the package due to legal requirements or limitations or other approved agreements. § 3: The Editor should be notified at the time of submission if access to the data used in a paper is restricted or limited, or if, for some other reason, the requirements above cannot be met. §4: If data or programs cannot be published in an openly accessible trusted data repository, authors must commit to preserving data and code for a period of no less than five years following publication of the manuscript, and to providing reasonable assistance to requests for clarification and replication. § 6: "the replication materials shall include... (b) description sufficient to access all data at their original source location," Comment: This rule is implicit in several different paragraphs of the AEA policy. The policy explicitly calls out situations where data may not be accessible or publishable. Authors must explicitly (publicly) commit to preserving materials, and supporting replication attempts. Deviations from the minimum duration are documented in the README. Implicit in 6(b) is the fact that a full description of how to access the data will generally also state that the data cannot be re-published. Finally, the license should be clear about this as well. A few last notes The current AEA policy was created before the release of the Data and Code Availability Standard. As the AEA and other journals align on a common standard, we will likely more closely adjust how our policy is expressed with the standard, making compliance by authors less well versed in these things easier. I welcome any feedback.]]></summary></entry><entry><title type="html">Launching DCAS</title><link href="https://aeadataeditor.github.io/posts/2022-12-15-launching-dcas" rel="alternate" type="text/html" title="Launching DCAS" /><published>2022-12-15T00:00:00-05:00</published><updated>2022-12-15T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/launching-dcas</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2022-12-15-launching-dcas"><![CDATA[<p><img src="https://datacodestandard.org/assets/img/logo-800.png" alt="DCAS Logo" />
The data editors of the journals of the <a href="https://www.aeaweb.org/journals">American Economic Association</a><sup id="fnref:aea" role="doc-noteref"><a href="#fn:aea" class="footnote" rel="footnote">1</a></sup>, of the <a href="https://res.org.uk/journals/">Royal Economic Society</a><sup id="fnref:res" role="doc-noteref"><a href="#fn:res" class="footnote" rel="footnote">2</a></sup>, the <a href="https://www.restud.com/">Review of Economic Studies</a>,  the <a href="https://www.economics.ca/cpages/cje-home">Canadian Journal of Economics</a>, and <a href="https://weai.org/view/EI">Economic Inquiry</a> have joined forces  to proudly launch <strong>DCAS</strong>, the <a href="https://datacodestandard.org/">Data and Code Availability Standard</a>. This set of rules regarding what constitutes an appropriate data and code replication package will help authors comply with journals’ data and code availability policies. DCAS provides a standard, meant to make compliance easier by setting common requirements across all participating journals, and to help journals create and align their data and code availability policy.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:aea" role="doc-endnote">
      <p>The journals of the American Economic Association are the American Economic Review, AER: Insights, and the American Economic Journal: Applied Economics, Economic Policy, Macroeconomics, and Microeconomics. <a href="#fnref:aea" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:res" role="doc-endnote">
      <p>The journals of the Royal Economic Society are the Econometrics Journal and the Economic Journal. <a href="#fnref:res" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>AEA Data Editor</name></author><category term="standards" /><category term="reproducibility" /><category term="provenance" /><category term="dcas" /><summary type="html"><![CDATA[The data editors of the journals of the American Economic Association1, of the Royal Economic Society2, the Review of Economic Studies, the Canadian Journal of Economics, and Economic Inquiry have joined forces to proudly launch DCAS, the Data and Code Availability Standard. This set of rules regarding what constitutes an appropriate data and code replication package will help authors comply with journals’ data and code availability policies. DCAS provides a standard, meant to make compliance easier by setting common requirements across all participating journals, and to help journals create and align their data and code availability policy. The journals of the American Economic Association are the American Economic Review, AER: Insights, and the American Economic Journal: Applied Economics, Economic Policy, Macroeconomics, and Microeconomics. &#8617; The journals of the Royal Economic Society are the Econometrics Journal and the Economic Journal. &#8617;]]></summary></entry><entry><title type="html">What is this LICENSE thing</title><link href="https://aeadataeditor.github.io/posts/2022-11-16-where-are-the-terms-of-use" rel="alternate" type="text/html" title="What is this LICENSE thing" /><published>2022-11-16T00:00:00-05:00</published><updated>2022-11-16T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/where-are-the-terms-of-use</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2022-11-16-where-are-the-terms-of-use"><![CDATA[<p>The <a href="https://social-science-data-editors.github.io/template_README/">template README</a> required by various econ journals asks for a statement about the rights to RE-distribute data. Many economists are confused by this: “<em>But the data is publicly available.</em>” Let me try to disentangle that somewhat.</p>

<!-- more -->

<h2 id="the-statement-about-rights">The statement about rights</h2>

<p>The statement says</p>

<blockquote>
  <p>I certify that the author(s) of the manuscript have documented 
permission to redistribute/publish the data contained within this 
replication package. Appropriate permission are documented in the 
LICENSE.txt file.</p>
</blockquote>

<p>Two questions arise: what does this mean, and what is an author supposed to do with the LICENSE.txt file? And then of course, how to cite it all.</p>

<h3 id="questions-and-some-answers">Questions and some answers</h3>

<p>Here are a few questions that arise</p>

<blockquote>
  <p>Do you require licensing information for all the data that we are using, or just the specific data that is provided in the replication package?</p>
</blockquote>

<p>Many econ papers use data from multiple sources, including data that are clearly confidential. Some data sources are not confidential, but are subject to copyright or licensing agreements. The replication package should ONLY contain data that can be redistributed, and the statement ONLY pertains to such data. It does not pertain to data not included within the replication package.</p>

<p>Of course, a good chunk of the README is spent describing ALL the data sources, including the confidential ones, the non-confidential ones that are copyrighted, the non-confidential ones that are proprietary, or otherwise subject to redistribution restrictions. ALL data provenance must be described, sufficient for a replicator to start from scratch, ignoring even the data provided within the replication package. That description should contain the licensing information for every dataset as well, at least in summary. It should list pertinent conditions and restrictions, for instance: application process, required residency or citizenship, etc. The LICENSE.txt is more likely to contain a long text in legalese, the formal permission to use the data that is in fact <em>included</em> in the package.</p>

<blockquote>
  <p>Why can’t I redistribute this data, since it is publicly available?</p>
</blockquote>

<p>I’ll take the IPUMS CPS and the S&amp;P 500 as an example.</p>

<p>“Publicly available” does not mean that you have the rights to distribute. For instance, you can use the <a href="https://fred.stlouisfed.org/series/SP500">S&amp;P 500 data distributed by FRED</a>, but you are not allowed to re-distribute that data, as noted on the page there. You would describe that in the README, but the license would not be in the LICENSE.txt, because you are not, in fact, including the data!</p>

<p>Turning to the CPS: When CPS data is pulled directly from the <a href="https://www.census.gov/programs-surveys/cps.html">US Census Bureau website</a>, it is in the “public domain,” i.e., not subject to copyright (Note that this is not clear from the Census Bureau’s website, which simply assumes that you know that! Check the <a href="https://www.usa.gov/government-works">USA.gov</a> website for an explanation.)</p>

<p>But when you obtain it through other sources (<a href="https://ceprdata.org/">CEPR</a>, <a href="https://www.epi.org/data/">EPI</a>, <a href="https://www.ipums.org/projects/ipums-cps">IPUMS</a>), you have to read the terms of use, since by re-packaging the data, the <strong>files</strong> containing the data​ are subject to copyright by the redistributor… .</p>

<p>If you are using the IPUMS data, the terms of use describe what you can do with the data: <a href="https://www.ipums.org/about/terms">https://www.ipums.org/about/terms</a>. As it turns out, you can​ redistribute an extract from their database, and that​ is what you should list in the LICENSE.txt.</p>

<p>Note that other licenses are “sticky” - if you obtain data that is under a <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a> (Creative Commons) license, then you can do with the data what you want - but you must include the CC-BY license and the original source attribution. In essence, that part of your data is also under a CC-BY license.</p>

<blockquote>
  <p>What goes into the LICENSE.txt?</p>
</blockquote>

<p><img src="/images/openicpsr-license.png" alt="LICENSE txt image" /></p>

<p>This is straightforward if you have a single source. It should state the permissions and conditions that are attached to that file. If the data you obtained has a LICENSE.txt (some do), then simply include that with your deposit. Licenses can be long - they are written in legalese, because they are, in fact, legal permission to do something with the data.</p>

<p>If you created or collected the primary data yourself, you define the LICENSE. By default, deposits on openICPSR have a CC-BY license. We have a small discussion of how to choose licenses at the <a href="https://aeadataeditor.github.io/aea-de-guidance/Licensing_guidance">AEA Data Editor’s website</a> and the <a href="https://social-science-data-editors.github.io/guidance/Licensing_guidance.html">Social Science Data Editors’ website</a>.</p>

<p>If you have multiple data sources, it becomes a bit more complicated. The LICENSE.txt can be a simple collation of the various terms of use/ licenses/etc. So you could have:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>For IPUMS CPS files, IPUMS' Standard Redistribution Terms 
apply (https://www.ipums.org/about/terms#redistribution)

    You will not redistribute the data without permission. You may 
    publish a subset of the data to meet journal requirements for 
    accessing data related to a particular publication. Contact us for
    permission for any other redistribution; we will consider requests
    for free and commercial redistribution. 

Applies to: AHTUS, ATUS, CPS, GeoMarker, HigherEd, IHGIS, MEPS, MTUS, NHGIS, NHIS

For UNCTAD TRAINS data:

The TRAINS Terms of Use at https://trainsonline.unctad.org/disclaimer state that users

   are not allowed to disseminate the data or parts of the 
   database in other dissemination tools unless written 
   permission is given by the Chief of UNCTAD's Trade 
   Information Section, Trade Analysis Branch, Division on 
   International Goods and Commodities. 

We have obtained such permission via email correspondence on 16 November 2022. 
</code></pre></div></div>

<blockquote>
  <p>OK, so how do I cite the data?</p>
</blockquote>

<p>Thank you for that question, since most researchers in economics do NOT cite the data. See this <a href="https://social-science-data-editors.github.io/guidance/addtl-data-citation-guidance.html">extensive discussion</a> over on the Social Science Data Editor website, consult the <a href="https://www.aeaweb.org/journals/policies/sample-references">AEA Style Reference</a>, and remember that not all data distributors provide suggested citations that satisfy the <a href="https://force11.org/info/joint-declaration-of-data-citation-principles-final/">Data Citation Principles</a>. If they ask you to cite a working paper, do so, but <strong>also</strong> cite the data correctly.</p>

<blockquote>
  <p>Most of this data was collected in 2016, but the <a href="https://www.ahtusdata.org/ahtus/citation.shtml">IPUMS AHTUS data citation page</a> only lists the 2018 version. I am unable to find a historic example of this specific citation.</p>
</blockquote>

<p>IPUMS doesn’t make it easy, I know.  There is a not-so-obvious list of versions of the data at this URL: <a href="https://www.ipums.org/projects/ipums-time-use">https://www.ipums.org/projects/ipums-time-use</a>. The <a href="https://www.ahtusdata.org/ahtus-action/revisions">IPUMS Time Use Revision history page</a> does NOT list the DOIs for the various version. So as far as I can deduce from that, you would have used V1.0 of the AHTUS data, which has DOI <strong>10.18128/D061.V1.0</strong>. You can use <a href="https://citation.crosscite.org/">https://citation.crosscite.org/</a>, or simply adapt their suggested citation accordingly.</p>

<p>Data providers have not all adapted to a world where data citations are ubiquitious, or should be. Sometimes it takes a little extra work.</p>

<p>Note that data citations should appear both in the manuscript (upon first mention of the data) and in the README (properly formatted as in the manuscript).</p>]]></content><author><name>AEA Data Editor</name></author><category term="license" /><category term="terms of use" /><category term="copyright" /><category term="reproducibility" /><category term="provenance" /><summary type="html"><![CDATA[The template README required by various econ journals asks for a statement about the rights to RE-distribute data. Many economists are confused by this: “But the data is publicly available.” Let me try to disentangle that somewhat.]]></summary></entry><entry><title type="html">A short example of how to update a replication package</title><link href="https://aeadataeditor.github.io/posts/2022-11-09-updating-post-publication" rel="alternate" type="text/html" title="A short example of how to update a replication package" /><published>2022-11-09T00:00:00-05:00</published><updated>2022-11-09T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/updating_post_publication</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2022-11-09-updating-post-publication"><![CDATA[<p>The AEA Data and Code Availability does not just require that authors publish a replication package - it also encourages authors to improve upon the replication package. Here is an example.</p>

<!-- more -->

<blockquote>
  <p>[NOTE] I am posting about this update with permission by the author.</p>
</blockquote>

<h3 id="links">Links</h3>

<ul>
  <li><a href="https://www.aeaweb.org/journals/policies/data-code">Data and Code Availability Policy</a></li>
  <li><a href="https://www.aeaweb.org/journals/data/policy-revisions">Revision Policy</a>’</li>
  <li><a href="https://aeadataeditor.github.io/aea-de-guidance/FAQ.html#i-was-wondering-whether-and-how-i-can-update-the-published-repository-for-our-paper-i-was-contacted-by-a-researcher-who-is-doing-a-replication--couple-of-minor-issues--forgotten-to-include-two-auxiliary-datasets-in-the-repository-without-which-one-of-the-programs-does-not-run-successfully">Instructions how to create a new version on openICPSR</a></li>
</ul>

<h3 id="tldr">TLDR</h3>

<p>In a nutshell, when authors, or replicators, or somebody on the internet, identifies an issue with a package, they have a few options to identify and publish a solution for it, so that others can benefit the update.</p>

<p>They can submit a comment to the journal, when the issue is a scientific one that materially affects the outcome and the conclusions.</p>

<p>They can write a new article, triggered by an issue identified through the reproduction or replication attempt. This can be an original new article, or a replication-specific article (<a href="https://onlinelibrary.wiley.com/page/journal/10991255/homepage/News.html#replication">for instance, at the Journal of Applied Econometrics</a>).</p>

<p>They can record the issue on platforms such as the <a href="https://www.socialsciencereproduction.org/">Social Science Reproduction Platform</a> or the <a href="https://replication.uni-goettingen.de/">Replication Wiki</a>.</p>

<p>Or, if the issue is really minor, or is simply an improvement, authors can post a revision of replication package according to the <strong><a href="https://www.aeaweb.org/journals/data/policy-revisions">AEA Revision Policy</a></strong>.</p>

<p>This post describes the latter.</p>

<h3 id="timeline">Timeline</h3>

<ul>
  <li>Oct 2019: Replication package was submitted to Data Editor (one of the first 200 cases). A first report was sent back to the author (they were simpler back then…), the author revised the package, and re-submitted an improved package.</li>
  <li>Nov 2019: The revised package was accepted (after 1 round). We were unable to access all data, but improved the documentation of the data sources.</li>
  <li>April 2020: Publication of the manuscript: <a href="https://doi.org/10.1257/aer.20171732">https://doi.org/10.1257/aer.20171732</a>, and of the replication package: <a href="https://doi.org/10.3886/E112121V1">https://doi.org/10.3886/E112121V1</a>. <img src="/images/revpolicy-article1.png" alt="article page" /> <img src="/images/revpolicy-data1.png" alt="replication package v1" /></li>
  <li>Sometime in 2020: a replicator, with access to the data, reports to the author various small issues, in particular missing files.</li>
  <li>Jan 2021: Author reaches out to AEA Data Editor,  and wants to correct the data deposit, so that future replicators can access the missing files. A case is created by the AEA Data Editor to follow up.</li>
  <li><em>Life intrudes</em> 🤷‍♂️</li>
  <li>Oct 2022: Author updates the replication package, together with a Changelog (as required by policy), creating a V2. The revised package is published: <a href="https://doi.org/10.3886/E112121V2">https://doi.org/10.3886/E112121V2</a>, and the V1 now has a banner identifying that a newer version is available. <img src="/images/revpolicy-data2.png" alt="revised data package" /></li>
</ul>

<h3 id="notes">Notes</h3>

<ul>
  <li>The original deposit - the version of record - remains available, and downloadable.</li>
  <li>The article page continues to link to the original deposit (V1) because it is the version of record.</li>
  <li>The original deposit has a banner indicating that a newer package is available, and directs to that newer deposit.</li>
  <li>The original deposit and the revised deposit contain cross-links.</li>
</ul>

<h3 id="conclusion">Conclusion</h3>

<p>This is a great example of how the ability to update replication packages is a key part, previously underexploited and not transparent, in improving science. Such updates happen for a variety of reasons multiple times a year. Sometimes, they happen for less happy reasons, such as a data provider requests that a file be removed because posting the file is not compliant with their terms of use. In other cases, authors simply post a better README, after having received feedback from students or replicators.</p>

<p>Revisions and new versions can be created on all regularly used repositories, such as <a href="https://www.openicpsr.org/openicpsr/search/aea/studies">openICPSR</a>, <a href="https://zenodo.org/communities/aeajournals/">Zenodo</a>, and <a href="https://dataverse.harvard.edu/">Dataverse</a>.</p>

<p>When authors publish their replication packages prior to submission, such revisions allow them to incorporate the changes made during the editorial process, whether related to the scientific or the computational content of the paper.</p>

<!-- Ref: AEAREP-228 -->]]></content><author><name>AEA Data Editor</name></author><category term="updating" /><category term="improvement" /><category term="reproducibility" /><summary type="html"><![CDATA[The AEA Data and Code Availability does not just require that authors publish a replication package - it also encourages authors to improve upon the replication package. Here is an example.]]></summary></entry><entry><title type="html">Some remarks on coding when data are confidential</title><link href="https://aeadataeditor.github.io/posts/2022-04-13-coding-confidential" rel="alternate" type="text/html" title="Some remarks on coding when data are confidential" /><published>2022-04-13T00:00:00-04:00</published><updated>2022-04-13T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/coding-confidential</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2022-04-13-coding-confidential"><![CDATA[<p>Back in the fall, I made a few notes regarding how to prepare replication packages when data are confidential (<a href="https://aeadataeditor.github.io/posts/2021-11-08-replication-pkg-confidential">here</a>). What I did not address, and what comes up regularly, is how to <strong>write code</strong> when some code and/or data are confidential.</p>

<!-- more -->

<h2 id="what-is-confidential-code-you-say">What is confidential code, you say?</h2>

<ul>
  <li>In the United States, some variables on IRS databases are considered super-top-secret. So you can’t name that-variable-that-you-filled-out-on-your-Form-1040 in your analysis code of same data. (They are often referred to in jargon as “Title 26 variables”). Not sure why that continues to be perceived as a problem, but until the law changes, that’s one possible constraint.</li>
  <li>Your code contains the random seed you used to anonymize the sensitive identifiers. This might allow to reverse-engineer the anonymization, and is not a good idea to publish.</li>
  <li>You used a look-up table hard-coded in your Stata code to anonymize the sensitive identifiers (<code class="language-plaintext highlighter-rouge">replace anoncounty=1 if county="Tompkins, NY"</code>). A really bad idea, but yes, you probably want to hide that.</li>
  <li>Your IT specialist or misguided disclosure officer thinks publishing the exact path to your copy of the confidential 2010 Census data, e.g., “/data/census/2010”, is a security risk and refuses to let that code through.</li>
  <li>You have adhered to disclosure rules, but for some reason, the precise minimum cell size is a confidential parameter.</li>
</ul>

<p>So whether reasonable or not, this is an issue. How do you do that, without messing up the code, or spending hours redacting your code?</p>

<h2 id="example">Example</h2>

<p>This will serve as an example throughout this post. I’m focusing on Stata, because so many economists use Stata, but none of this is specific to Stata, and the solutions for R, Python, Julia, Matlab, etc. are all quite similar. Assume that variables <code class="language-plaintext highlighter-rouge">q2f</code> and <code class="language-plaintext highlighter-rouge">q3e</code> are considered confidential by some rule, and that the minimum cell size <code class="language-plaintext highlighter-rouge">10</code> is also confidential.</p>

<pre><code class="language-{stata}">set seed 12345
use q2f q3e county using "/data/economic/cmf2012/extract.dta", clear
gen logprofit = log(q2f)
by county: collapse (count)  n=q3e (mean) logprofit
drop if n&lt;10
graph twoway n logprofit
</code></pre>

<h2 id="do-not-do-this">Do not do this</h2>

<p>A bad example, because literally making more work for you and for future replicators, is to manually redact the confidential information with text that is not legitimate code:</p>

<pre><code class="language-{stata}">set seed NNNNN
use &lt;removed vars&gt; county using "&lt;removed path&gt;", clear
gen logprofit = log(XXXX)
by county: collapse (count)  n=XXXX (mean) logprofit
drop if n&lt;XXXX
graph twoway n logprofit
</code></pre>

<p>The redacted program above will no longer run, and will be very tedious to un-redact if a subsequent replicator obtains legitimate access to the confidential data.</p>

<h2 id="better">Better</h2>

<p>Simply replacing the confidential data with replacement that are valid placeholders in the programming language of your choice is already better. Here’s the confidential version of the file:</p>

<pre><code class="language-{stata}">//============ confidential parameters =============
global confseed    12345
global confpath    "/data/economic/cmf2012"
global confprofit  q2f
global confemploy  q3e
global confmincell 10
//============ end confidential parameters =========
set seed $confseed
use $confprofit county using "${confpath}/extract.dta", clear
gen logprofit = log($confprofit)
by county: collapse (count)  n=$confemploy (mean) logprofit
drop if n&lt;$confmincell
graph twoway n logprofit
</code></pre>

<p>and this would be the released file, part of the replication package:</p>

<pre><code class="language-{stata}">//============ confidential parameters =============
global confseed    XXXX    // a number
global confpath    "XXXX"  // a path that will be communicated to you
global confprofit  XXX     // Variable name for profit T26
global confemploy  XXX     // Variable name for employment T26
global confmincell XXX     // a number
//============ end confidential parameters =========
set seed $confseed
use $confprofit county using "${confpath}/extract.dta", clear
gen logprofit = log($confprofit)
by county: collapse (count)  n=$confemploy (mean) logprofit
drop if n&lt;$confmincell
graph twoway n logprofit
</code></pre>

<p>While the code won’t run as-is, it is easy to un-redact, regardless of how many times you reference the confidential values, e.g., <code class="language-plaintext highlighter-rouge">q2f</code>, anywhere in the code.</p>

<h2 id="best">Best</h2>

<p>Note that you have to re-run the entire code to obtain a modified graph, e.g., if you want to add some reference line, or change colors. But if the data presented in the graph is non-sensitive (i.e., disclosable), then the data underlying it is as well. Thus, and this is a more general approach, we can provide code that automatically detects if the confidential data is there, and only then will it run the data preparation part, but it will always run for the graphing (“analysis”) part of the code.</p>

<p>We also introduce the use of a separate file for all the confidential parameters, which may be more convenient, since now, no redaction is needed - the confidential file is simply dropped (but should be documented).</p>

<p>Main file <code class="language-plaintext highlighter-rouge">main.do</code>:</p>

<pre><code class="language-{stata}">//============ confidential parameters =============
capture confirm file "include/confparms.do"
if _rc == 0 {
    // file exists
    include "include/confparms.do"
} else {
    di in red "No confidential parameters found"
}
//============ end confidential parameters =========

//============ non-confidential parameters =========
global safepath "releasable"
cap mkdir "$safepath"

//============ end parameters ======================

// ::::  Process only if confidential data is present 

capture confirm "${confpath}/extract.dta"
if _rc == 0 {
   set seed $confseed
   use $confprofit county using "${confpath}/extract.dta", clear
   gen logprofit = log($confprofit)
   by county: collapse (count)  n=$confemploy (mean) logprofit
   drop if n&lt;$confmincell
   save "${safepath}/figure1.dta", replace
} else { di in red "Skipping processing of confidential data" }

//============ at this point, the data is releasable ======
// ::::  Process always 

use "${safepath}/figure1.dta", clear
graph twoway n logprofit
graph export "${safepath}/figure1.pdf", replace
</code></pre>

<p>Auxiliary file <code class="language-plaintext highlighter-rouge">include/confparms.do</code> (not released)</p>

<pre><code class="language-{stata}">//============ confidential parameters =============
global confseed    12345
global confpath    "/data/economic/cmf2012"
global confprofit  q2f
global confemploy  q3e
global confmincell 10
//============ end confidential parameters =========
</code></pre>

<p>Auxiliary file <code class="language-plaintext highlighter-rouge">include/confparms_template.do</code> (this is released)</p>

<pre><code class="language-{stata}">//============ confidential parameters =============
global confseed    XXXX    // a number
global confpath    "XXXX"  // a path that will be communicated to you
global confprofit  XXX     // Variable name for profit T26
global confemploy  XXX     // Variable name for employment T26
global confmincell XXX     // a number
//============ end confidential parameters =========
</code></pre>

<p>And after a successful run, the files <code class="language-plaintext highlighter-rouge">releasable/figure1.dta</code> and <code class="language-plaintext highlighter-rouge">releasable/figure1.pdf</code> are available, and can be reviewed and released.</p>

<p>Thus, the replication package would have:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>main.do
README.md
include/confparms_template.do
releasable/figure1.dta
releasable/figure1.pdf
</code></pre></div></div>

<p>Voilà! The resulting non-confidential package will run to produce the analysis (<code class="language-plaintext highlighter-rouge">figure1.pdf</code>) based on the distributable, non-confidential analysis file (<code class="language-plaintext highlighter-rouge">analysis.dta</code>). It can also be very simply brought back into the confidential environment, where either the replicator creates a new <code class="language-plaintext highlighter-rouge">confparms.do</code>, or copies the confidential <code class="language-plaintext highlighter-rouge">confparms.do</code> from the original author into their own working area.</p>]]></content><author><name>AEA Data Editor</name></author><category term="confidential data" /><category term="complex projects" /><summary type="html"><![CDATA[Back in the fall, I made a few notes regarding how to prepare replication packages when data are confidential (here). What I did not address, and what comes up regularly, is how to write code when some code and/or data are confidential.]]></summary></entry><entry><title type="html">Use of Docker for Reproducibility in Economics</title><link href="https://aeadataeditor.github.io/posts/2021-11-16-docker" rel="alternate" type="text/html" title="Use of Docker for Reproducibility in Economics" /><published>2021-11-21T00:00:00-05:00</published><updated>2021-11-21T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/docker</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-11-16-docker"><![CDATA[<p>In reproducibility verification, a common scenario is the author response “but-it-works-on-my-machine”. Finding common environments is important in such situations, to demonstrate that the error does arise, reproducibly, but also to share with the author the exact environment so that the issue can be fixed. Shipping around laptops probably isn’t the right solution. We illustrate how we addressed some of those cases using container technology throughout this post.</p>

<!-- more -->

<blockquote>
  <p>NOTE: There are probably still errors in this post. It will remain draft until the stream of comments has died down…</p>
</blockquote>

<blockquote>
  <p>NOTE 2: Post updated with final publication dates for some articles.</p>
</blockquote>

<h2 id="what-are-containers">What are containers</h2>

<p>Containers are “implementations of operating system-level virtualization,” <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> typically on Linux. The most common version is provided by <a href="https://docker.com">Docker</a>, but several other implementations exist, such as <a href="https://singularity.hpcng.org/">Singularity</a>. The use of containers as part of replication packages in economics is extremely low, and yet they have some advantages. This post will explore both pre-submission and post-publication uses of containers, as well as several shortcomings.</p>

<p>In a nutshell,</p>

<blockquote>
  <p>“A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another.” <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></p>
</blockquote>

<p>In particular, this means that all dependencies are handled, and there should be virtually no differences across time, users’ operating system, and software implementation in reproducing the outcomes of software.</p>

<p>Containers also isolate the computation from the host system, so that no user-specific settings (stuff you have configured over the past 10 years of working on a project) are carried through into the container, up to a point. That kind of isolation can also be achieved in various ways: for the cognescenti (also called geeks), <code class="language-plaintext highlighter-rouge">chroot</code> environments on Unix systems go back to the early 1980s <sup id="fnref:chroot" role="doc-noteref"><a href="#fn:chroot" class="footnote" rel="footnote">3</a></sup>, and “virtual machines” probably go back to 1960s IBM mainframes <sup id="fnref:vm" role="doc-noteref"><a href="#fn:vm" class="footnote" rel="footnote">4</a></sup>)</p>

<h2 id="containers-and-reproducibility">Containers and reproducibility</h2>

<p>Containers can, but do not necessarily contribute to reproducibility and replicability. For an excellent introduction, see Boettinger (2015) <sup id="fnref:intro" role="doc-noteref"><a href="#fn:intro" class="footnote" rel="footnote">5</a></sup>. Once created, containers can (should) reliably reproduce the context and output they were designed to handle. Because containers typically use a plain-text script for their creation (so-called <code class="language-plaintext highlighter-rouge">Dockerfile</code>), they can contribute to transparency. However, containers can also be interactively created, or incorporate externally created packages, which may lead to some black-box actions that are not transparent. Thus, containers can generate reproducible output, but not be themselves reproducibly created. Furthermore, if containers rely on external resources – for instance, accessing the internet to download data from an API, or installed “latest” packages – the output generated may not be reproduced, though it may still be considered replicable.</p>

<h2 id="containers-in-computational-social-science">Containers in computational social science</h2>

<p>For the (social science) research environment, this should, in principle, handle many of the common problems that workarounds and READMEs list. In this post, we will explore several such cases, in which a computational issue was encountered, debugged leveraging both locally installed and cloud-based containers, and ultimately solved.</p>

<ul>
  <li>Run R through a container</li>
  <li>Run Intel Fortran (or another complex setup) through container</li>
  <li>Run Gurobi through container with a dynamic license</li>
  <li>The Holy Grail in Economics: Run Stata through a container</li>
</ul>

<p>The examples here are based on personal research experience as well as the experience when attempting to conduct reproducibility verifications on nearly 1,000 economics articles. They are by no means meant to be exhaustive or cover all the possible uses of containers. We should note that many of these examples are retro-actively ported to containers, and may not constitute the optimal setup. In our experience with 1,000 economics articles, as of November 2021, we have encountered only 1 (in words: <strong>one</strong>) that used any Docker in their submission to the AEA journals: Lamadon, Mogstad, and Setzler, “Imperfect Competition, Compensating Differentials and Rent Sharing in the U.S. Labor Market”,<sup id="fnref:lms" role="doc-noteref"><a href="#fn:lms" class="footnote" rel="footnote">6</a></sup> who leveraged 4 different CodeOcean compute capsules to support their analyses (we will return to CodeOcean later).</p>

<h2 id="running-r-julia-python-in-docker">Running R, Julia, Python in Docker</h2>

<p>Many of the examples one can find on the Internet sees container used in conjunction with open-source languages. For most statistical and other languages, in particular open-source languages, progress is continuous. In part what attracts researchers to these environments is the rich eco-system of add-on packages and libraries, most of which are available for free as well. However, combining versions of languages, packages, and dependencies to those packages can be a challenge. Use of these can sometimes be tedious - and not easily reproducible - because of a constantly evolving environment and very active development. Various methods exist to “pin” packages used (see <a href="https://cran.r-project.org/package=renv">renv</a>, <a href="https://cran.r-project.org/package=checkpoint">checkpoint</a> and others in R, “environments”, <a href="https://pip.pypa.io/en/stable/reference/pip_freeze/"><code class="language-plaintext highlighter-rouge">pip freeze</code></a> or <a href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#sharing-an-environment"><code class="language-plaintext highlighter-rouge">conda env export</code></a> in Python, <code class="language-plaintext highlighter-rouge">Manifest.toml</code> files and <a href="https://julia.quantecon.org/more_julia/tools_editors.html#Package-Environments">package environments</a> in Julia). These rely, of course, not just on the ability to install the right packages, but also the right base software. In some cases, it can be challenging for users to install multiple base versions simultaneously on their computers - either because they work on multiple projects on their own at different times, or in collaborations with others. This is sometimes necessitated by changes that create breaks between versions (examples include <a href="https://docs.julialang.org/en/v1.4/NEWS/#Standard-library-changes-1">changes in random number generators in Julia</a> and <a href="https://blog.revolutionanalytics.com/2020/04/r-400-is-released.html">certain breaks in R when version 4.0 was introduced</a>). Programmatic solutions for this exist, of course, but add complexity to an often complex set of programs.</p>

<p>Thankfully, that same open-source community has also provided containers that lock in some of the base software versions, facilitating the simultaneous maintenance of multiple versions of the same software. We illustrate this with an example that we have used in some reproducibility cases with R. It addresses the particular use case of having multiple versions of R, but does not pin the particular package versions. See the tutorials for  <a href="https://cran.r-project.org/package=renv">renv</a> and <a href="https://cran.r-project.org/package=checkpoint">checkpoint</a> for even finer control.</p>

<h3 id="a-really-simple-example-with-r">A Really Simple Example with R</h3>

<p>To start, we identify from instructions provided by the author both the version of R and the required packages. From the required packages, we use a standard <a href="https://github.com/AEADataEditor/docker-r-starter/blob/main/setup.R">setup program</a> and add those libraries to the list of dependencies.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">7</a></sup> We then leverage the <a href="https://hub.docker.com/u/rocker">R Docker images</a> maintained by the <a href="https://github.com/rocker-org/rocker">Rocker group</a>, and build a custom R Docker image that should have all dependencies as articulated by the authors:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Dockerfile</code>:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FROM rocker/r-ver:4.0.1

COPY setup.R .
RUN Rscript setup.R
</code></pre></div></div>
<p>That’s already all there is to creating a Docker image! Of course, it now needs to be built:<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">8</a></sup></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DOCKER_BUILDKIT=1 docker build . -t $MYHUBID/$MYIMG:$TAG
</code></pre></div></div>

<p>where I have previously configured some environment variables for ease of notation and reference:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TAG=v$(date +%F)
MYIMG=aer-9999-8888
MYHUBID=aeadataeditor
</code></pre></div></div>

<p>This locks in our R environment, at the time of building (<code class="language-plaintext highlighter-rouge">$TAG</code>). It is then straightforward to run the authors’ code, reliably, over and over again:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd path/to/code
docker run -it --rm -v $(pwd)/subdir:/code -w /code $MYHUBID/${MYIMG}:$TAG Rscript main.R
</code></pre></div></div>

<p>Note that for each project, we can specify a different R version (<code class="language-plaintext highlighter-rouge">rocker/r-ver:4.0.1</code>), and we can even, for the same project, test the reproducibility with multiple R versions, by building multiple images (we might need to refine our tagging for that to work).</p>

<p>Furthermore, if we run into reproducibility discrepancies, we can share the resulting (public) Docker image and the “very simple” instructions with the authors. In doing so, we reproducibly share the failure to reproduce. We have done so, in fact, in several cases, though we will describe that particular type of interaction in the next section, in somewhat more challenging cases.</p>

<p>All we need is Docker as a software installation on our workstation. Or: in the cloud.</p>

<h2 id="running-docker-the-cloud-way">Running Docker the Cloud way</h2>

<p>Numerous cloud computing providers facilitate running Docker. Some might call it an “app” that you are running, others may require you to boot up a Linux VM before running Docker, the mechanisms vary substantially. In many instances, you may need to worry about how to recover the results once the Docker image has finished running your code, and both data and code will likely need to be embedded in the Docker image, something not addressed here.</p>

<p>One innovation that multiple authors have recently pointed to is the July 2021 release of “Github Codespaces.” Subject to some conditions, anyone can easily run arbitrary Docker images in the cloud. We illustrate this using a <a href="https://github.com/labordynamicsinstitute/reproducibility-confidential">reproducible environment to conduct a tutorial</a> (readers might want to consult the tutorial for several other reasons as well).</p>

<p>The tutorial is programmed in R, leverages R-generated HTML slides (<code class="language-plaintext highlighter-rouge">ioslides</code>). Relevant for the point here is that the tutorial is intended to be conducted interactively. To do that, after having <a href="https://docs.github.com/en/codespaces/managing-codespaces-for-your-organization/enabling-codespaces-for-your-organization">enabled Codespaces for the organization</a>, we select and launch a codespace - essentially, a cloud-computer running our code.</p>

<p><img src="/images/github-codespaces-1.png" alt="Launching Codespaces" /></p>

<p>After choosing a size (which can go up to a 16-core/ 32GB RAM server), the system launches into a simple Linux shell, with the source git repository already checked out</p>

<p><img src="/images/github-codespaces-2.png" alt="Launching Codespaces" /></p>

<p>Docker comes into play here because we want to use a Rstudio instance in the cloud, already set up the way we need it to be. The build script does most of the original legwork for us, and once in the cloud, all we need to do is to launch the pre-configured (reproducible!) Docker instance, loaded with our libraries and code:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run \
   -e PASSWORD=testing \
   -v $WORKSPACE:/home/rstudio \
   --rm -p 8787:8787 $dockerspace/$repo
</code></pre></div></div>
<p>which we do straight from the cloud command line:</p>

<p><img src="/images/github-codespaces-3.png" alt="Launching docker" /></p>

<p>The docker command again downloads the image components from the Docker Hub, and runs the Rstudio instance:</p>

<p><img src="/images/github-codespaces-4.png" alt="Launching docker" /></p>

<p>Codespaces detects that we are running a webserver within the Docker image, and prompts us to connect to it:</p>

<p><img src="/images/github-codespaces-5.png" alt="Launching Rstudio" /></p>

<p>This is an example of reproducibility for interactive uses, but would apply in much the same way if all we wanted to do is run some R code repeatedly, or reproducibly. In fact, that is exactly what a separate functionality (Github Workflow/Actions) does to generate the slides for this particular tutorial, something left for next time (but see the <a href="https://github.com/labordynamicsinstitute/reproducibility-confidential/blob/main/.github/workflows/main.yml">workflow configuration file</a> for the tutorial). We will come back to this later.</p>

<h2 id="compiling-fortran-code-through-a-container">Compiling Fortran code through a container</h2>

<p>Compilers are the workhorses for high-performance computing, and many economists will program compute-intensive routines in Fortran, then compile and run such code. Both open-source <sup id="fnref:osfortran" role="doc-noteref"><a href="#fn:osfortran" class="footnote" rel="footnote">9</a></sup> and commercial<sup id="fnref:commfortran" role="doc-noteref"><a href="#fn:commfortran" class="footnote" rel="footnote">10</a></sup> are available. We describe two use cases for using Fortran in combination with Docker.</p>

<h3 id="ce-fortran">CE Fortran</h3>

<p>In many cases, compilers require the presence of many separate libraries, and installation is traditionally complicated. The <a href="https://www.ce-fortran.com/">CE-Fortran</a> project (“Computational Economics using Fortran”, Hans Fehr and Fabian Kindermann) trains and guides economists using open source <a href="https://gcc.gnu.org/fortran/">GNU Fortran</a>.</p>

<p><img src="/images/ce-fortran-webpage.png" alt="CE Fortran" /></p>

<p>They have traditionally provided detailed installation instructions for all three operation systems, striving to make the development environment as comparable as possible across all three. More recently, the authors have started providing a Docker image to provide a consistent environment, see <a href="https://github.com/fabiankindermann/ce-fortran/tree/main/installation/docker/docker_base">their Github page</a>.</p>

<p>Nevertheless, some of the issues cannot be fully handled in a Docker image. For instance, while the environment in the base Docker image can create images, it cannot be used to provide an IDE or for manipulating images interactively. For this purpose, the authors provide a second, much <a href="https://github.com/fabiankindermann/ce-fortran/tree/main/installation/docker/docker_vnc">larger Docker image</a> that includes a workaround (a VNC server).</p>

<h3 id="intel-fortran">Intel Fortran</h3>

<p>A second scenario is frequently encountered among the AEA’s replication packages. Many authors, particularly in macroeconomics, use Intel Fortran compilers. While installation instructions have been streamlined, they remain onerous: the most recent Windows installation instructions rely on a two installers, and have a dependency on Microsoft Visual Studio - a separate installer - which in turn has multiple additional dependencies. Furthermore, authors rarely use Makefiles, a way to compile code and address dependencies commonly used in the open source community, and only sometimes use Windows-specific Visual Studio Project files. The typical instruction, repeated dozens of times, looks like this:</p>

<p><img src="/images/README_page07.png" alt="Compiler instruction" /></p>

<p>with subsequent instructions to manually run the compiled code. Such instructions are inefficient, and potentially error prone.</p>

<h3 id="a-fortran-docker-example">A Fortran Docker Example</h3>

<p>In reproducing a recent paper, we instead opted to streamline the process, making for a more efficient reproducibility check, and also – if the authors were to adopt this process – a more efficient development process.</p>

<ol>
  <li>Using scripting tools, we extracted all of the <code class="language-plaintext highlighter-rouge">ifort</code> commands from the README PDF (34 lines)</li>
  <li>We manually inserted the relevant directories, and added code to automatically run the compiled binary.</li>
  <li>The resulting script file (<code class="language-plaintext highlighter-rouge">run_all.sh</code>) looks like this (in <code class="language-plaintext highlighter-rouge">bash</code> notation - this could also be done as a Windows <code class="language-plaintext highlighter-rouge">bat</code> file):</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Code to run models 
# Author: Lars Vilhuber
# Based on instructions in the paper's replication package
# NOTE: this should really be a Makefile!
# Capture base folder

BASE=$(pwd)

# Compiler options

IFORTOPTS=" -qopenmp"

# Figure 1A

cd $BASE/rep_agent_models/tc_model_nongrace

time ifort $IFORTOPTS rep_tc_delta_array.f90 rouwenhorst.f90 \
  -o rep_tc_delta_array.exe &amp;&amp; time ./rep_tc_delta_array.exe 

cd $BASE/rep_agent_models/tc_model_grace

time ifort $IFORTOPTS rep_tc_grace_delta_array.f90 rouwenhorst.f90 \
  -o rep_tc_grace_delta_array.exe &amp;&amp; time ./rep_tc_grace_delta_array.exe 

# and so on...
</code></pre></div></div>

<h4 id="simplicity">Simplicity</h4>

<p>Once we had the script, we used the <a href="https://hub.docker.com/r/intel/oneapi-hpckit/tags?page=1&amp;ordering=last_updated">Intel OneAPI-hpckit</a> (required 23GB of disk space, compared to the 24GB that the Windows install would have taken):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker pull intel/oneapi-hpckit:2021.2-devel-ubuntu18.04
</code></pre></div></div>

<ol>
  <li>Ran master script through the docker image
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd PATH/model_codes
docker run --rm -it -w /code \
  -v $(pwd):/code intel/oneapi-hpckit:2021.2-devel-ubuntu18.04 \
  /code/run_all.sh &gt; run_all.output.txt
</code></pre></div>    </div>
  </li>
</ol>

<p>This generated about 100 output files, without any further manual intervention. There is no separate installation process for the Intel compilers, a simple <code class="language-plaintext highlighter-rouge">docker pull</code> command allowed us to run all of the required files, within a few minutes.</p>

<h4 id="flexibility">Flexibility</h4>

<p>When one of the compile steps required a larger memory size (25GB) than our workstation had available (23GB), we simply re-ran the following three steps on a general purpose server we had never before used for this purpose (but which already had Docker installed):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git pull (URL of the reproducibility repository)
cd PATH/model_codes
docker run --rm -it -w /code \
  -v $(pwd):/code \
  intel/oneapi-hpckit:2021.2-devel-ubuntu18.04 \
  /code/run_all.sh &gt; run_all.output.txt
</code></pre></div></div>
<p>(the <code class="language-plaintext highlighter-rouge">docker pull</code> command is automatically executed by the <code class="language-plaintext highlighter-rouge">docker run</code> command if the image is not locally available).</p>

<h4 id="thoughts">Thoughts</h4>

<p>When using a container for the task of running these (fairly standard) types of structural models, we gained robustness and simplicity. Instead of a complex and manual Windows install specific to this type of project, we had a very simple way to run the author-provided code. The “transparency boundary” remains unchanged: the reliance on the proprietary (non-open source) Intel compiler, whether installed as a Windows installer, or obtained via a Intel-provided Docker image, is conceptually similar, and similarly opaque.</p>

<h2 id="running-docker-the-easy-way">Running Docker the Easy Way</h2>

<p>Of course, this may all seem overwhelming and complicated, as any new piece of software. Which is why several services are available that make this all a lot easier. These include <a href="https://codeocean.com/">CodeOcean</a>, <a href="https://wholetale.org/">WholeTale</a>, <a href="https://mybinder.org/">Binder</a>, and others (see Konkol et al, 2020,<sup id="fnref:konkol" role="doc-noteref"><a href="#fn:konkol" class="footnote" rel="footnote">11</a></sup> for a broader overview). Behind the scenes, these use containers as well, sometimes built on the fly, but also able to archive the containers, ensuring persistence of what hopefully are reproducible containers.</p>

<p>We have started to use these services to enable reproducibility verification in an environment which allows us, when the time inevitably arrives, to share the exact environment with the authors in order to debug code. In contrast with the statement “Author, please use this Docker image to reproduce the issue”, the request “Author, please click on this URL to reproduce the issue” is much simpler. Several authors have been offered both options (no RCT…), and have generally preferred the option of an online easy interface to the ability to run Docker or Singularity locally.</p>

<p>And we have started to leverage the ability to also publish these reproducible artifacts. Recent examples include Rossi (2021)<sup id="fnref:rossi" role="doc-noteref"><a href="#fn:rossi" class="footnote" rel="footnote">12</a></sup> and DellaVigna and Pope (2021)<sup id="fnref:stefano" role="doc-noteref"><a href="#fn:stefano" class="footnote" rel="footnote">13</a></sup>. In both cases, we were able to populate the <a href="https://doi.org/10.24433/CO.7940775.v1">CodeOcean</a> <a href="https://doi.org/10.24433/CO.0687784.v1">capsule</a> when we ran into reproducibility issues, sharing it (via a URL) with the authors, and solving the issue that both satisfied the AEA Data Editor, and is likely to satisfy future replicators as well.</p>

<p>We are working with the <a href="https://wholetale.org/">WholeTale</a> on similar usage scenarios, and are open to working with authors’ choices whereever those may lead.</p>

<p>One key aspect here is worthwhile highlighting. In contrast to some other online computational platforms, for instance <a href="https://colab.research.google.com/">Google Colab</a>, the ability to download (nearly) the entire reproducible environment, not just the code, and archive it, are key. That does not mean that they are automatically “fully reproducible”. They may still be missing some key elements that replicators will need to contribute, such as licenses.</p>

<h2 id="licenses">Licenses</h2>

<p>Most examples out there use open source software, not requiring licenses. This is an issue in economics, where the most common software used - Stata, Matlab - are proprietary and require licenses. Luckily, there are many ways to include licenses in Docker images at runtime, or, if using them internally within a research group, embedding licenses within the Docker image, as one would install a license in any “real” computer. The online systems mentioned above sometimes provide access to such licenses as well. We briefly illustrate first the easy, online way to incorporate licenses into container-based workflows, and then two “hard” ways.</p>

<h3 id="an-example-using-stata-licenses-and-the-easy-way">An example using Stata, licenses, and the “Easy Way”</h3>

<p>Bringing many of the issues alluded to earlier together, we have successfully leveraged this “toolkit” to improve the reproducibility and accessibility of Stata-based replication packages. Stata is used by the vast majority of economists, so being able to handle this scenario is important, but it also illustrates how licensed software can be used with containers.</p>

<p><a href="https://aeadataeditor.github.io/aea-supplement-migration/programs/aea201910-migration.html"><img src="https://github.com/AEADataEditor/aea-supplement-migration/raw/530f1e9ad8059e68815b5836db33155c990154b0/programs/figure_software_years_pct.png" alt="Stata usage at AEA journals" /></a></p>

<p>The easiest way is to use an online system that provides such access. The first to our knowledge was <a href="https://codeocean.com/">CodeOcean</a>. Simply choosing one of the configured Stata images will create a Docker image with Stata:</p>

<p><img src="/images/codeocean-choice.png" alt="Stata choice" /></p>

<h3 id="hard-to-nail-down-failure-to-compute">Hard-to-nail down failure to compute</h3>

<p>This is the environment we used to work with the authors to create the reproducible package for DellaVigna and Pope (2021). We were able to work exclusively within CodeOcean’s environment, debugging a tenacious problem that wasn’t easy to diagnose. But we also wanted to make sure that the resulting replication package is not reliant on CodeOcean’s infrastructure. The authors debugged the code on CodeOcean (yielding the <a href="https://doi.org/10.24433/CO.0687784.v1">published capsule</a>). We  then verified the <a href="https://doi.org/10.3886/E135221V1-101800">instructions to re-run the replication package</a> downloaded from CodeOcean on a personal workstation, emulating a somewhat typical economist. We  also populated the official replication package on openICPSR with the same code (<a href="https://doi.org/10.3886/E135221V1">https://doi.org/10.3886/E135221V1</a>). This is strictly speaking not necessary, since CodeOcean is a trusted repository, and assigns DOIs, but for now, we make it easier to discover this way.</p>

<p>After downloading the CodeOcean capsule (<code class="language-plaintext highlighter-rouge">57033059-76d7-422d-8301-d173e3520f07.zip</code>), or equivalently, the openICPSR deposit, the following straightforward code (mostly documented in the CodeOcean-provided <code class="language-plaintext highlighter-rouge">REPRODUCING.md</code>) reproduces the paper’s outputs perfectly:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>unzip 57033059-76d7-422d-8301-d173e3520f07.zip 
cd environment/
# Need the Stata license
cp /path/to/statalicense/stata.lic.16 stata.lic
# Build the image - note, requires CodeOcean provided image. Could be replaced with the dataeditors/stata16 image
DOCKER_BUILDKIT=1 docker build . \
  --tag 57033059-76d7-422d-8301-d173e3520f07
cd ..
# Ensure the script is runnable - this is not documented
chmod a+rx code/run 
docker run --rm   \
  --workdir /code   \
  --volume "$PWD/environment/stata.lic":/usr/local/stata/stata.lic   \
  --volume "$PWD/data":/data   \
  --volume "$PWD/code":/code   \
  --volume "$PWD/results":/results  \ 57033059-76d7-422d-8301-d173e3520f07 \
  ./run
</code></pre></div></div>

<h2 id="challenges">Challenges</h2>

<h3 id="big-data">Big data</h3>

<p>Since a container is meant to package up all necessary dependencies, it would seem logical that one could include all data. However, this breaks down when the data are large, even before getting into “big data” territory. The typical Docker image is no larger than 2-3 GB. Thus, the issues that plague  reproducibility when data are large - delays in downloading or streaming data, availability of local space - are not solved by containers. That being said, satisfying the software dependencies is a first step in making sure that reproducibility can be achieved. Thus, a variant of the above way to run a Docker image could also be used in the presence of big data, by mounting the local storage directory for the data:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run --rm   \
  --workdir /code   \
  --volume "$PWD/data":/data   \
  --volume "/path/to/BIG/DATA:/bigdata \
  --volume "$PWD/code":/code   \
  --volume "$PWD/results":/results  \ 
  researcherhub/papercontainer \
  ./run
</code></pre></div></div>

<h3 id="licenses-not-provided">Licenses not provided</h3>

<p>Most of the “easy” systems are easy because they can accomodate a limited set of customizations. For instance, one can specify some post-install scripts on various platforms, but not choose an unsupported software image. But when the software requires additional licenses, a tension arises between publishing the successfully run image with an embedded license, and providing a template implementation that requires provision of a license.</p>

<p>Mathworks has gone the latter route, providing a <a href="https://hub.docker.com/r/mathworks/matlab">Matlab Docker image</a> without a license, and then providing instructions on how to provision the container with a valid license, for instance within a university’s internal network with a network server. Internally, WholeTale and CodeOcean use a similar mechanism behind the scenes.</p>

<p>Stata does not provide Docker image, but has allowed the AEA Data Editor to provide <a href="https://hub.docker.com/u/dataeditors">license-less Docker images for Stata</a>. The <a href="https://github.com/AEADataEditor/docker-stata">instructions provided</a> identify various ways a license can be provisioned to the image, so that code can be run:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run -it --rm \
  -v ${STATALIC}:/usr/local/stata/stata.lic \
  -v $(pwd)/code:/code \
  -v $(pwd)/data:/data \
  -v $(pwd)/results:/results \
  $MYHUBID/${MYSTATAIMG}:${TAG}
</code></pre></div></div>

<p>In effect, users can simply use their own Stata license to enable a Stata Docker image. Again, WholeTale and CodeOcean use a similar mechanism behind the scenes, but the fact that any Stata user can re-execute such a Docker image with a valid Stata license is no more constraining that having installed Stata on their own computer.</p>

<p>In other circumstances, expiring licenses may be used. In a case where we needed to install <a href="https://www.gurobi.com/academia/academic-program-and-licenses/">Gurobi</a> together with R, we used a new feature provided by Gurobi to provide “<a href="https://www.gurobi.com/web-license-service/">web licenses</a>.” These can be disabled from a dashboard, and naturally expire after a while. Thus, our CodeOcean “postInstall” script installed Gurobi into a R container, then hard-coded a license key:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget -v https://packages.gurobi.com/${GRB_SHORT_VERSION}/gurobi${GRB_VERSION}_linux64.tar.gz \
    &amp;&amp; tar -xvf gurobi${GRB_VERSION}_linux64.tar.gz  \
    &amp;&amp; rm -f gurobi${GRB_VERSION}_linux64.tar.gz \
    &amp;&amp; mv -f gurobi* gurobi \
    &amp;&amp; rm -rf gurobi/linux64/docs


cd /opt/gurobi/linux64
#run the setup
python3.7 setup.py install

# Add the license key
# For replication purposes, this will need to be re-initialized, as post-publication, this key was disabled.
# You will need to provide your own.
echo "
WLSACCESSID=96388c95-2a7f-4195-88af-b167b077c019
WLSSECRET=ef818954-18ed-43f5-84b0-ace17641fd18
LICENSEID=6521234
" &gt; /opt/gurobi/gurobi.lic
</code></pre></div></div>

<p>Once published, simply disabling the key on the Gurobi dashboard would prevent any unauthorized use of the license. Alternatively, of course, the method used for the Stata license above would also work outside of the CodeOcean environment, by using</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run -it --rm \
  -v gurobi.lic:/opt/gurobi/gurobi.lic \
  -v $(pwd)/code:/code \
  -v $(pwd)/data:/data \
  -v $(pwd)/results:/results \
  $MYHUBID/${MYGUROBIIMG}:${TAG}
</code></pre></div></div>
<p>Thus, generically, licensed software can very well be used when the proprietary software provider allows for redistribution of the binary portion of the software in the form of “opaque” containers; however, in many circumstances, the “easy” online providers of such container-based services can make it non-trivial to implement.</p>

<h3 id="complex-interactions-between-software">Complex interactions between software</h3>

<p>Finally, as one example where limitations are hard to address ex-post, we highlight an example where researchers called a separately compiled Fortran binary from within Matlab. While each software could easily be run in its own container, it becomes non-trivial (but not impossible) to use multiple containers in this way.</p>

<p>The solution, as evidenced by the Gurobi example earlier, consists in installing one software into a container provided by the other. This, however, may lose the advantages of using pre-configured containers that avoid complex installation procedures, as in the case of Matlab and Intel compilers. An alternative (not tested) might consist in leveraging <a href="https://docs.docker.com/develop/develop-images/multistage-build/">multi-stage builds</a>, where entire portions are copied from one container into another. This is beyond the scope of the “easy” web-based solutions (though it may be on their development plan). However, precisely because a knowledgeable researcher can handle the (now much more complex) container creation, future users may not have to. By publishing the associated <code class="language-plaintext highlighter-rouge">Dockerfiles</code>, <a href="https://github.com/AEADataEditor/docker-r-starter/blob/main/Dockerfile">simple</a> or more <a href="https://github.com/AEADataEditor/docker-r-gurobi/blob/main/Dockerfile">complex</a>, future users do not need to reinvent the wheel - one of the purposes of the transparency that reproducibility fosters.</p>

<h3 id="continuous-integration">Continuous integration</h3>

<p>Containers are also a tool for continuous integration - the software engineering best practice to test software at every step - but which can also be used to streamline research analyses. Consider the scenario where all data is available in a researcher’s Git repository (because of course, the researcher is using a Git repository). Containers can then be leveraged to create output - a research article, preliminary analyses, or a number of webpages. For instance, many researchers now use R in combination with Markdown to create “dynamic documents”. The (perenially incomplete) <a href="https://labordynamicsinstitute.github.io/replicability-training-curriculum/">training manual for our undergraduate replicators</a> is “built” this way, using the great <a href="https://pkgs.rstudio.com/bookdown/"><code class="language-plaintext highlighter-rouge">bookdown</code> package</a> by Yihui Xie, using a simple preconfigured container:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     - name: Run docker for R 
        uses: docker://larsvilhuber/ideahandbook:latest
        with:
          args: "/github/workspace/_build.sh publish"
</code></pre></div></div>

<p>(see the <a href="https://github.com/labordynamicsinstitute/replicability-training-curriculum/blob/master/.github/workflows/main.yml">Github Action workflow file</a> for full details)</p>

<h3 id="graphical-utilities">Graphical utilities</h3>

<p>Some of the “easy” online systems do not provide the native coding environment that many users are used to, for instance the Matlab or Stata desktop applications. This makes it harder, in fact, for such researchers to adapt to these tools. We regularly observe code or instructions that use visual inspection of the results, or leverage other features only available in a full graphical environment. This is less a concern for more recent (and typically open source) software, such as R (availability of Rstudio as a web service), Python, and Julia (Jupyter notebooks). However, WholeTale is trialling (with assistance from us) a combination of reproducible “tale” combined with a graphical user interface for Stata. The <a href="https://hub.docker.com/r/mathworks/matlab">Matlab Docker image</a> provides a graphical interface, as does one of the <a href="https://github.com/fabiankindermann/ce-fortran/tree/main/installation/docker/docker_vnc">CE-Fortran docker images</a>, so these are not fundamentally problems.</p>

<h2 id="preliminary-conclusion">(Preliminary) Conclusion</h2>

<p>Containers provide a way to share computational environments in an efficient way, to make such environments robust to changes in the underlying software, and to publish the fully transparent methods that lead to such containers. They are, however, underutilized in economics replication packages and by economics researchers. This document has provided a few scenarios that illustrate cases where the use of containers can help improve reproducibility.</p>

<h2 id="resources">Resources</h2>

<p>So is this all rocket science? While I’m sure that the rocket scientists use containers, it isn’t really that complicated. Here is a (almost surely incomplete) list of a few resources to get you started:</p>

<h3 id="economics-articles-and-replication-packages-using-docker">Economics Articles and Replication Packages using Docker</h3>

<ul>
  <li>Rossi (<a href="https://doi.org/10.1257/jel.20201479">JEL, 2021</a>): “Forecasting in the presence of instabilities: How do we know whether models predict”<sup id="fnref:rossi:1" role="doc-noteref"><a href="#fn:rossi" class="footnote" rel="footnote">12</a></sup></li>
  <li>DellaVigna and Pope (<a href="https://doi.org/10.1257/mic.20200129">American Economic Journal: Microeconomics, 2022</a>) “Stability of Experimental Results: Forecasts and Evidence”<sup id="fnref:stefano:1" role="doc-noteref"><a href="#fn:stefano" class="footnote" rel="footnote">13</a></sup></li>
  <li>Bonhomme, Lamadon, and Manresa (<a href="https://doi.org/10.3982/ECTA15722">Econometrica, 2019</a>): “A distributional framework for matched employer-employee data”, <a href="https://github.com/tlamadon/blm-replicate">Github repository</a></li>
  <li>Sergio Firpo, Vitor Possebom. 2018. “Synthetic Control Method: Inference, Sensitivity Analysis and Confidence Sets” Journal of Causal Inference 6.2, <a href="https://doi.org/10.1515/jci-2016-0026">https://doi.org/10.1515/jci-2016-0026</a>. <a href="https://doi.org/10.24433/CO.23bd238f-38c5-4b3e-82f4-3a1624fd8a33">Compute Capsule at CodeOcean</a></li>
  <li>Matias D. Cattaneo, Nicolás Idrobo, Rocío Titiunik. 2018.  “A Practical Introduction to Regression Discontinuity Designs: Volume I” <a href="https://doi.org/10.24433/CO.263b2a1e-bbc1-45c9-af03-23ac11032950">Compute Capsule at CodeOcean</a></li>
</ul>

<h3 id="tutorials">Tutorials</h3>

<ul>
  <li><a href="https://raw.githack.com/uo-ec607/lectures/master/13-docker/13-docker.html#1">Grant McDermott’s EC 607 graduate course, Docker lesson</a></li>
  <li><a href="https://carpentries-incubator.github.io/docker-introduction/index.html">Carpentries tutorial on Docker</a></li>
  <li>Installing Docker on a <em>managed</em> Windows system can be challenging, and my poor colleagues Michael Darisse and Leonel  Borja Plaza have suffered through it for you to bring you <a href="https://github.com/labordynamicsinstitute/replicability-training/blob/master/Docker_Windows.md">this tutorial</a>.
    <ul>
      <li>Installing Docker on a Linux system, on the other hand, can be as simple as <code class="language-plaintext highlighter-rouge">yum install docker</code>.</li>
      <li>The command line can help on  Mac as well: <a href="https://www.cprime.com/resources/blog/docker-on-mac-with-homebrew-a-step-by-step-tutorial/"><code class="language-plaintext highlighter-rouge">brew install docker</code></a>.</li>
    </ul>
  </li>
</ul>

<h3 id="examples-and-images">Examples and Images</h3>

<ul>
  <li><a href="https://github.com/AEADataEditor/docker-stata">Stata as Docker</a></li>
  <li><a href="https://github.com/AEADataEditor/docker-r-gurobi">R and Gurobi as Docker</a></li>
  <li><a href="https://hub.docker.com/r/mathworks/matlab">Matlab Docker image</a></li>
  <li><a href="https://www.rocker-project.org/">Rocker project</a></li>
  <li><a href="https://hub.docker.com/r/intel/oneapi-hpckit/tags?page=1&amp;ordering=last_updated">Intel OneAPI-hpckit</a></li>
</ul>

<h3 id="tools">Tools</h3>

<h4 id="r-centric">R-centric</h4>

<ul>
  <li><a href="https://o2r.info/containerit/">containerit</a></li>
  <li><a href="https://www.rocker-project.org/">Rocker project</a></li>
  <li><a href="https://dirk.eddelbuettel.com/papers/cologneRUG2020.pdf">Dirk Eddelbuettel’s tutorial</a></li>
</ul>

<h4 id="git-centric">Git-centric</h4>

<ul>
  <li><a href="https://repo2docker.readthedocs.io/en/latest/">repo2docker</a></li>
  <li><a href="https://docs.github.com/en/codespaces/managing-codespaces-for-your-organization/enabling-codespaces-for-your-organization">Github Codespaces</a></li>
</ul>

<h3 id="services">Services</h3>

<p>These are the services listed in Konkol et (2020)<sup id="fnref:konkol:1" role="doc-noteref"><a href="#fn:konkol" class="footnote" rel="footnote">11</a></sup> that use Docker</p>

<ul>
  <li><a href="https://codeocean.com">CodeOcean</a></li>
  <li><a href="https://mybinder.org/">Binder</a></li>
  <li><a href="https://wholetale.org/">WholeTale</a></li>
</ul>

<p>as well as more recent</p>

<ul>
  <li><a href="https://docs.github.com/en/codespaces/managing-codespaces-for-your-organization/enabling-codespaces-for-your-organization">Github Codespaces</a></li>
</ul>

<p>and</p>

<ul>
  <li><a href="https://gigantum.com/">Gigantum</a> (not tested)</li>
</ul>

<p>as well as many cloud service providers.</p>

<h2 id="disclosures">Disclosures</h2>

<p>We received a generous compute and storage quota from <a href="https://codeocean.com/">CodeOcean</a>, a free license to use Stata 17 for one year in cloud applications from <a href="https://stata.com">Stata</a>, and a subaward on NSF grant <a href="https://nsf.gov/awardsearch/showAward?AWD_ID=1541450&amp;HistoricalAwards=false">1541450</a> “<em>CC*DNI DIBBS: Merging Science and Cyberinfrastructure Pathways: The Whole Tale</em>” from the University of Illinois to evaluate the platform for the purpose of reproducibility verification. None of the sponsors have reviewed this preliminary assessment, or have had influence on any of the conclusions of this document. <a href="https://codeocean.com/">CodeOcean</a> currently offers academic users a certain number of monthly free compute hours. <a href="https://wholetale.org/">WholeTale</a> is free to use, though the Stata desktop functionality is not yet publicly available as of the writing of this document in November 2021.</p>

<h2 id="notes">Notes</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Wikipedia. 2021. “List of Linux containers.” <a href="hhttps://en.wikipedia.org/w/index.php?title=List_of_Linux_containers&amp;oldid=1015376890">wikipedia.org/wiki/List_of_Linux_containers</a>, accessed on 2021-07-07. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Docker.com. 2021. “What is a Container.” <a href="https://web.archive.org/web/20210609145942/https://www.docker.com/resources/what-container">docker.com/resources/what-container</a>, accessed on 2021-07-07. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:chroot" role="doc-endnote">
      <p>Wikipedia. 2021a. “chroot”. <a href="https://en.wikipedia.org/w/index.php?title=Chroot&amp;oldid=1044767727">https://en.wikipedia.org/w/index.php?title=Chroot&amp;oldid=1044767727</a>, accessed 2021-11-19. <a href="#fnref:chroot" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:vm" role="doc-endnote">
      <p>Wikipedia. 2021b. “Hardware virtualization”. <a href="https://en.wikipedia.org/w/index.php?title=Hardware_virtualization&amp;oldid=1053629506">https://en.wikipedia.org/w/index.php?title=Hardware_virtualization&amp;oldid=1053629506</a>, accessed 2021-11-19 <a href="#fnref:vm" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:intro" role="doc-endnote">
      <p>Boettiger, Carl. “An Introduction to Docker for Reproducible Research.” ACM SIGOPS Operating Systems Review 49, no. 1 (January 20, 2015): 71–79. <a href="https://doi.org/10.1145/2723872.2723882">https://doi.org/10.1145/2723872.2723882</a>. <a href="#fnref:intro" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:lms" role="doc-endnote">
      <p>Lamadon, Thibaut, Magne Mogstad, and Bradley Setzler. 2022. “<a href="https://www.aeaweb.org/articles?id=10.1257/aer.20190790">Imperfect Competition, Compensating Differentials and Rent Sharing in the U.S. Labor Market.</a>” <em>American Economic Review</em> with <a href="https://github.com/setzler/LMS">Github repository</a> and <a href="https://doi.org/10.24433/CO.7147919.v1">1</a> <a href="https://doi.org/10.24433/CO.3047157.v1">2</a> <a href="https://doi.org/10.24433/CO.4775581.v1">3</a> <a href="https://doi.org/10.24433/CO.3648033.v1">4</a> compute capsules. <a href="#fnref:lms" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Even without using the <code class="language-plaintext highlighter-rouge">checkpoint</code> package, we might use the <a href="https://cran.microsoft.com/snapshot/">MRAN snapshot server</a>, but a faster method is provided by the binary packages provided by the <a href="https://packagemanager.rstudio.com/">Rstudio Public Package Manager</a> used by the Rocker images. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>For additional steps, and complete instructions, see <a href="https://github.com/AEADataEditor/docker-r-starter">github.com/AEADataEditor/docker-r-starter</a> <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:osfortran" role="doc-endnote">
      <p><a href="https://gcc.gnu.org/fortran/">GNU Fortran</a> and various LLVM-based Fortran front-ends are available, see a list at <a href="https://fortran-lang.org/compilers/">fortran-lang.org/compilers/</a>. <a href="#fnref:osfortran" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:commfortran" role="doc-endnote">
      <p><a href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/all-toolkits.html">Intel</a> and <a href="https://www.nag.com/nag-compiler">NAG</a> are popular. <a href="#fnref:commfortran" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:konkol" role="doc-endnote">
      <p>Konkol, Markus, Daniel Nüst, and Laura Goulier. 2020. “Publishing Computational Research - a Review of Infrastructures for Reproducible and Transparent Scholarly Communication.” Research Integrity and Peer Review 5, no. 1 (July 14, 2020): 10. <a href="https://doi.org/10.1186/s41073-020-00095-y">https://doi.org/10.1186/s41073-020-00095-y</a>. <a href="#fnref:konkol" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:konkol:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:rossi" role="doc-endnote">
      <p>Rossi, Barbara. 2021. “Compute Capsule for: Forecasting in the presence of instabilities: How do we know whether models predict [Source Code].” <em>CodeOcean</em>. <a href="https://doi.org/10.24433/CO.7940775.v1">https://doi.org/10.24433/CO.7940775.v1</a>, which accompanies her  article in the Journal of Economic Literature (<a href="https://doi.org/10.1257/jel.20201479">Rossi, 2021</a>), and which is also archived in the more traditional location as Rossi, Barbara. 2021. “Data and Code for: Forecasting in the Presence of Instabilities.” <em>American Economic Association</em> [publisher], <em>Inter-university Consortium for Political and Social Research</em> [distributor]. <a href="https://doi.org/10.3886/E147225V1">https://doi.org/10.3886/E147225V1</a> <a href="#fnref:rossi" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:rossi:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:stefano" role="doc-endnote">
      <p>DellaVigna, Stefano and Devin Pope. 2021. “Compute Capsule for: Stability of Experimental Results: Forecasts and Evidence” [Source Code]. <em>CodeOcean</em>. https://doi.org/10.24433/CO.0687784.v1, which accompanies a <a href="https://doi.org/10.1257/mic.20200129">2022 article in American Economic Journal: Microeconomics</a>, and which is also archived in the more traditional location as DellaVigna, Stefano, and Devin Pope. 2021. “Data and Code for: Stability of Experimental Results: Forecasts and Evidence.” <em>American Economic Association</em> [publisher], <em>Inter-university Consortium for Political and Social Research</em> [distributor]. https://doi.org/10.3886/E135221V1 <a href="#fnref:stefano" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:stefano:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
  </ol>
</div>]]></content><author><name>AEA Data Editor</name></author><category term="FAQ" /><category term="Twitter" /><category term="Docker" /><category term="Code" /><summary type="html"><![CDATA[In reproducibility verification, a common scenario is the author response “but-it-works-on-my-machine”. Finding common environments is important in such situations, to demonstrate that the error does arise, reproducibly, but also to share with the author the exact environment so that the issue can be fixed. Shipping around laptops probably isn’t the right solution. We illustrate how we addressed some of those cases using container technology throughout this post.]]></summary></entry><entry><title type="html">How to prepare replication packages for papers that used confidential data</title><link href="https://aeadataeditor.github.io/posts/2021-11-08-replication-pkg-confidential" rel="alternate" type="text/html" title="How to prepare replication packages for papers that used confidential data" /><published>2021-11-08T00:00:00-05:00</published><updated>2021-11-08T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/replication-pkg-confidential</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-11-08-replication-pkg-confidential"><![CDATA[<p>On a tangent: we get this question regularly - how to prepare replication packages for papers that used confidential data (here: by statistical agencies). A really <a href="https://twitter.com/AeaData/status/1457815800438562828">short thread</a>.</p>

<!-- more -->

<p><img src="/images/img-2021-11-08-1.png" alt="inquiry" /></p>

<p>The very general answer is: The guidance is the same as for any other paper, including with public data:</p>

<blockquote>
  <p>describe where the data came from, describe how others can get the data, provide all the code, describe how to run code, create README for it all.</p>
</blockquote>

<p>The only part that’s different is that getting access to the data WAS complicated for you, and MIGHT be a tad complicated/long/costly/impossible for others. Details, details…</p>

<p>But concretely, here are a few pointers.</p>

<ol>
  <li>First, start with our <a href="https://social-science-data-editors.github.io/template_README/">fabulous template README</a>. Really, it helps! Available at <a href="https://social-science-data-editors.github.io/template_README/">https://social-science-data-editors.github.io/template_README/</a></li>
</ol>

<p><a href="https://social-science-data-editors.github.io/template_README/"><img src="/images/img-2021-11-08-2.png" alt="README" /></a></p>

<ol>
  <li>In order to describe data availability, split into two:
    <ul>
      <li>how did YOU get access to the data, and</li>
      <li>how can OTHERS get access to the same data.</li>
      <li>The two are not always the same, but are both relevant.</li>
    </ul>
  </li>
</ol>

<p>Examples include <a href="https://social-science-data-editors.github.io/guidance/DCAS_Restricted_data.html#us-census-bureau-and-fsrdc">this excellent description</a> from a paper by <a href="https://faculty.tuck.dartmouth.edu/teresa-fort/">Teresa Fort</a> (<a href="https://twitter.com/Tfpiasecki">@Tfpiasecki</a>). Or <a href="https://social-science-data-editors.github.io/guidance/Requested_information_dcas.html#example-for-confidential-data">this description</a> by Fadlon and Nielsen about Danish data</p>

<p>Note: That’s for the data which you <em>cannot</em> share - because it is not yours to share. In general, the statistical agencies, or other providers, control access. You, the author, can only share information about <em>how</em> to access.</p>

<p>Furthermore,  you should also make an archive <em>WITHIN</em> the secure computing facility - of anything that cannot be shared, to the extent permissible, and as long as possible. And then provide information about it in the README.</p>

<ol>
  <li>Code: <strong>All</strong> code needs to be provided - no exceptions! Redactions for security/privacy are OK. Requesting code is standard practice in most secure computing facilities, but might take some time, so do it as soon as possible if you have not already done so.</li>
</ol>

<p>In the unlikely event that you get push back from whatever agency provided you with the data, contact your favorite data editor.</p>

<ol>
  <li>
    <p>All public use data you might have introduced to the secure computing facility are expected to be provided in the replication package, including where they came from. You probably had to describe the provenance anyway in order to import them (most secure computing facilities, such as the US FSRDC or the Canadian CRDCN, require such documentation).</p>
  </li>
  <li>
    <p>Do not forget to cite data! See our <a href="https://social-science-data-editors.github.io/guidance/Data_citation_guidance.html">Guidance on Data Citation</a></p>
  </li>
</ol>

<p>And if you have questions, contact us!</p>]]></content><author><name>AEA Data Editor</name></author><category term="restricted-access" /><category term="administrative" /><category term="replication package" /><summary type="html"><![CDATA[On a tangent: we get this question regularly - how to prepare replication packages for papers that used confidential data (here: by statistical agencies). A really short thread.]]></summary></entry></feed>