<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="https://aeadataeditor.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://aeadataeditor.github.io/" rel="alternate" type="text/html" /><updated>2023-01-12T11:23:39-05:00</updated><id>https://aeadataeditor.github.io/feed.xml</id><title type="html">Office of the AEA Data Editor</title><subtitle>(current: Lars Vilhuber)</subtitle><author><name>AEA Data Editor</name></author><entry><title type="html">Launching DCAS</title><link href="https://aeadataeditor.github.io/posts/2022-12-15-launching-dcas" rel="alternate" type="text/html" title="Launching DCAS" /><published>2022-12-15T00:00:00-05:00</published><updated>2022-12-15T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/launching-dcas</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2022-12-15-launching-dcas"><![CDATA[<p><img src="https://datacodestandard.org/assets/img/logo-800.png" alt="DCAS Logo" />
The data editors of the journals] of the <a href="https://www.aeaweb.org/journals">American Economic Association</a><sup id="fnref:aea" role="doc-noteref"><a href="#fn:aea" class="footnote" rel="footnote">1</a></sup>, of the <a href="https://res.org.uk/journals/">Royal Economic Society</a><sup id="fnref:res" role="doc-noteref"><a href="#fn:res" class="footnote" rel="footnote">2</a></sup>, the <a href="https://www.restud.com/">Review of Economic Studies</a>,  the <a href="https://www.economics.ca/cpages/cje-home">Canadian Journal of Economics</a>, and <a href="https://weai.org/view/EI">Economic Inquiry</a> have joined forces  to proudly launch <strong>DCAS</strong>, the <a href="https://datacodestandard.org/">Data and Code Availability Standard</a>. This set of rules regarding what constitutes an appropriate data and code replication package will help authors comply with journals’ data and code availability policies. DCAS provides a standard, meant to make compliance easier by setting common requirements across all participating journals, and to help journals create and align their data and code availability policy.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:aea" role="doc-endnote">
      <p>The journals of the American Economic Association are the American Economic Review, AER: Insights, and the American Economic Journal: Applied Economics, Economic Policy, Macroeconomics, and Microeconomics. <a href="#fnref:aea" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:res" role="doc-endnote">
      <p>The journals of the Royal Economic Society are the Econometrics Journal and the Economic Journal. <a href="#fnref:res" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>AEA Data Editor</name></author><category term="standards" /><category term="reproducibility" /><category term="provenance" /><summary type="html"><![CDATA[The data editors of the journals] of the American Economic Association1, of the Royal Economic Society2, the Review of Economic Studies, the Canadian Journal of Economics, and Economic Inquiry have joined forces to proudly launch DCAS, the Data and Code Availability Standard. This set of rules regarding what constitutes an appropriate data and code replication package will help authors comply with journals’ data and code availability policies. DCAS provides a standard, meant to make compliance easier by setting common requirements across all participating journals, and to help journals create and align their data and code availability policy. The journals of the American Economic Association are the American Economic Review, AER: Insights, and the American Economic Journal: Applied Economics, Economic Policy, Macroeconomics, and Microeconomics. &#8617; The journals of the Royal Economic Society are the Econometrics Journal and the Economic Journal. &#8617;]]></summary></entry><entry><title type="html">What is this LICENSE thing</title><link href="https://aeadataeditor.github.io/posts/2022-11-16-where-are-the-terms-of-use" rel="alternate" type="text/html" title="What is this LICENSE thing" /><published>2022-11-16T00:00:00-05:00</published><updated>2022-11-16T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/where-are-the-terms-of-use</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2022-11-16-where-are-the-terms-of-use"><![CDATA[<p>The <a href="https://social-science-data-editors.github.io/template_README/">template README</a> required by various econ journals asks for a statement about the rights to RE-distribute data. Many economists are confused by this: “<em>But the data is publicly available.</em>” Let me try to disentangle that somewhat.</p>

<!-- more -->

<h2 id="the-statement-about-rights">The statement about rights</h2>

<p>The statement says</p>

<blockquote>
  <p>I certify that the author(s) of the manuscript have documented 
permission to redistribute/publish the data contained within this 
replication package. Appropriate permission are documented in the 
LICENSE.txt file.</p>
</blockquote>

<p>Two questions arise: what does this mean, and what is an author supposed to do with the LICENSE.txt file? And then of course, how to cite it all.</p>

<h3 id="questions-and-some-answers">Questions and some answers</h3>

<p>Here are a few questions that arise</p>

<blockquote>
  <p>Do you require licensing information for all the data that we are using, or just the specific data that is provided in the replication package?</p>
</blockquote>

<p>Many econ papers use data from multiple sources, including data that are clearly confidential. Some data sources are not confidential, but are subject to copyright or licensing agreements. The replication package should ONLY contain data that can be redistributed, and the statement ONLY pertains to such data. It does not pertain to data not included within the replication package.</p>

<p>Of course, a good chunk of the README is spent describing ALL the data sources, including the confidential ones, the non-confidential ones that are copyrighted, the non-confidential ones that are proprietary, or otherwise subject to redistribution restrictions. ALL data provenance must be described, sufficient for a replicator to start from scratch, ignoring even the data provided within the replication package. That description should contain the licensing information for every dataset as well, at least in summary. It should list pertinent conditions and restrictions, for instance: application process, required residency or citizenship, etc. The LICENSE.txt is more likely to contain a long text in legalese, the formal permission to use the data that is in fact <em>included</em> in the package.</p>

<blockquote>
  <p>Why can’t I redistribute this data, since it is publicly available?</p>
</blockquote>

<p>I’ll take the IPUMS CPS and the S&amp;P 500 as an example.</p>

<p>“Publicly available” does not mean that you have the rights to distribute. For instance, you can use the <a href="https://fred.stlouisfed.org/series/SP500">S&amp;P 500 data distributed by FRED</a>, but you are not allowed to re-distribute that data, as noted on the page there. You would describe that in the README, but the license would not be in the LICENSE.txt, because you are not, in fact, including the data!</p>

<p>Turning to the CPS: When CPS data is pulled directly from the <a href="https://www.census.gov/programs-surveys/cps.html">US Census Bureau website</a>, it is in the “public domain,” i.e., not subject to copyright (Note that this is not clear from the Census Bureau’s website, which simply assumes that you know that! Check the <a href="https://www.usa.gov/government-works">USA.gov</a> website for an explanation.)</p>

<p>But when you obtain it through other sources (<a href="https://ceprdata.org/">CEPR</a>, <a href="https://www.epi.org/data/">EPI</a>, <a href="https://www.ipums.org/projects/ipums-cps">IPUMS</a>), you have to read the terms of use, since by re-packaging the data, the <strong>files</strong> containing the data​ are subject to copyright by the redistributor… .</p>

<p>If you are using the IPUMS data, the terms of use describe what you can do with the data: <a href="https://www.ipums.org/about/terms">https://www.ipums.org/about/terms</a>. As it turns out, you can​ redistribute an extract from their database, and that​ is what you should list in the LICENSE.txt.</p>

<p>Note that other licenses are “sticky” - if you obtain data that is under a <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a> (Creative Commons) license, then you can do with the data what you want - but you must include the CC-BY license and the original source attribution. In essence, that part of your data is also under a CC-BY license.</p>

<blockquote>
  <p>What goes into the LICENSE.txt?</p>
</blockquote>

<p><img src="/images/openicpsr-license.png" alt="LICENSE txt image" /></p>

<p>This is straightforward if you have a single source. It should state the permissions and conditions that are attached to that file. If the data you obtained has a LICENSE.txt (some do), then simply include that with your deposit. Licenses can be long - they are written in legalese, because they are, in fact, legal permission to do something with the data.</p>

<p>If you created or collected the primary data yourself, you define the LICENSE. By default, deposits on openICPSR have a CC-BY license. We have a small discussion of how to choose licenses at the <a href="https://aeadataeditor.github.io/aea-de-guidance/Licensing_guidance">AEA Data Editor’s website</a> and the <a href="https://social-science-data-editors.github.io/guidance/Licensing_guidance.html">Social Science Data Editors’ website</a>.</p>

<p>If you have multiple data sources, it becomes a bit more complicated. The LICENSE.txt can be a simple collation of the various terms of use/ licenses/etc. So you could have:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>For IPUMS CPS files, IPUMS' Standard Redistribution Terms 
apply (https://www.ipums.org/about/terms#redistribution)

    You will not redistribute the data without permission. You may 
    publish a subset of the data to meet journal requirements for 
    accessing data related to a particular publication. Contact us for
    permission for any other redistribution; we will consider requests
    for free and commercial redistribution. 

Applies to: AHTUS, ATUS, CPS, GeoMarker, HigherEd, IHGIS, MEPS, MTUS, NHGIS, NHIS

For UNCTAD TRAINS data:

The TRAINS Terms of Use at https://trainsonline.unctad.org/disclaimer state that users

   are not allowed to disseminate the data or parts of the 
   database in other dissemination tools unless written 
   permission is given by the Chief of UNCTAD's Trade 
   Information Section, Trade Analysis Branch, Division on 
   International Goods and Commodities. 

We have obtained such permission via email correspondence on 16 November 2022. 
</code></pre></div></div>

<blockquote>
  <p>OK, so how do I cite the data?</p>
</blockquote>

<p>Thank you for that question, since most researchers in economics do NOT cite the data. See this <a href="https://social-science-data-editors.github.io/guidance/addtl-data-citation-guidance.html">extensive discussion</a> over on the Social Science Data Editor website, consult the <a href="https://www.aeaweb.org/journals/policies/sample-references">AEA Style Reference</a>, and remember that not all data distributors provide suggested citations that satisfy the <a href="https://force11.org/info/joint-declaration-of-data-citation-principles-final/">Data Citation Principles</a>. If they ask you to cite a working paper, do so, but <strong>also</strong> cite the data correctly.</p>

<blockquote>
  <p>Most of this data was collected in 2016, but the <a href="https://www.ahtusdata.org/ahtus/citation.shtml">IPUMS AHTUS data citation page</a> only lists the 2018 version. I am unable to find a historic example of this specific citation.</p>
</blockquote>

<p>IPUMS doesn’t make it easy, I know.  There is a not-so-obvious list of versions of the data at this URL: <a href="https://www.ipums.org/projects/ipums-time-use">https://www.ipums.org/projects/ipums-time-use</a>. The <a href="https://www.ahtusdata.org/ahtus-action/revisions">IPUMS Time Use Revision history page</a> does NOT list the DOIs for the various version. So as far as I can deduce from that, you would have used V1.0 of the AHTUS data, which has DOI <strong>10.18128/D061.V1.0</strong>. You can use <a href="https://citation.crosscite.org/">https://citation.crosscite.org/</a>, or simply adapt their suggested citation accordingly.</p>

<p>Data providers have not all adapted to a world where data citations are ubiquitious, or should be. Sometimes it takes a little extra work.</p>

<p>Note that data citations should appear both in the manuscript (upon first mention of the data) and in the README (properly formatted as in the manuscript).</p>]]></content><author><name>AEA Data Editor</name></author><category term="license" /><category term="terms of use" /><category term="copyright" /><category term="reproducibility" /><category term="provenance" /><summary type="html"><![CDATA[The template README required by various econ journals asks for a statement about the rights to RE-distribute data. Many economists are confused by this: “But the data is publicly available.” Let me try to disentangle that somewhat.]]></summary></entry><entry><title type="html">A short example of how to update a replication package</title><link href="https://aeadataeditor.github.io/posts/2022-11-09-updating-post-publication" rel="alternate" type="text/html" title="A short example of how to update a replication package" /><published>2022-11-09T00:00:00-05:00</published><updated>2022-11-09T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/updating_post_publication</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2022-11-09-updating-post-publication"><![CDATA[<p>The AEA Data and Code Availability does not just require that authors publish a replication package - it also encourages authors to improve upon the replication package. Here is an example.</p>

<!-- more -->

<blockquote>
  <p>[NOTE] I am posting about this update with permission by the author.</p>
</blockquote>

<h3 id="links">Links</h3>

<ul>
  <li><a href="https://www.aeaweb.org/journals/policies/data-code">Data and Code Availability Policy</a></li>
  <li><a href="https://www.aeaweb.org/journals/data/policy-revisions">Revision Policy</a>’</li>
  <li><a href="https://aeadataeditor.github.io/aea-de-guidance/FAQ.html#i-was-wondering-whether-and-how-i-can-update-the-published-repository-for-our-paper-i-was-contacted-by-a-researcher-who-is-doing-a-replication--couple-of-minor-issues--forgotten-to-include-two-auxiliary-datasets-in-the-repository-without-which-one-of-the-programs-does-not-run-successfully">Instructions how to create a new version on openICPSR</a></li>
</ul>

<h3 id="tldr">TLDR</h3>

<p>In a nutshell, when authors, or replicators, or somebody on the internet, identifies an issue with a package, they have a few options to identify and publish a solution for it, so that others can benefit the update.</p>

<p>They can submit a comment to the journal, when the issue is a scientific one that materially affects the outcome and the conclusions.</p>

<p>They can write a new article, triggered by an issue identified through the reproduction or replication attempt. This can be an original new article, or a replication-specific article (<a href="https://onlinelibrary.wiley.com/page/journal/10991255/homepage/News.html#replication">for instance, at the Journal of Applied Econometrics</a>).</p>

<p>They can record the issue on platforms such as the <a href="https://www.socialsciencereproduction.org/">Social Science Reproduction Platform</a> or the <a href="https://replication.uni-goettingen.de/">Replication Wiki</a>.</p>

<p>Or, if the issue is really minor, or is simply an improvement, authors can post a revision of replication package according to the <strong><a href="https://www.aeaweb.org/journals/data/policy-revisions">AEA Revision Policy</a></strong>.</p>

<p>This post describes the latter.</p>

<h3 id="timeline">Timeline</h3>

<ul>
  <li>Oct 2019: Replication package was submitted to Data Editor (one of the first 200 cases). A first report was sent back to the author (they were simpler back then…), the author revised the package, and re-submitted an improved package.</li>
  <li>Nov 2019: The revised package was accepted (after 1 round). We were unable to access all data, but improved the documentation of the data sources.</li>
  <li>April 2020: Publication of the manuscript: <a href="https://doi.org/10.1257/aer.20171732">https://doi.org/10.1257/aer.20171732</a>, and of the replication package: <a href="https://doi.org/10.3886/E112121V1">https://doi.org/10.3886/E112121V1</a>. <img src="/images/revpolicy-article1.png" alt="article page" /> <img src="/images/revpolicy-data1.png" alt="replication package v1" /></li>
  <li>Sometime in 2020: a replicator, with access to the data, reports to the author various small issues, in particular missing files.</li>
  <li>Jan 2021: Author reaches out to AEA Data Editor,  and wants to correct the data deposit, so that future replicators can access the missing files. A case is created by the AEA Data Editor to follow up.</li>
  <li><em>Life intrudes</em> 🤷‍♂️</li>
  <li>Oct 2022: Author updates the replication package, together with a Changelog (as required by policy), creating a V2. The revised package is published: <a href="https://doi.org/10.3886/E112121V2">https://doi.org/10.3886/E112121V2</a>, and the V1 now has a banner identifying that a newer version is available. <img src="/images/revpolicy-data2.png" alt="revised data package" /></li>
</ul>

<h3 id="notes">Notes</h3>

<ul>
  <li>The original deposit - the version of record - remains available, and downloadable.</li>
  <li>The article page continues to link to the original deposit (V1) because it is the version of record.</li>
  <li>The original deposit has a banner indicating that a newer package is available, and directs to that newer deposit.</li>
  <li>The original deposit and the revised deposit contain cross-links.</li>
</ul>

<h3 id="conclusion">Conclusion</h3>

<p>This is a great example of how the ability to update replication packages is a key part, previously underexploited and not transparent, in improving science. Such updates happen for a variety of reasons multiple times a year. Sometimes, they happen for less happy reasons, such as a data provider requests that a file be removed because posting the file is not compliant with their terms of use. In other cases, authors simply post a better README, after having received feedback from students or replicators.</p>

<p>Revisions and new versions can be created on all regularly used repositories, such as <a href="https://www.openicpsr.org/openicpsr/search/aea/studies">openICPSR</a>, <a href="https://zenodo.org/communities/aeajournals/">Zenodo</a>, and <a href="https://dataverse.harvard.edu/">Dataverse</a>.</p>

<p>When authors publish their replication packages prior to submission, such revisions allow them to incorporate the changes made during the editorial process, whether related to the scientific or the computational content of the paper.</p>

<!-- Ref: AEAREP-228 -->]]></content><author><name>AEA Data Editor</name></author><category term="updating" /><category term="improvement" /><category term="reproducibility" /><summary type="html"><![CDATA[The AEA Data and Code Availability does not just require that authors publish a replication package - it also encourages authors to improve upon the replication package. Here is an example.]]></summary></entry><entry><title type="html">Some remarks on coding when data are confidential</title><link href="https://aeadataeditor.github.io/posts/2022-04-13-coding-confidential" rel="alternate" type="text/html" title="Some remarks on coding when data are confidential" /><published>2022-04-13T00:00:00-04:00</published><updated>2022-04-13T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/coding-confidential</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2022-04-13-coding-confidential"><![CDATA[<p>Back in the fall, I made a few notes regarding how to prepare replication packages when data are confidential (<a href="https://aeadataeditor.github.io/posts/2021-11-08-replication-pkg-confidential">here</a>). What I did not address, and what comes up regularly, is how to <strong>write code</strong> when some code and/or data are confidential.</p>

<!-- more -->

<h2 id="what-is-confidential-code-you-say">What is confidential code, you say?</h2>

<ul>
  <li>In the United States, some variables on IRS databases are considered super-top-secret. So you can’t name that-variable-that-you-filled-out-on-your-Form-1040 in your analysis code of same data. (They are often referred to in jargon as “Title 26 variables”). Not sure why that continues to be perceived as a problem, but until the law changes, that’s one possible constraint.</li>
  <li>Your code contains the random seed you used to anonymize the sensitive identifiers. This might allow to reverse-engineer the anonymization, and is not a good idea to publish.</li>
  <li>You used a look-up table hard-coded in your Stata code to anonymize the sensitive identifiers (<code class="language-plaintext highlighter-rouge">replace anoncounty=1 if county="Tompkins, NY"</code>). A really bad idea, but yes, you probably want to hide that.</li>
  <li>Your IT specialist or misguided disclosure officer thinks publishing the exact path to your copy of the confidential 2010 Census data, e.g., “/data/census/2010”, is a security risk and refuses to let that code through.</li>
  <li>You have adhered to disclosure rules, but for some reason, the precise minimum cell size is a confidential parameter.</li>
</ul>

<p>So whether reasonable or not, this is an issue. How do you do that, without messing up the code, or spending hours redacting your code?</p>

<h2 id="example">Example</h2>

<p>This will serve as an example throughout this post. I’m focusing on Stata, because so many economists use Stata, but none of this is specific to Stata, and the solutions for R, Python, Julia, Matlab, etc. are all quite similar. Assume that variables <code class="language-plaintext highlighter-rouge">q2f</code> and <code class="language-plaintext highlighter-rouge">q3e</code> are considered confidential by some rule, and that the minimum cell size <code class="language-plaintext highlighter-rouge">10</code> is also confidential.</p>

<pre><code class="language-{stata}">set seed 12345
use q2f q3e county using "/data/economic/cmf2012/extract.dta", clear
gen logprofit = log(q2f)
by county: collapse (count)  n=q3e (mean) logprofit
drop if n&lt;10
graph twoway n logprofit
</code></pre>

<h2 id="do-not-do-this">Do not do this</h2>

<p>A bad example, because literally making more work for you and for future replicators, is to manually redact the confidential information with text that is not legitimate code:</p>

<pre><code class="language-{stata}">set seed NNNNN
use &lt;removed vars&gt; county using "&lt;removed path&gt;", clear
gen logprofit = log(XXXX)
by county: collapse (count)  n=XXXX (mean) logprofit
drop if n&lt;XXXX
graph twoway n logprofit
</code></pre>

<p>The redacted program above will no longer run, and will be very tedious to un-redact if a subsequent replicator obtains legitimate access to the confidential data.</p>

<h2 id="better">Better</h2>

<p>Simply replacing the confidential data with replacement that are valid placeholders in the programming language of your choice is already better. Here’s the confidential version of the file:</p>

<pre><code class="language-{stata}">//============ confidential parameters =============
global confseed    12345
global confpath    "/data/economic/cmf2012"
global confprofit  q2f
global confemploy  q3e
global confmincell 10
//============ end confidential parameters =========
set seed $confseed
use $confprofit county using "${confpath}/extract.dta", clear
gen logprofit = log($confprofit)
by county: collapse (count)  n=$confemploy (mean) logprofit
drop if n&lt;$confmincell
graph twoway n logprofit
</code></pre>

<p>and this would be the released file, part of the replication package:</p>

<pre><code class="language-{stata}">//============ confidential parameters =============
global confseed    XXXX    // a number
global confpath    "XXXX"  // a path that will be communicated to you
global confprofit  XXX     // Variable name for profit T26
global confemploy  XXX     // Variable name for employment T26
global confmincell XXX     // a number
//============ end confidential parameters =========
set seed $confseed
use $confprofit county using "${confpath}/extract.dta", clear
gen logprofit = log($confprofit)
by county: collapse (count)  n=$confemploy (mean) logprofit
drop if n&lt;$confmincell
graph twoway n logprofit
</code></pre>

<p>While the code won’t run as-is, it is easy to un-redact, regardless of how many times you reference the confidential values, e.g., <code class="language-plaintext highlighter-rouge">q2f</code>, anywhere in the code.</p>

<h2 id="best">Best</h2>

<p>Note that you have to re-run the entire code to obtain a modified graph, e.g., if you want to add some reference line, or change colors. But if the data presented in the graph is non-sensitive (i.e., disclosable), then the data underlying it is as well. Thus, and this is a more general approach, we can provide code that automatically detects if the confidential data is there, and only then will it run the data preparation part, but it will always run for the graphing (“analysis”) part of the code.</p>

<p>We also introduce the use of a separate file for all the confidential parameters, which may be more convenient, since now, no redaction is needed - the confidential file is simply dropped (but should be documented).</p>

<p>Main file <code class="language-plaintext highlighter-rouge">main.do</code>:</p>

<pre><code class="language-{stata}">//============ confidential parameters =============
capture confirm file "include/confparms.do"
if _rc == 0 {
    // file exists
    include "include/confparms.do"
} else {
    di in red "No confidential parameters found"
}
//============ end confidential parameters =========

//============ non-confidential parameters =========
global safepath "releasable"
cap mkdir "$safepath"

//============ end parameters ======================

// ::::  Process only if confidential data is present 

capture confirm "${confpath}/extract.dta"
if _rc == 0 {
   set seed $confseed
   use $confprofit county using "${confpath}/extract.dta", clear
   gen logprofit = log($confprofit)
   by county: collapse (count)  n=$confemploy (mean) logprofit
   drop if n&lt;$confmincell
   save "${safepath}/figure1.dta", replace
} else { di in red "Skipping processing of confidential data" }

//============ at this point, the data is releasable ======
// ::::  Process always 

use "${safepath}/figure1.dta", clear
graph twoway n logprofit
graph export "${safepath}/figure1.pdf", replace
</code></pre>

<p>Auxiliary file <code class="language-plaintext highlighter-rouge">include/confparms.do</code> (not released)</p>

<pre><code class="language-{stata}">//============ confidential parameters =============
global confseed    12345
global confpath    "/data/economic/cmf2012"
global confprofit  q2f
global confemploy  q3e
global confmincell 10
//============ end confidential parameters =========
</code></pre>

<p>Auxiliary file <code class="language-plaintext highlighter-rouge">include/confparms_template.do</code> (this is released)</p>

<pre><code class="language-{stata}">//============ confidential parameters =============
global confseed    XXXX    // a number
global confpath    "XXXX"  // a path that will be communicated to you
global confprofit  XXX     // Variable name for profit T26
global confemploy  XXX     // Variable name for employment T26
global confmincell XXX     // a number
//============ end confidential parameters =========
</code></pre>

<p>And after a successful run, the files <code class="language-plaintext highlighter-rouge">releasable/figure1.dta</code> and <code class="language-plaintext highlighter-rouge">releasable/figure1.pdf</code> are available, and can be reviewed and released.</p>

<p>Thus, the replication package would have:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>main.do
README.md
include/confparms_template.do
releasable/figure1.dta
releasable/figure1.pdf
</code></pre></div></div>

<p>Voilà! The resulting non-confidential package will run to produce the analysis (<code class="language-plaintext highlighter-rouge">figure1.pdf</code>) based on the distributable, non-confidential analysis file (<code class="language-plaintext highlighter-rouge">analysis.dta</code>). It can also be very simply brought back into the confidential environment, where either the replicator creates a new <code class="language-plaintext highlighter-rouge">confparms.do</code>, or copies the confidential <code class="language-plaintext highlighter-rouge">confparms.do</code> from the original author into their own working area.</p>]]></content><author><name>AEA Data Editor</name></author><category term="confidential data" /><category term="complex projects" /><summary type="html"><![CDATA[Back in the fall, I made a few notes regarding how to prepare replication packages when data are confidential (here). What I did not address, and what comes up regularly, is how to write code when some code and/or data are confidential.]]></summary></entry><entry><title type="html">Use of Docker for Reproducibility in Economics</title><link href="https://aeadataeditor.github.io/posts/2021-11-16-docker" rel="alternate" type="text/html" title="Use of Docker for Reproducibility in Economics" /><published>2021-11-21T00:00:00-05:00</published><updated>2021-11-21T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/docker</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-11-16-docker"><![CDATA[<p>In reproducibility verification, a common scenario is the author response “but-it-works-on-my-machine”. Finding common environments is important in such situations, to demonstrate that the error does arise, reproducibly, but also to share with the author the exact environment so that the issue can be fixed. Shipping around laptops probably isn’t the right solution. We illustrate how we addressed some of those cases using container technology throughout this post.</p>

<!-- more -->

<blockquote>
  <p>NOTE: There are probably still errors in this post. It will remain draft until the stream of comments has died down…</p>
</blockquote>

<blockquote>
  <p>NOTE 2: Post updated with final publication dates for some articles.</p>
</blockquote>

<h2 id="what-are-containers">What are containers</h2>

<p>Containers are “implementations of operating system-level virtualization,” <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> typically on Linux. The most common version is provided by <a href="https://docker.com">Docker</a>, but several other implementations exist, such as <a href="https://singularity.hpcng.org/">Singularity</a>. The use of containers as part of replication packages in economics is extremely low, and yet they have some advantages. This post will explore both pre-submission and post-publication uses of containers, as well as several shortcomings.</p>

<p>In a nutshell,</p>

<blockquote>
  <p>“A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another.” <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></p>
</blockquote>

<p>In particular, this means that all dependencies are handled, and there should be virtually no differences across time, users’ operating system, and software implementation in reproducing the outcomes of software.</p>

<p>Containers also isolate the computation from the host system, so that no user-specific settings (stuff you have configured over the past 10 years of working on a project) are carried through into the container, up to a point. That kind of isolation can also be achieved in various ways: for the cognescenti (also called geeks), <code class="language-plaintext highlighter-rouge">chroot</code> environments on Unix systems go back to the early 1980s <sup id="fnref:chroot" role="doc-noteref"><a href="#fn:chroot" class="footnote" rel="footnote">3</a></sup>, and “virtual machines” probably go back to 1960s IBM mainframes <sup id="fnref:vm" role="doc-noteref"><a href="#fn:vm" class="footnote" rel="footnote">4</a></sup>)</p>

<h2 id="containers-and-reproducibility">Containers and reproducibility</h2>

<p>Containers can, but do not necessarily contribute to reproducibility and replicability. For an excellent introduction, see Boettinger (2015) <sup id="fnref:intro" role="doc-noteref"><a href="#fn:intro" class="footnote" rel="footnote">5</a></sup>. Once created, containers can (should) reliably reproduce the context and output they were designed to handle. Because containers typically use a plain-text script for their creation (so-called <code class="language-plaintext highlighter-rouge">Dockerfile</code>), they can contribute to transparency. However, containers can also be interactively created, or incorporate externally created packages, which may lead to some black-box actions that are not transparent. Thus, containers can generate reproducible output, but not be themselves reproducibly created. Furthermore, if containers rely on external resources – for instance, accessing the internet to download data from an API, or installed “latest” packages – the output generated may not be reproduced, though it may still be considered replicable.</p>

<h2 id="containers-in-computational-social-science">Containers in computational social science</h2>

<p>For the (social science) research environment, this should, in principle, handle many of the common problems that workarounds and READMEs list. In this post, we will explore several such cases, in which a computational issue was encountered, debugged leveraging both locally installed and cloud-based containers, and ultimately solved.</p>

<ul>
  <li>Run R through a container</li>
  <li>Run Intel Fortran (or another complex setup) through container</li>
  <li>Run Gurobi through container with a dynamic license</li>
  <li>The Holy Grail in Economics: Run Stata through a container</li>
</ul>

<p>The examples here are based on personal research experience as well as the experience when attempting to conduct reproducibility verifications on nearly 1,000 economics articles. They are by no means meant to be exhaustive or cover all the possible uses of containers. We should note that many of these examples are retro-actively ported to containers, and may not constitute the optimal setup. In our experience with 1,000 economics articles, as of November 2021, we have encountered only 1 (in words: <strong>one</strong>) that used any Docker in their submission to the AEA journals: Lamadon, Mogstad, and Setzler, “Imperfect Competition, Compensating Differentials and Rent Sharing in the U.S. Labor Market”,<sup id="fnref:lms" role="doc-noteref"><a href="#fn:lms" class="footnote" rel="footnote">6</a></sup> who leveraged 4 different CodeOcean compute capsules to support their analyses (we will return to CodeOcean later).</p>

<h2 id="running-r-julia-python-in-docker">Running R, Julia, Python in Docker</h2>

<p>Many of the examples one can find on the Internet sees container used in conjunction with open-source languages. For most statistical and other languages, in particular open-source languages, progress is continuous. In part what attracts researchers to these environments is the rich eco-system of add-on packages and libraries, most of which are available for free as well. However, combining versions of languages, packages, and dependencies to those packages can be a challenge. Use of these can sometimes be tedious - and not easily reproducible - because of a constantly evolving environment and very active development. Various methods exist to “pin” packages used (see <a href="https://cran.r-project.org/package=renv">renv</a>, <a href="https://cran.r-project.org/package=checkpoint">checkpoint</a> and others in R, “environments”, <a href="https://pip.pypa.io/en/stable/reference/pip_freeze/"><code class="language-plaintext highlighter-rouge">pip freeze</code></a> or <a href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#sharing-an-environment"><code class="language-plaintext highlighter-rouge">conda env export</code></a> in Python, <code class="language-plaintext highlighter-rouge">Manifest.toml</code> files and <a href="https://julia.quantecon.org/more_julia/tools_editors.html#Package-Environments">package environments</a> in Julia). These rely, of course, not just on the ability to install the right packages, but also the right base software. In some cases, it can be challenging for users to install multiple base versions simultaneously on their computers - either because they work on multiple projects on their own at different times, or in collaborations with others. This is sometimes necessitated by changes that create breaks between versions (examples include <a href="https://docs.julialang.org/en/v1.4/NEWS/#Standard-library-changes-1">changes in random number generators in Julia</a> and <a href="https://blog.revolutionanalytics.com/2020/04/r-400-is-released.html">certain breaks in R when version 4.0 was introduced</a>). Programmatic solutions for this exist, of course, but add complexity to an often complex set of programs.</p>

<p>Thankfully, that same open-source community has also provided containers that lock in some of the base software versions, facilitating the simultaneous maintenance of multiple versions of the same software. We illustrate this with an example that we have used in some reproducibility cases with R. It addresses the particular use case of having multiple versions of R, but does not pin the particular package versions. See the tutorials for  <a href="https://cran.r-project.org/package=renv">renv</a> and <a href="https://cran.r-project.org/package=checkpoint">checkpoint</a> for even finer control.</p>

<h3 id="a-really-simple-example-with-r">A Really Simple Example with R</h3>

<p>To start, we identify from instructions provided by the author both the version of R and the required packages. From the required packages, we use a standard <a href="https://github.com/AEADataEditor/docker-r-starter/blob/main/setup.R">setup program</a> and add those libraries to the list of dependencies.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">7</a></sup> We then leverage the <a href="https://hub.docker.com/u/rocker">R Docker images</a> maintained by the <a href="https://github.com/rocker-org/rocker">Rocker group</a>, and build a custom R Docker image that should have all dependencies as articulated by the authors:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Dockerfile</code>:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FROM rocker/r-ver:4.0.1

COPY setup.R .
RUN Rscript setup.R
</code></pre></div></div>
<p>That’s already all there is to creating a Docker image! Of course, it now needs to be built:<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">8</a></sup></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DOCKER_BUILDKIT=1 docker build . -t $MYHUBID/$MYIMG:$TAG
</code></pre></div></div>

<p>where I have previously configured some environment variables for ease of notation and reference:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TAG=v$(date +%F)
MYIMG=aer-9999-8888
MYHUBID=aeadataeditor
</code></pre></div></div>

<p>This locks in our R environment, at the time of building (<code class="language-plaintext highlighter-rouge">$TAG</code>). It is then straightforward to run the authors’ code, reliably, over and over again:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd path/to/code
docker run -it --rm -v $(pwd)/subdir:/code -w /code $MYHUBID/${MYIMG}:$TAG Rscript main.R
</code></pre></div></div>

<p>Note that for each project, we can specify a different R version (<code class="language-plaintext highlighter-rouge">rocker/r-ver:4.0.1</code>), and we can even, for the same project, test the reproducibility with multiple R versions, by building multiple images (we might need to refine our tagging for that to work).</p>

<p>Furthermore, if we run into reproducibility discrepancies, we can share the resulting (public) Docker image and the “very simple” instructions with the authors. In doing so, we reproducibly share the failure to reproduce. We have done so, in fact, in several cases, though we will describe that particular type of interaction in the next section, in somewhat more challenging cases.</p>

<p>All we need is Docker as a software installation on our workstation. Or: in the cloud.</p>

<h2 id="running-docker-the-cloud-way">Running Docker the Cloud way</h2>

<p>Numerous cloud computing providers facilitate running Docker. Some might call it an “app” that you are running, others may require you to boot up a Linux VM before running Docker, the mechanisms vary substantially. In many instances, you may need to worry about how to recover the results once the Docker image has finished running your code, and both data and code will likely need to be embedded in the Docker image, something not addressed here.</p>

<p>One innovation that multiple authors have recently pointed to is the July 2021 release of “Github Codespaces.” Subject to some conditions, anyone can easily run arbitrary Docker images in the cloud. We illustrate this using a <a href="https://github.com/labordynamicsinstitute/reproducibility-confidential">reproducible environment to conduct a tutorial</a> (readers might want to consult the tutorial for several other reasons as well).</p>

<p>The tutorial is programmed in R, leverages R-generated HTML slides (<code class="language-plaintext highlighter-rouge">ioslides</code>). Relevant for the point here is that the tutorial is intended to be conducted interactively. To do that, after having <a href="https://docs.github.com/en/codespaces/managing-codespaces-for-your-organization/enabling-codespaces-for-your-organization">enabled Codespaces for the organization</a>, we select and launch a codespace - essentially, a cloud-computer running our code.</p>

<p><img src="/images/github-codespaces-1.png" alt="Launching Codespaces" /></p>

<p>After choosing a size (which can go up to a 16-core/ 32GB RAM server), the system launches into a simple Linux shell, with the source git repository already checked out</p>

<p><img src="/images/github-codespaces-2.png" alt="Launching Codespaces" /></p>

<p>Docker comes into play here because we want to use a Rstudio instance in the cloud, already set up the way we need it to be. The build script does most of the original legwork for us, and once in the cloud, all we need to do is to launch the pre-configured (reproducible!) Docker instance, loaded with our libraries and code:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run \
   -e PASSWORD=testing \
   -v $WORKSPACE:/home/rstudio \
   --rm -p 8787:8787 $dockerspace/$repo
</code></pre></div></div>
<p>which we do straight from the cloud command line:</p>

<p><img src="/images/github-codespaces-3.png" alt="Launching docker" /></p>

<p>The docker command again downloads the image components from the Docker Hub, and runs the Rstudio instance:</p>

<p><img src="/images/github-codespaces-4.png" alt="Launching docker" /></p>

<p>Codespaces detects that we are running a webserver within the Docker image, and prompts us to connect to it:</p>

<p><img src="/images/github-codespaces-5.png" alt="Launching Rstudio" /></p>

<p>This is an example of reproducibility for interactive uses, but would apply in much the same way if all we wanted to do is run some R code repeatedly, or reproducibly. In fact, that is exactly what a separate functionality (Github Workflow/Actions) does to generate the slides for this particular tutorial, something left for next time (but see the <a href="https://github.com/labordynamicsinstitute/reproducibility-confidential/blob/main/.github/workflows/main.yml">workflow configuration file</a> for the tutorial). We will come back to this later.</p>

<h2 id="compiling-fortran-code-through-a-container">Compiling Fortran code through a container</h2>

<p>Compilers are the workhorses for high-performance computing, and many economists will program compute-intensive routines in Fortran, then compile and run such code. Both open-source <sup id="fnref:osfortran" role="doc-noteref"><a href="#fn:osfortran" class="footnote" rel="footnote">9</a></sup> and commercial<sup id="fnref:commfortran" role="doc-noteref"><a href="#fn:commfortran" class="footnote" rel="footnote">10</a></sup> are available. We describe two use cases for using Fortran in combination with Docker.</p>

<h3 id="ce-fortran">CE Fortran</h3>

<p>In many cases, compilers require the presence of many separate libraries, and installation is traditionally complicated. The <a href="https://www.ce-fortran.com/">CE-Fortran</a> project (“Computational Economics using Fortran”, Hans Fehr and Fabian Kindermann) trains and guides economists using open source <a href="https://gcc.gnu.org/fortran/">GNU Fortran</a>.</p>

<p><img src="/images/ce-fortran-webpage.png" alt="CE Fortran" /></p>

<p>They have traditionally provided detailed installation instructions for all three operation systems, striving to make the development environment as comparable as possible across all three. More recently, the authors have started providing a Docker image to provide a consistent environment, see <a href="https://github.com/fabiankindermann/ce-fortran/tree/main/installation/docker/docker_base">their Github page</a>.</p>

<p>Nevertheless, some of the issues cannot be fully handled in a Docker image. For instance, while the environment in the base Docker image can create images, it cannot be used to provide an IDE or for manipulating images interactively. For this purpose, the authors provide a second, much <a href="https://github.com/fabiankindermann/ce-fortran/tree/main/installation/docker/docker_vnc">larger Docker image</a> that includes a workaround (a VNC server).</p>

<h3 id="intel-fortran">Intel Fortran</h3>

<p>A second scenario is frequently encountered among the AEA’s replication packages. Many authors, particularly in macroeconomics, use Intel Fortran compilers. While installation instructions have been streamlined, they remain onerous: the most recent Windows installation instructions rely on a two installers, and have a dependency on Microsoft Visual Studio - a separate installer - which in turn has multiple additional dependencies. Furthermore, authors rarely use Makefiles, a way to compile code and address dependencies commonly used in the open source community, and only sometimes use Windows-specific Visual Studio Project files. The typical instruction, repeated dozens of times, looks like this:</p>

<p><img src="/images/README_page07.png" alt="Compiler instruction" /></p>

<p>with subsequent instructions to manually run the compiled code. Such instructions are inefficient, and potentially error prone.</p>

<h3 id="a-fortran-docker-example">A Fortran Docker Example</h3>

<p>In reproducing a recent paper, we instead opted to streamline the process, making for a more efficient reproducibility check, and also – if the authors were to adopt this process – a more efficient development process.</p>

<ol>
  <li>Using scripting tools, we extracted all of the <code class="language-plaintext highlighter-rouge">ifort</code> commands from the README PDF (34 lines)</li>
  <li>We manually inserted the relevant directories, and added code to automatically run the compiled binary.</li>
  <li>The resulting script file (<code class="language-plaintext highlighter-rouge">run_all.sh</code>) looks like this (in <code class="language-plaintext highlighter-rouge">bash</code> notation - this could also be done as a Windows <code class="language-plaintext highlighter-rouge">bat</code> file):</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Code to run models 
# Author: Lars Vilhuber
# Based on instructions in the paper's replication package
# NOTE: this should really be a Makefile!
# Capture base folder

BASE=$(pwd)

# Compiler options

IFORTOPTS=" -qopenmp"

# Figure 1A

cd $BASE/rep_agent_models/tc_model_nongrace

time ifort $IFORTOPTS rep_tc_delta_array.f90 rouwenhorst.f90 \
  -o rep_tc_delta_array.exe &amp;&amp; time ./rep_tc_delta_array.exe 

cd $BASE/rep_agent_models/tc_model_grace

time ifort $IFORTOPTS rep_tc_grace_delta_array.f90 rouwenhorst.f90 \
  -o rep_tc_grace_delta_array.exe &amp;&amp; time ./rep_tc_grace_delta_array.exe 

# and so on...
</code></pre></div></div>

<h4 id="simplicity">Simplicity</h4>

<p>Once we had the script, we used the <a href="https://hub.docker.com/r/intel/oneapi-hpckit/tags?page=1&amp;ordering=last_updated">Intel OneAPI-hpckit</a> (required 23GB of disk space, compared to the 24GB that the Windows install would have taken):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker pull intel/oneapi-hpckit:2021.2-devel-ubuntu18.04
</code></pre></div></div>

<ol>
  <li>Ran master script through the docker image
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd PATH/model_codes
docker run --rm -it -w /code \
  -v $(pwd):/code intel/oneapi-hpckit:2021.2-devel-ubuntu18.04 \
  /code/run_all.sh &gt; run_all.output.txt
</code></pre></div>    </div>
  </li>
</ol>

<p>This generated about 100 output files, without any further manual intervention. There is no separate installation process for the Intel compilers, a simple <code class="language-plaintext highlighter-rouge">docker pull</code> command allowed us to run all of the required files, within a few minutes.</p>

<h4 id="flexibility">Flexibility</h4>

<p>When one of the compile steps required a larger memory size (25GB) than our workstation had available (23GB), we simply re-ran the following three steps on a general purpose server we had never before used for this purpose (but which already had Docker installed):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git pull (URL of the reproducibility repository)
cd PATH/model_codes
docker run --rm -it -w /code \
  -v $(pwd):/code \
  intel/oneapi-hpckit:2021.2-devel-ubuntu18.04 \
  /code/run_all.sh &gt; run_all.output.txt
</code></pre></div></div>
<p>(the <code class="language-plaintext highlighter-rouge">docker pull</code> command is automatically executed by the <code class="language-plaintext highlighter-rouge">docker run</code> command if the image is not locally available).</p>

<h4 id="thoughts">Thoughts</h4>

<p>When using a container for the task of running these (fairly standard) types of structural models, we gained robustness and simplicity. Instead of a complex and manual Windows install specific to this type of project, we had a very simple way to run the author-provided code. The “transparency boundary” remains unchanged: the reliance on the proprietary (non-open source) Intel compiler, whether installed as a Windows installer, or obtained via a Intel-provided Docker image, is conceptually similar, and similarly opaque.</p>

<h2 id="running-docker-the-easy-way">Running Docker the Easy Way</h2>

<p>Of course, this may all seem overwhelming and complicated, as any new piece of software. Which is why several services are available that make this all a lot easier. These include <a href="https://codeocean.com/">CodeOcean</a>, <a href="https://wholetale.org/">WholeTale</a>, <a href="https://mybinder.org/">Binder</a>, and others (see Konkol et al, 2020,<sup id="fnref:konkol" role="doc-noteref"><a href="#fn:konkol" class="footnote" rel="footnote">11</a></sup> for a broader overview). Behind the scenes, these use containers as well, sometimes built on the fly, but also able to archive the containers, ensuring persistence of what hopefully are reproducible containers.</p>

<p>We have started to use these services to enable reproducibility verification in an environment which allows us, when the time inevitably arrives, to share the exact environment with the authors in order to debug code. In contrast with the statement “Author, please use this Docker image to reproduce the issue”, the request “Author, please click on this URL to reproduce the issue” is much simpler. Several authors have been offered both options (no RCT…), and have generally preferred the option of an online easy interface to the ability to run Docker or Singularity locally.</p>

<p>And we have started to leverage the ability to also publish these reproducible artifacts. Recent examples include Rossi (2021)<sup id="fnref:rossi" role="doc-noteref"><a href="#fn:rossi" class="footnote" rel="footnote">12</a></sup> and DellaVigna and Pope (2021)<sup id="fnref:stefano" role="doc-noteref"><a href="#fn:stefano" class="footnote" rel="footnote">13</a></sup>. In both cases, we were able to populate the <a href="https://doi.org/10.24433/CO.7940775.v1">CodeOcean</a> <a href="https://doi.org/10.24433/CO.0687784.v1">capsule</a> when we ran into reproducibility issues, sharing it (via a URL) with the authors, and solving the issue that both satisfied the AEA Data Editor, and is likely to satisfy future replicators as well.</p>

<p>We are working with the <a href="https://wholetale.org/">WholeTale</a> on similar usage scenarios, and are open to working with authors’ choices whereever those may lead.</p>

<p>One key aspect here is worthwhile highlighting. In contrast to some other online computational platforms, for instance <a href="https://colab.research.google.com/">Google Colab</a>, the ability to download (nearly) the entire reproducible environment, not just the code, and archive it, are key. That does not mean that they are automatically “fully reproducible”. They may still be missing some key elements that replicators will need to contribute, such as licenses.</p>

<h2 id="licenses">Licenses</h2>

<p>Most examples out there use open source software, not requiring licenses. This is an issue in economics, where the most common software used - Stata, Matlab - are proprietary and require licenses. Luckily, there are many ways to include licenses in Docker images at runtime, or, if using them internally within a research group, embedding licenses within the Docker image, as one would install a license in any “real” computer. The online systems mentioned above sometimes provide access to such licenses as well. We briefly illustrate first the easy, online way to incorporate licenses into container-based workflows, and then two “hard” ways.</p>

<h3 id="an-example-using-stata-licenses-and-the-easy-way">An example using Stata, licenses, and the “Easy Way”</h3>

<p>Bringing many of the issues alluded to earlier together, we have successfully leveraged this “toolkit” to improve the reproducibility and accessibility of Stata-based replication packages. Stata is used by the vast majority of economists, so being able to handle this scenario is important, but it also illustrates how licensed software can be used with containers.</p>

<p><a href="https://aeadataeditor.github.io/aea-supplement-migration/programs/aea201910-migration.html"><img src="https://github.com/AEADataEditor/aea-supplement-migration/raw/530f1e9ad8059e68815b5836db33155c990154b0/programs/figure_software_years_pct.png" alt="Stata usage at AEA journals" /></a></p>

<p>The easiest way is to use an online system that provides such access. The first to our knowledge was <a href="https://codeocean.com/">CodeOcean</a>. Simply choosing one of the configured Stata images will create a Docker image with Stata:</p>

<p><img src="/images/codeocean-choice.png" alt="Stata choice" /></p>

<h3 id="hard-to-nail-down-failure-to-compute">Hard-to-nail down failure to compute</h3>

<p>This is the environment we used to work with the authors to create the reproducible package for DellaVigna and Pope (2021). We were able to work exclusively within CodeOcean’s environment, debugging a tenacious problem that wasn’t easy to diagnose. But we also wanted to make sure that the resulting replication package is not reliant on CodeOcean’s infrastructure. The authors debugged the code on CodeOcean (yielding the <a href="https://doi.org/10.24433/CO.0687784.v1">published capsule</a>). We  then verified the <a href="https://doi.org/10.3886/E135221V1-101800">instructions to re-run the replication package</a> downloaded from CodeOcean on a personal workstation, emulating a somewhat typical economist. We  also populated the official replication package on openICPSR with the same code (<a href="https://doi.org/10.3886/E135221V1">https://doi.org/10.3886/E135221V1</a>). This is strictly speaking not necessary, since CodeOcean is a trusted repository, and assigns DOIs, but for now, we make it easier to discover this way.</p>

<p>After downloading the CodeOcean capsule (<code class="language-plaintext highlighter-rouge">57033059-76d7-422d-8301-d173e3520f07.zip</code>), or equivalently, the openICPSR deposit, the following straightforward code (mostly documented in the CodeOcean-provided <code class="language-plaintext highlighter-rouge">REPRODUCING.md</code>) reproduces the paper’s outputs perfectly:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>unzip 57033059-76d7-422d-8301-d173e3520f07.zip 
cd environment/
# Need the Stata license
cp /path/to/statalicense/stata.lic.16 stata.lic
# Build the image - note, requires CodeOcean provided image. Could be replaced with the dataeditors/stata16 image
DOCKER_BUILDKIT=1 docker build . \
  --tag 57033059-76d7-422d-8301-d173e3520f07
cd ..
# Ensure the script is runnable - this is not documented
chmod a+rx code/run 
docker run --rm   \
  --workdir /code   \
  --volume "$PWD/environment/stata.lic":/usr/local/stata/stata.lic   \
  --volume "$PWD/data":/data   \
  --volume "$PWD/code":/code   \
  --volume "$PWD/results":/results  \ 57033059-76d7-422d-8301-d173e3520f07 \
  ./run
</code></pre></div></div>

<h2 id="challenges">Challenges</h2>

<h3 id="big-data">Big data</h3>

<p>Since a container is meant to package up all necessary dependencies, it would seem logical that one could include all data. However, this breaks down when the data are large, even before getting into “big data” territory. The typical Docker image is no larger than 2-3 GB. Thus, the issues that plague  reproducibility when data are large - delays in downloading or streaming data, availability of local space - are not solved by containers. That being said, satisfying the software dependencies is a first step in making sure that reproducibility can be achieved. Thus, a variant of the above way to run a Docker image could also be used in the presence of big data, by mounting the local storage directory for the data:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run --rm   \
  --workdir /code   \
  --volume "$PWD/data":/data   \
  --volume "/path/to/BIG/DATA:/bigdata \
  --volume "$PWD/code":/code   \
  --volume "$PWD/results":/results  \ 
  researcherhub/papercontainer \
  ./run
</code></pre></div></div>

<h3 id="licenses-not-provided">Licenses not provided</h3>

<p>Most of the “easy” systems are easy because they can accomodate a limited set of customizations. For instance, one can specify some post-install scripts on various platforms, but not choose an unsupported software image. But when the software requires additional licenses, a tension arises between publishing the successfully run image with an embedded license, and providing a template implementation that requires provision of a license.</p>

<p>Mathworks has gone the latter route, providing a <a href="https://hub.docker.com/r/mathworks/matlab">Matlab Docker image</a> without a license, and then providing instructions on how to provision the container with a valid license, for instance within a university’s internal network with a network server. Internally, WholeTale and CodeOcean use a similar mechanism behind the scenes.</p>

<p>Stata does not provide Docker image, but has allowed the AEA Data Editor to provide <a href="https://hub.docker.com/u/dataeditors">license-less Docker images for Stata</a>. The <a href="https://github.com/AEADataEditor/docker-stata">instructions provided</a> identify various ways a license can be provisioned to the image, so that code can be run:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run -it --rm \
  -v ${STATALIC}:/usr/local/stata/stata.lic \
  -v $(pwd)/code:/code \
  -v $(pwd)/data:/data \
  -v $(pwd)/results:/results \
  $MYHUBID/${MYSTATAIMG}:${TAG}
</code></pre></div></div>

<p>In effect, users can simply use their own Stata license to enable a Stata Docker image. Again, WholeTale and CodeOcean use a similar mechanism behind the scenes, but the fact that any Stata user can re-execute such a Docker image with a valid Stata license is no more constraining that having installed Stata on their own computer.</p>

<p>In other circumstances, expiring licenses may be used. In a case where we needed to install <a href="https://www.gurobi.com/academia/academic-program-and-licenses/">Gurobi</a> together with R, we used a new feature provided by Gurobi to provide “<a href="https://www.gurobi.com/web-license-service/">web licenses</a>.” These can be disabled from a dashboard, and naturally expire after a while. Thus, our CodeOcean “postInstall” script installed Gurobi into a R container, then hard-coded a license key:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget -v https://packages.gurobi.com/${GRB_SHORT_VERSION}/gurobi${GRB_VERSION}_linux64.tar.gz \
    &amp;&amp; tar -xvf gurobi${GRB_VERSION}_linux64.tar.gz  \
    &amp;&amp; rm -f gurobi${GRB_VERSION}_linux64.tar.gz \
    &amp;&amp; mv -f gurobi* gurobi \
    &amp;&amp; rm -rf gurobi/linux64/docs


cd /opt/gurobi/linux64
#run the setup
python3.7 setup.py install

# Add the license key
# For replication purposes, this will need to be re-initialized, as post-publication, this key was disabled.
# You will need to provide your own.
echo "
WLSACCESSID=96388c95-2a7f-4195-88af-b167b077c019
WLSSECRET=ef818954-18ed-43f5-84b0-ace17641fd18
LICENSEID=6521234
" &gt; /opt/gurobi/gurobi.lic
</code></pre></div></div>

<p>Once published, simply disabling the key on the Gurobi dashboard would prevent any unauthorized use of the license. Alternatively, of course, the method used for the Stata license above would also work outside of the CodeOcean environment, by using</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run -it --rm \
  -v gurobi.lic:/opt/gurobi/gurobi.lic \
  -v $(pwd)/code:/code \
  -v $(pwd)/data:/data \
  -v $(pwd)/results:/results \
  $MYHUBID/${MYGUROBIIMG}:${TAG}
</code></pre></div></div>
<p>Thus, generically, licensed software can very well be used when the proprietary software provider allows for redistribution of the binary portion of the software in the form of “opaque” containers; however, in many circumstances, the “easy” online providers of such container-based services can make it non-trivial to implement.</p>

<h3 id="complex-interactions-between-software">Complex interactions between software</h3>

<p>Finally, as one example where limitations are hard to address ex-post, we highlight an example where researchers called a separately compiled Fortran binary from within Matlab. While each software could easily be run in its own container, it becomes non-trivial (but not impossible) to use multiple containers in this way.</p>

<p>The solution, as evidenced by the Gurobi example earlier, consists in installing one software into a container provided by the other. This, however, may lose the advantages of using pre-configured containers that avoid complex installation procedures, as in the case of Matlab and Intel compilers. An alternative (not tested) might consist in leveraging <a href="https://docs.docker.com/develop/develop-images/multistage-build/">multi-stage builds</a>, where entire portions are copied from one container into another. This is beyond the scope of the “easy” web-based solutions (though it may be on their development plan). However, precisely because a knowledgeable researcher can handle the (now much more complex) container creation, future users may not have to. By publishing the associated <code class="language-plaintext highlighter-rouge">Dockerfiles</code>, <a href="https://github.com/AEADataEditor/docker-r-starter/blob/main/Dockerfile">simple</a> or more <a href="https://github.com/AEADataEditor/docker-r-gurobi/blob/main/Dockerfile">complex</a>, future users do not need to reinvent the wheel - one of the purposes of the transparency that reproducibility fosters.</p>

<h3 id="continuous-integration">Continuous integration</h3>

<p>Containers are also a tool for continuous integration - the software engineering best practice to test software at every step - but which can also be used to streamline research analyses. Consider the scenario where all data is available in a researcher’s Git repository (because of course, the researcher is using a Git repository). Containers can then be leveraged to create output - a research article, preliminary analyses, or a number of webpages. For instance, many researchers now use R in combination with Markdown to create “dynamic documents”. The (perenially incomplete) <a href="https://labordynamicsinstitute.github.io/replicability-training-curriculum/">training manual for our undergraduate replicators</a> is “built” this way, using the great <a href="https://pkgs.rstudio.com/bookdown/"><code class="language-plaintext highlighter-rouge">bookdown</code> package</a> by Yihui Xie, using a simple preconfigured container:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     - name: Run docker for R 
        uses: docker://larsvilhuber/ideahandbook:latest
        with:
          args: "/github/workspace/_build.sh publish"
</code></pre></div></div>

<p>(see the <a href="https://github.com/labordynamicsinstitute/replicability-training-curriculum/blob/master/.github/workflows/main.yml">Github Action workflow file</a> for full details)</p>

<h3 id="graphical-utilities">Graphical utilities</h3>

<p>Some of the “easy” online systems do not provide the native coding environment that many users are used to, for instance the Matlab or Stata desktop applications. This makes it harder, in fact, for such researchers to adapt to these tools. We regularly observe code or instructions that use visual inspection of the results, or leverage other features only available in a full graphical environment. This is less a concern for more recent (and typically open source) software, such as R (availability of Rstudio as a web service), Python, and Julia (Jupyter notebooks). However, WholeTale is trialling (with assistance from us) a combination of reproducible “tale” combined with a graphical user interface for Stata. The <a href="https://hub.docker.com/r/mathworks/matlab">Matlab Docker image</a> provides a graphical interface, as does one of the <a href="https://github.com/fabiankindermann/ce-fortran/tree/main/installation/docker/docker_vnc">CE-Fortran docker images</a>, so these are not fundamentally problems.</p>

<h2 id="preliminary-conclusion">(Preliminary) Conclusion</h2>

<p>Containers provide a way to share computational environments in an efficient way, to make such environments robust to changes in the underlying software, and to publish the fully transparent methods that lead to such containers. They are, however, underutilized in economics replication packages and by economics researchers. This document has provided a few scenarios that illustrate cases where the use of containers can help improve reproducibility.</p>

<h2 id="resources">Resources</h2>

<p>So is this all rocket science? While I’m sure that the rocket scientists use containers, it isn’t really that complicated. Here is a (almost surely incomplete) list of a few resources to get you started:</p>

<h3 id="economics-articles-and-replication-packages-using-docker">Economics Articles and Replication Packages using Docker</h3>

<ul>
  <li>Rossi (<a href="https://doi.org/10.1257/jel.20201479">JEL, 2021</a>): “Forecasting in the presence of instabilities: How do we know whether models predict”<sup id="fnref:rossi:1" role="doc-noteref"><a href="#fn:rossi" class="footnote" rel="footnote">12</a></sup></li>
  <li>DellaVigna and Pope (<a href="https://doi.org/10.1257/mic.20200129">American Economic Journal: Microeconomics, 2022</a>) “Stability of Experimental Results: Forecasts and Evidence”<sup id="fnref:stefano:1" role="doc-noteref"><a href="#fn:stefano" class="footnote" rel="footnote">13</a></sup></li>
  <li>Bonhomme, Lamadon, and Manresa (<a href="https://doi.org/10.3982/ECTA15722">Econometrica, 2019</a>): “A distributional framework for matched employer-employee data”, <a href="https://github.com/tlamadon/blm-replicate">Github repository</a></li>
  <li>Sergio Firpo, Vitor Possebom. 2018. “Synthetic Control Method: Inference, Sensitivity Analysis and Confidence Sets” Journal of Causal Inference 6.2, <a href="https://doi.org/10.1515/jci-2016-0026">https://doi.org/10.1515/jci-2016-0026</a>. <a href="https://doi.org/10.24433/CO.23bd238f-38c5-4b3e-82f4-3a1624fd8a33">Compute Capsule at CodeOcean</a></li>
  <li>Matias D. Cattaneo, Nicolás Idrobo, Rocío Titiunik. 2018.  “A Practical Introduction to Regression Discontinuity Designs: Volume I” <a href="https://doi.org/10.24433/CO.263b2a1e-bbc1-45c9-af03-23ac11032950">Compute Capsule at CodeOcean</a></li>
</ul>

<h3 id="tutorials">Tutorials</h3>

<ul>
  <li><a href="https://raw.githack.com/uo-ec607/lectures/master/13-docker/13-docker.html#1">Grant McDermott’s EC 607 graduate course, Docker lesson</a></li>
  <li><a href="https://carpentries-incubator.github.io/docker-introduction/index.html">Carpentries tutorial on Docker</a></li>
  <li>Installing Docker on a <em>managed</em> Windows system can be challenging, and my poor colleagues Michael Darisse and Leonel  Borja Plaza have suffered through it for you to bring you <a href="https://github.com/labordynamicsinstitute/replicability-training/blob/master/Docker_Windows.md">this tutorial</a>.
    <ul>
      <li>Installing Docker on a Linux system, on the other hand, can be as simple as <code class="language-plaintext highlighter-rouge">yum install docker</code>.</li>
      <li>The command line can help on  Mac as well: <a href="https://www.cprime.com/resources/blog/docker-on-mac-with-homebrew-a-step-by-step-tutorial/"><code class="language-plaintext highlighter-rouge">brew install docker</code></a>.</li>
    </ul>
  </li>
</ul>

<h3 id="examples-and-images">Examples and Images</h3>

<ul>
  <li><a href="https://github.com/AEADataEditor/docker-stata">Stata as Docker</a></li>
  <li><a href="https://github.com/AEADataEditor/docker-r-gurobi">R and Gurobi as Docker</a></li>
  <li><a href="https://hub.docker.com/r/mathworks/matlab">Matlab Docker image</a></li>
  <li><a href="https://www.rocker-project.org/">Rocker project</a></li>
  <li><a href="https://hub.docker.com/r/intel/oneapi-hpckit/tags?page=1&amp;ordering=last_updated">Intel OneAPI-hpckit</a></li>
</ul>

<h3 id="tools">Tools</h3>

<h4 id="r-centric">R-centric</h4>

<ul>
  <li><a href="https://o2r.info/containerit/">containerit</a></li>
  <li><a href="https://www.rocker-project.org/">Rocker project</a></li>
  <li><a href="https://dirk.eddelbuettel.com/papers/cologneRUG2020.pdf">Dirk Eddelbuettel’s tutorial</a></li>
</ul>

<h4 id="git-centric">Git-centric</h4>

<ul>
  <li><a href="https://repo2docker.readthedocs.io/en/latest/">repo2docker</a></li>
  <li><a href="https://docs.github.com/en/codespaces/managing-codespaces-for-your-organization/enabling-codespaces-for-your-organization">Github Codespaces</a></li>
</ul>

<h3 id="services">Services</h3>

<p>These are the services listed in Konkol et (2020)<sup id="fnref:konkol:1" role="doc-noteref"><a href="#fn:konkol" class="footnote" rel="footnote">11</a></sup> that use Docker</p>

<ul>
  <li><a href="https://codeocean.com">CodeOcean</a></li>
  <li><a href="https://mybinder.org/">Binder</a></li>
  <li><a href="https://wholetale.org/">WholeTale</a></li>
</ul>

<p>as well as more recent</p>

<ul>
  <li><a href="https://docs.github.com/en/codespaces/managing-codespaces-for-your-organization/enabling-codespaces-for-your-organization">Github Codespaces</a></li>
</ul>

<p>and</p>

<ul>
  <li><a href="https://gigantum.com/">Gigantum</a> (not tested)</li>
</ul>

<p>as well as many cloud service providers.</p>

<h2 id="disclosures">Disclosures</h2>

<p>We received a generous compute and storage quota from <a href="https://codeocean.com/">CodeOcean</a>, a free license to use Stata 17 for one year in cloud applications from <a href="https://stata.com">Stata</a>, and a subaward on NSF grant <a href="https://nsf.gov/awardsearch/showAward?AWD_ID=1541450&amp;HistoricalAwards=false">1541450</a> “<em>CC*DNI DIBBS: Merging Science and Cyberinfrastructure Pathways: The Whole Tale</em>” from the University of Illinois to evaluate the platform for the purpose of reproducibility verification. None of the sponsors have reviewed this preliminary assessment, or have had influence on any of the conclusions of this document. <a href="https://codeocean.com/">CodeOcean</a> currently offers academic users a certain number of monthly free compute hours. <a href="https://wholetale.org/">WholeTale</a> is free to use, though the Stata desktop functionality is not yet publicly available as of the writing of this document in November 2021.</p>

<h2 id="notes">Notes</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Wikipedia. 2021. “List of Linux containers.” <a href="hhttps://en.wikipedia.org/w/index.php?title=List_of_Linux_containers&amp;oldid=1015376890">wikipedia.org/wiki/List_of_Linux_containers</a>, accessed on 2021-07-07. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Docker.com. 2021. “What is a Container.” <a href="https://web.archive.org/web/20210609145942/https://www.docker.com/resources/what-container">docker.com/resources/what-container</a>, accessed on 2021-07-07. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:chroot" role="doc-endnote">
      <p>Wikipedia. 2021a. “chroot”. <a href="https://en.wikipedia.org/w/index.php?title=Chroot&amp;oldid=1044767727">https://en.wikipedia.org/w/index.php?title=Chroot&amp;oldid=1044767727</a>, accessed 2021-11-19. <a href="#fnref:chroot" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:vm" role="doc-endnote">
      <p>Wikipedia. 2021b. “Hardware virtualization”. <a href="https://en.wikipedia.org/w/index.php?title=Hardware_virtualization&amp;oldid=1053629506">https://en.wikipedia.org/w/index.php?title=Hardware_virtualization&amp;oldid=1053629506</a>, accessed 2021-11-19 <a href="#fnref:vm" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:intro" role="doc-endnote">
      <p>Boettiger, Carl. “An Introduction to Docker for Reproducible Research.” ACM SIGOPS Operating Systems Review 49, no. 1 (January 20, 2015): 71–79. <a href="https://doi.org/10.1145/2723872.2723882">https://doi.org/10.1145/2723872.2723882</a>. <a href="#fnref:intro" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:lms" role="doc-endnote">
      <p>Lamadon, Thibaut, Magne Mogstad, and Bradley Setzler. 2022. “<a href="https://www.aeaweb.org/articles?id=10.1257/aer.20190790">Imperfect Competition, Compensating Differentials and Rent Sharing in the U.S. Labor Market.</a>” <em>American Economic Review</em> with <a href="https://github.com/setzler/LMS">Github repository</a> and <a href="https://doi.org/10.24433/CO.7147919.v1">1</a> <a href="https://doi.org/10.24433/CO.3047157.v1">2</a> <a href="https://doi.org/10.24433/CO.4775581.v1">3</a> <a href="https://doi.org/10.24433/CO.3648033.v1">4</a> compute capsules. <a href="#fnref:lms" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Even without using the <code class="language-plaintext highlighter-rouge">checkpoint</code> package, we might use the <a href="https://cran.microsoft.com/snapshot/">MRAN snapshot server</a>, but a faster method is provided by the binary packages provided by the <a href="https://packagemanager.rstudio.com/">Rstudio Public Package Manager</a> used by the Rocker images. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>For additional steps, and complete instructions, see <a href="https://github.com/AEADataEditor/docker-r-starter">github.com/AEADataEditor/docker-r-starter</a> <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:osfortran" role="doc-endnote">
      <p><a href="https://gcc.gnu.org/fortran/">GNU Fortran</a> and various LLVM-based Fortran front-ends are available, see a list at <a href="https://fortran-lang.org/compilers/">fortran-lang.org/compilers/</a>. <a href="#fnref:osfortran" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:commfortran" role="doc-endnote">
      <p><a href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/all-toolkits.html">Intel</a> and <a href="https://www.nag.com/nag-compiler">NAG</a> are popular. <a href="#fnref:commfortran" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:konkol" role="doc-endnote">
      <p>Konkol, Markus, Daniel Nüst, and Laura Goulier. 2020. “Publishing Computational Research - a Review of Infrastructures for Reproducible and Transparent Scholarly Communication.” Research Integrity and Peer Review 5, no. 1 (July 14, 2020): 10. <a href="https://doi.org/10.1186/s41073-020-00095-y">https://doi.org/10.1186/s41073-020-00095-y</a>. <a href="#fnref:konkol" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:konkol:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:rossi" role="doc-endnote">
      <p>Rossi, Barbara. 2021. “Compute Capsule for: Forecasting in the presence of instabilities: How do we know whether models predict [Source Code].” <em>CodeOcean</em>. <a href="https://doi.org/10.24433/CO.7940775.v1">https://doi.org/10.24433/CO.7940775.v1</a>, which accompanies her  article in the Journal of Economic Literature (<a href="https://doi.org/10.1257/jel.20201479">Rossi, 2021</a>), and which is also archived in the more traditional location as Rossi, Barbara. 2021. “Data and Code for: Forecasting in the Presence of Instabilities.” <em>American Economic Association</em> [publisher], <em>Inter-university Consortium for Political and Social Research</em> [distributor]. <a href="https://doi.org/10.3886/E147225V1">https://doi.org/10.3886/E147225V1</a> <a href="#fnref:rossi" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:rossi:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:stefano" role="doc-endnote">
      <p>DellaVigna, Stefano and Devin Pope. 2021. “Compute Capsule for: Stability of Experimental Results: Forecasts and Evidence” [Source Code]. <em>CodeOcean</em>. https://doi.org/10.24433/CO.0687784.v1, which accompanies a <a href="https://doi.org/10.1257/mic.20200129">2022 article in American Economic Journal: Microeconomics</a>, and which is also archived in the more traditional location as DellaVigna, Stefano, and Devin Pope. 2021. “Data and Code for: Stability of Experimental Results: Forecasts and Evidence.” <em>American Economic Association</em> [publisher], <em>Inter-university Consortium for Political and Social Research</em> [distributor]. https://doi.org/10.3886/E135221V1 <a href="#fnref:stefano" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:stefano:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
  </ol>
</div>]]></content><author><name>AEA Data Editor</name></author><category term="FAQ" /><category term="Twitter" /><category term="Docker" /><category term="Code" /><summary type="html"><![CDATA[In reproducibility verification, a common scenario is the author response “but-it-works-on-my-machine”. Finding common environments is important in such situations, to demonstrate that the error does arise, reproducibly, but also to share with the author the exact environment so that the issue can be fixed. Shipping around laptops probably isn’t the right solution. We illustrate how we addressed some of those cases using container technology throughout this post.]]></summary></entry><entry><title type="html">How to prepare replication packages for papers that used confidential data</title><link href="https://aeadataeditor.github.io/posts/2021-11-08-replication-pkg-confidential" rel="alternate" type="text/html" title="How to prepare replication packages for papers that used confidential data" /><published>2021-11-08T00:00:00-05:00</published><updated>2021-11-08T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/replication-pkg-confidential</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-11-08-replication-pkg-confidential"><![CDATA[<p>On a tangent: we get this question regularly - how to prepare replication packages for papers that used confidential data (here: by statistical agencies). A really <a href="https://twitter.com/AeaData/status/1457815800438562828">short thread</a>.</p>

<!-- more -->

<p><img src="/images/img-2021-11-08-1.png" alt="inquiry" /></p>

<p>The very general answer is: The guidance is the same as for any other paper, including with public data:</p>

<blockquote>
  <p>describe where the data came from, describe how others can get the data, provide all the code, describe how to run code, create README for it all.</p>
</blockquote>

<p>The only part that’s different is that getting access to the data WAS complicated for you, and MIGHT be a tad complicated/long/costly/impossible for others. Details, details…</p>

<p>But concretely, here are a few pointers.</p>

<ol>
  <li>First, start with our <a href="https://social-science-data-editors.github.io/template_README/">fabulous template README</a>. Really, it helps! Available at <a href="https://social-science-data-editors.github.io/template_README/">https://social-science-data-editors.github.io/template_README/</a></li>
</ol>

<p><a href="https://social-science-data-editors.github.io/template_README/"><img src="/images/img-2021-11-08-2.png" alt="README" /></a></p>

<ol>
  <li>In order to describe data availability, split into two:
    <ul>
      <li>how did YOU get access to the data, and</li>
      <li>how can OTHERS get access to the same data.</li>
      <li>The two are not always the same, but are both relevant.</li>
    </ul>
  </li>
</ol>

<p>Examples include <a href="https://social-science-data-editors.github.io/guidance/DCAS_Restricted_data.html#us-census-bureau-and-fsrdc">this excellent description</a> from a paper by <a href="https://faculty.tuck.dartmouth.edu/teresa-fort/">Teresa Fort</a> (<a href="https://twitter.com/Tfpiasecki">@Tfpiasecki</a>). Or <a href="https://social-science-data-editors.github.io/guidance/Requested_information_dcas.html#example-for-confidential-data">this description</a> by Fadlon and Nielsen about Danish data</p>

<p>Note: That’s for the data which you <em>cannot</em> share - because it is not yours to share. In general, the statistical agencies, or other providers, control access. You, the author, can only share information about <em>how</em> to access.</p>

<p>Furthermore,  you should also make an archive <em>WITHIN</em> the secure computing facility - of anything that cannot be shared, to the extent permissible, and as long as possible. And then provide information about it in the README.</p>

<ol>
  <li>Code: <strong>All</strong> code needs to be provided - no exceptions! Redactions for security/privacy are OK. Requesting code is standard practice in most secure computing facilities, but might take some time, so do it as soon as possible if you have not already done so.</li>
</ol>

<p>In the unlikely event that you get push back from whatever agency provided you with the data, contact your favorite data editor.</p>

<ol>
  <li>
    <p>All public use data you might have introduced to the secure computing facility are expected to be provided in the replication package, including where they came from. You probably had to describe the provenance anyway in order to import them (most secure computing facilities, such as the US FSRDC or the Canadian CRDCN, require such documentation).</p>
  </li>
  <li>
    <p>Do not forget to cite data! See our <a href="https://social-science-data-editors.github.io/guidance/Data_citation_guidance.html">Guidance on Data Citation</a></p>
  </li>
</ol>

<p>And if you have questions, contact us!</p>]]></content><author><name>AEA Data Editor</name></author><category term="restricted-access" /><category term="administrative" /><category term="replication package" /><summary type="html"><![CDATA[On a tangent: we get this question regularly - how to prepare replication packages for papers that used confidential data (here: by statistical agencies). A really short thread.]]></summary></entry><entry><title type="html">When a reproducibility check turns into a replication exercise</title><link href="https://aeadataeditor.github.io/posts/2021-10-28-reproducibility-restricted-france" rel="alternate" type="text/html" title="When a reproducibility check turns into a replication exercise" /><published>2021-10-28T00:00:00-04:00</published><updated>2021-10-28T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/reproducibility-restricted-france</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-10-28-reproducibility-restricted-france"><![CDATA[<p>I wanted to highlight a particular interesting article in the latest <a href="https://www.aeaweb.org/journals/mic">AEJ: Microeconomics</a> from the perspective of replicability and reproducibility.</p>

<!-- more -->

<blockquote>
  <p>Piveteau, Paul. 2021. “An Empirical Dynamic Model of Trade with Consumer Accumulation.” <em>American Economic Journal: Microeconomics</em>, 13 (4): 23-63. <a href="https://doi.org/10.1257/mic.20190051">https://doi.org/10.1257/mic.20190051</a></p>
</blockquote>

<p><img src="/images/aejmicro-2021-10-piveteau.png" alt="AEJ:Micro 20190051" /></p>

<p><a href="https://paulpiveteau.com/">Paul</a> uses granular (firm-level) French customs data to estimate a model with trade flows. The detailed but confidential French customs data were obtained by Paul many years ago, directly from the French administration. However, by the time the replication package was sent to the AEA Data Editor (me), the French customs agency had (very recently) signed an agreement with <a href="https://www.casd.eu/">CASD (Centre d’accès sécurisé aux données)</a>, the French system for academic use of restricted-access data, making more generalized access to the customs data feasible for future researchers and replicators.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> Furthermore, several years ago, <a href="https://people.hec.edu/perignon/">Christophe Perignon</a> (HEC Paris, <a href="https://twitter.com/christoperignon">@christoperignon</a>) and <a href="https://sites.google.com/view/christophe-hurlin/home">Christophe Hurlin</a> (Université d’Orléans, <a href="https://twitter.com/churlin1804">@churlin1804</a>) created <a href="https://www.cascad.tech/"><em>cascad</em></a>, an organization dedicated to conducting reproducibility checks, including within the confines of the secure environment at CASD.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></p>

<p>We therefore requested that <em>cascad</em> conduct a reproducibility check for the AEA, using the full confidential French customs data available within CASD.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup> And… the first attempt at reproducing even basic statistics failed. The data deposited by the customs agency at CASD many years later were subtly different in several dimensions. While the replicators worked hard to adapt the code to the data structure available to them, we ultimately turned to Paul for help. In the end, pure computational reproducibility was not possible, but a replication using the more recently extracted customs data was feasible.</p>

<p>Jointly, but mostly through Paul’s efforts, the team succeeded in adapting the cleaning and preparation code to the newer data, and ran most of the code successfully. As should be expected when data are somewhat different, some of the results were different, though generally not in a substantial way.  However, some results were not replicable:</p>

<blockquote>
  <p>However, this replication exercise highlighted some numerical fragilities in the algorithm developed to estimate the dynamic model in the paper. In particular, the estimation of the model on the sample of wood exporters (appendix C) could not be performed.</p>
</blockquote>

<p>But instead of either resolving this via (private) correspondence between editors and authors, or letting future replicators find this out the hard way, Paul adopted what I believe is the best approach: acknowledging the limits of the computational reproducibility.</p>

<p>And you do not need to rely on my hearsay - you can read all about it in the summary in <a href="https://assets.aeaweb.org/asset-server/files/15530.pdf#page=36">Appendix H of the online appendix, page 77</a> (from which the quote above is pulled), with the full replication report and all replicated tables and figures by <em>cascad</em> available at in the “<a href="https://doi.org/10.3886/E120070V1-100007">Replication_Fall20</a>” folder in the public replication package.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup></p>

<p>No future replicator can access the data that Paul originally had obtained. But many future replicators (subject to certain conditions) can access the confidential customs data available through CASD. And can request such access with the assurance that the baseline analysis can be replicated (and the replication reproduced), making such requests - costly in time, effort, and money - worth a researcher’s while.</p>

<p>The final outcome is, in my opinion, more transparent than it would have been in many other scenarios, and verified to be more robust than if we had only relied on Paul’s original materials.</p>

<p>We thank Paul for his patience and assistance, and Christophe, Christophe, and Olivier Akmansoy (the replicator at <em>cascad</em>) for their help in conducting this reproducibility check plus replication exercise.</p>

<p>Authors interested in communicating with us about ways to verify reproducibility when the data are confidential can consult our <a href="https://aeadataeditor.github.io/aea-de-guidance/preparing-for-data-deposit.html#structure-in-the-presence-of-confidential-unpublished-data">step-by-step guide</a>.</p>

<h2 id="notes">Notes</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Full disclosure: I (Lars Vilhuber) happen to serve as <a href="https://www.casd.eu/nomination-de-lars-vilhuber-en-tant-que-president-du-conseil-scientifique-du-casd/">chair of the scientific advisory board</a>. However, access to the customs data, and to the services of <em>cascad</em> are open to anyone, and no privileged access or treatment was necessary to obtain the outcomes of this post. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Pérignon, Christophe, Kamel Gadouche, Christophe Hurlin, Roxane Silberman, and Eric Debonnel. 2019. “Certify Reproducibility with Confidential Data.” Science 365, no. 6449: 127–28. <a href="https://doi.org/10.1126/science.aaw2825">https://doi.org/10.1126/science.aaw2825</a>. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>As of the writing of this post, the customs data are not yet listed in the CASD data catalog at <a href="https://www.casd.eu/les-sources-de-donnees-disponibles-au-casd/">https://www.casd.eu/les-sources-de-donnees-disponibles-au-casd/</a>. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>Piveteau, Paul. 2021. “Data and Code for: An Empirical Dynamic Model of Trade with Consumer Accumulation: Replication_Fall20.” <em>American Economic Association [publisher]</em>,  <em>Inter-university Consortium for Political and Social Research [distributor]</em>. <a href="https://doi.org/10.3886/E120070V1-100007">https://doi.org/10.3886/E120070V1-100007</a>. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>AEA Data Editor</name></author><category term="restricted-access" /><category term="AEJ:Micro" /><category term="CASD" /><category term="cascad" /><summary type="html"><![CDATA[I wanted to highlight a particular interesting article in the latest AEJ: Microeconomics from the perspective of replicability and reproducibility.]]></summary></entry><entry><title type="html">Software, code, and repositories</title><link href="https://aeadataeditor.github.io/posts/2021-06-17-software-citations" rel="alternate" type="text/html" title="Software, code, and repositories" /><published>2021-06-17T00:00:00-04:00</published><updated>2021-06-17T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/software-citations</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-06-17-software-citations"><![CDATA[<p>A short thread on software, code, versioning, citation, and repositories. Only very few AEA articles reference Github/Gitlab/Bitbucket repositories. More should do so. A few notes.</p>

<!-- more -->

<h2 id="replication-packages-and-version-control">Replication packages and version control</h2>

<p>Fact: all replication packages contain code.</p>

<p>Note: sometimes, that’s an Excel file, but that’s still code.</p>

<p>But few seem to stem from version control repositories. The most common version control software these days is <code class="language-plaintext highlighter-rouge">git</code>, though I’ve seen a few uses of <code class="language-plaintext highlighter-rouge">svn</code>. Both are popular because they usually come accompanied by online web services that allow authors to showcase their code, as well as conduct a few other key functions that I will get to.</p>

<p>By far the most popular as of 2021 is <a href="https://github.com">Github</a> - in fact, this <a href="https://github.com/AEADataEditor/aeadataeditor.github.io/blob/main/_posts/2021-06-17-software-citations.md">blog post</a> and website are hosted on Github-provided resources. Others include <a href="https://gitlab.com">Gitlab</a>, <a href="https://bitbucket.org">Bitbucket</a>, and for <code class="language-plaintext highlighter-rouge">svn</code>, <a href="https://sourceforge.net/">SourceForge</a>.</p>

<p>Version control allows for, well, version control. This is particularly relevant for replication packages, since code probably is evolving. Which version was used to generate the tables and figures in the paper is very important information.</p>

<p>While authors are able to “lock in” a version that was used when they submit to the AEA Data Editor (via <a href="https://www.openicpsr.org/openicpsr/search/aea/studies">AEA Data and Code Repository</a>), ideally, that version is locked in <strong>prior</strong> to submitting.</p>

<h2 id="locking-in-versions">Locking in versions</h2>

<p>If using version control, creating a “locked in” version that corresponds to a particular version of the paper is easy. It may be called different things (“releases” on Github and in <code class="language-plaintext highlighter-rouge">svn</code>, “tags” in native <code class="language-plaintext highlighter-rouge">git</code>), but it achieves the same function: It marks a particularly version of code.</p>

<p>That <code class="language-plaintext highlighter-rouge">tag</code> can contain additional “metadata” - an “<a href="https://git-scm.com/docs/git-tag">annotated tag</a>” or a “<a href="https://docs.github.com/en/github/administering-a-repository/releasing-projects-on-github/managing-releases-in-a-repository">Github release</a>” can be quite verbose. But in all cases, the key is to uniquely identify the version of the code that was used to do something, or that corresponds to something.</p>

<p>NOTE: strictly speaking, those <code class="language-plaintext highlighter-rouge">tags</code> are not necessary. Authors could simply point to a particular “commit hash”, e.g. “<code class="language-plaintext highlighter-rouge">https://github.com/&lt;user&gt;/&lt;project&gt;/tree/&lt;hash&gt;</code>” to uniquely point to a particular version as well (similarly on <code class="language-plaintext highlighter-rouge">svn</code>, pointing to revision numbers). But <code class="language-plaintext highlighter-rouge">tags</code> are a tad more human readable than <a href="https://github.com/AEADataEditor/replication-template-development/tree/7634e14ee9a0a433db1ab6f25609dfb4c6876483"><code class="language-plaintext highlighter-rouge">https://github.com/AEADataEditor/replication-template-development/tree/7634e14ee9a0a433db1ab6f25609dfb4c6876483</code></a>.</p>

<h2 id="archiving-versions">Archiving Versions</h2>

<p>Once authors have identified a particular version of the code, there remains of course the issue that Github &amp; Co. are not “trusted repositories”. So authors will still need to somehow archive that particular version.</p>

<p>One convenience of using features like “Github releases” or even tags on Github is that the interface provides a convenient link to download a ZIP or TAR file without all the extra <code class="language-plaintext highlighter-rouge">git</code> information.</p>

<p><img src="/images/github-release-screenshot-assets.png" alt="Screenshot of download links on Github release" /></p>

<p>Once you have the ZIP or TAR, you can manually send this off to a trusted repository. That’s what most authors are or should be doing when submitting to the <a href="https://www.openicpsr.org/openicpsr/search/aea/studies">AEA Data and Code Repository</a>, or for that matter for any journal’s supplementary materials archive.</p>

<p>However, that is tedious, and at least for Github, there is a different (automated) option: <a href="https://guides.github.com/activities/citable-code/">linking it to Zenodo</a>. Authors should consult the (very easy) details in the link, but in a nutshell, this is what happens:</p>

<ul>
  <li>you set up the link. Takes a bit of work the first time, but then it’s done, forever.</li>
  <li>every time a release is made, the ZIP file is sent automatically to Zenodo, and creates an archive, with a DOI and a preservation guarantee.
    <ul>
      <li>The Zenodo deposit links back to the particular release/tag on Github</li>
    </ul>
  </li>
  <li>some cosmetic editing (to Zenodo metadata, to eye candy such as a DOI badge) can make it pretty, but are not needed.</li>
</ul>

<h2 id="example">Example</h2>

<p>For an example see</p>

<ul>
  <li>the <a href="https://github.com/social-science-data-editors/template_README/">source code for template README on Github</a>, including any <a href="https://github.com/social-science-data-editors/template_README/releases">releases</a></li>
  <li>the <a href="https://social-science-data-editors.github.io/template_README/">page generated from the source code on Github.io</a></li>
  <li>the “badge”: <a href="https://doi.org/10.5281/zenodo.4319999"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.4319999.svg" alt="DOI badge" /></a></li>
  <li>the <a href="https://doi.org/10.5281/zenodo.4319999">archived version on Zenodo</a></li>
</ul>

<p><img src="/images/zenodo-readme-v1.png" alt="template README on Zenodo" /></p>

<p>The version - in fact, any future version - is now properly archived at a trusted repository.</p>

<h2 id="citing-software-versions">Citing Software Versions</h2>

<p>Last but not least, but in particular when the code authors generated is of more general utility (a Stata or R package for a new econometric technique), <strong>citing the software</strong> is a must (see <a href="https://www.force11.org/software-citation-principles">FORCE11 Software Citation Principles</a>,<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>)</p>

<p>By creating archived versions, Zenodo, or any other trusted repository, provides a DOI that can then be cited:</p>

<blockquote>
  <p>Smith, A. and J. Wesson. 2021. “15-fold quantum fixed effects, R package.” v0.2-alpha. Zenodo. https://doi.org/10.5281/zen0do.12345</p>
</blockquote>

<p>Naturally, authors could also cite the Github-hosted version, but only with the authority of a (transient, ephemerous) website:</p>

<blockquote>
  <p>Smith, A. and J. Wesson. 2021. “15-fold quantum fixed effects, R package.” v0.2-alpha. Github. Last accessed at https://github.com/smith-wesson/cdqfe/releases/tag/v0.2-alpha on June 17, 2025.</p>
</blockquote>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Smith AM, Katz DS, Niemeyer KE, FORCE11 Software Citation Working Group. 2016. Software Citation Principles. <em>PeerJ Computer Science</em> 2:e86. DOI: <a href="https://doi.org/10.7717/peerj-cs.86">10.7717/peerj-cs.86</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>AEA Data Editor</name></author><category term="FAQ" /><category term="Twitter" /><category term="Software" /><category term="Code" /><summary type="html"><![CDATA[A short thread on software, code, versioning, citation, and repositories. Only very few AEA articles reference Github/Gitlab/Bitbucket repositories. More should do so. A few notes.]]></summary></entry><entry><title type="html">File paths in statistical software</title><link href="https://aeadataeditor.github.io/posts/2021-04-09-paths" rel="alternate" type="text/html" title="File paths in statistical software" /><published>2021-04-09T00:00:00-04:00</published><updated>2021-04-09T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/paths</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-04-09-paths"><![CDATA[<p>A short thread (PSA) on a FOC (frequently occurring problem) that shouldn’t be one: file paths in statistical software.</p>

<!-- more -->

<p>Comment in a recent reply to one of our replication reports (note: this was not actually a problem):</p>

<blockquote>
  <p>“We use a HPC and a Linux environment. Therefore, the folders are separated by / and not \ . This might
create problems if working with Windows.”</p>
</blockquote>

<p>Actually, it does not!</p>

<h2 id="stata">Stata</h2>

<p>Every <strong>Stata</strong> user (but in particular those on Windows) should know 👇. Rule: ALWAYS use “<code class="language-plaintext highlighter-rouge">/</code>”, NEVER “<code class="language-plaintext highlighter-rouge">\</code>” and you should be fine.</p>

<p><img src="/images/stata-technical-note-paths.png" alt="Stata note on paths" /></p>

<h2 id="r">R</h2>

<p>use “<code class="language-plaintext highlighter-rouge">file.path('path','file')</code>” or even use packages <a href="https://cran.r-project.org/web/packages/here/vignettes/here.html"><code class="language-plaintext highlighter-rouge">here</code></a> or <a href="https://cran.r-project.org/web/packages/rprojroot/vignettes/rprojroot.html"><code class="language-plaintext highlighter-rouge">rprojroot</code></a>.</p>

<h2 id="matlab">Matlab</h2>

<p>Use “<code class="language-plaintext highlighter-rouge">/</code>” and it will do the right thing.</p>

<p><img src="/images/matlab-paths.png" alt="Matlab paths" /></p>

<h2 id="python">Python</h2>

<p><code class="language-plaintext highlighter-rouge">os.path.join()</code> is your friend</p>

<p><img src="/images/python-paths.png" alt="Python paths" /></p>

<h2 id="others">Others</h2>

<p>And there are likely similar functions in lots of other programming languages and statistical software.</p>

<h2 id="take-away">Take away</h2>

<p>Be aware of and always use the platform independent coding of paths, either a function or using “<code class="language-plaintext highlighter-rouge">/</code>”. NEVER use “<code class="language-plaintext highlighter-rouge">\</code>”.</p>]]></content><author><name>AEA Data Editor</name></author><category term="FAQ" /><category term="Twitter" /><category term="Data" /><category term="Code" /><summary type="html"><![CDATA[A short thread (PSA) on a FOC (frequently occurring problem) that shouldn’t be one: file paths in statistical software.]]></summary></entry><entry><title type="html">What data to provide</title><link href="https://aeadataeditor.github.io/posts/2021-03-31-what-data" rel="alternate" type="text/html" title="What data to provide" /><published>2021-03-31T00:00:00-04:00</published><updated>2021-03-31T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/what-data</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-03-31-what-data"><![CDATA[<p>What do we mean by “data”?</p>

<!-- more -->

<h2 id="what-data-should-be-provided">What data should be provided?</h2>

<p>One of my data editor colleagues at <a href="https://social-science-data-editors.github.io/">Social Science Data Editors</a> relayed a question to me recently (“asking for a friend…”): “do extract files need to be included in AEA data replication submissions?”</p>

<p>They noted “The closest I could find was <a href="https://www.aeaweb.org/journals/data/data-code-policy#content">https://www.aeaweb.org/journals/data/data-code-policy#content</a> which has a blanket request for “data” but it might help to distinguish between “extracts” and “analysis” files.</p>

<h2 id="the-short-answer">The short answer</h2>

<p>It depends.</p>

<ul>
  <li>extract (raw) data can be reliably re-acquired today?</li>
  <li>extract (raw) data can be reliably re-acquired in the future?</li>
  <li>analysis data can be reproduced with reasonable resources?</li>
</ul>

<h2 id="the-longer-answer">The longer answer</h2>

<p>For the raw input data (which may be an extract - that’s actually not the key criterion), we require that the <strong>acquisition</strong> of the data be reproducible.</p>

<p>You don’t have to provide <strong>any</strong> data, if</p>

<ul>
  <li>the results can be reproduced by downloading precisely specified raw data (reasonableness constraint)</li>
  <li>can reproduce analysis files reliably - subject to a reasonableness constraint.</li>
</ul>

<p>But you might also have to provide <strong>all</strong> the data.</p>

<p>Reproducibility, now and in the future, is key, not whether the data is part of the package or not.</p>

<p>But: this is not always straightforward. Take IPUMS as a (frequent) example.</p>

<ol>
  <li>IPUMS curates its entire database (assign a DOI), so the “reliably in the future” part is OK ✅</li>
  <li>But IPUMS has a purely (as of today) manual data extract system. There is no computer code that can reliably re-acquire an extract today or in the (near) future. ❌
    <ul>
      <li>And even manual extraction is fraught with the potential for error (and can be quite tedious)  ❌</li>
    </ul>
  </li>
  <li>And very importantly: providing extracts is allowed by their <a href="https://ipums.org/about/terms">terms of use</a> for MOST but not all of their datasets. ✅</li>
</ol>

<p>We thus prefer to have a copy of IPUMS extracts - and the read-in code, and the data dictionary that they provide with every extract (if you didn’t grab yours, go back into the IPUMS system and download it now!) The AEA’s Data and Code Repository can curate as well as IPUMS, but make the data more easily available, lowering the cost of reproducibility for all future researchers.</p>

<p>If IPUMS were to allow for sharing or archiving of machine-actionable extract specs (not an easy problem), we would reconsider and NOT request extracts!</p>

<h2 id="problems">Problems?</h2>

<p>Of course, there can be impediments. For instance, we would prefer to curate the data when the data provider does NOT curate the data (has no preservation policy, assigns no DOI). But the third condition (terms of use) is just as important, and often prevents us from taking custody of an extract (or even of the analysis data).</p>

<p>We ask for extracts from various online query systems (WDI, OECD, etc.) because the precise query cannot be saved, or is complicated, etc.</p>

<h2 id="solutions">Solutions?</h2>

<p>One obvious solution is for all data query systems to have some system to save or export query code.</p>

<h3 id="psid">PSID</h3>

<p>A nice (simple, but not perfect) example for such a stored-query system is the PSID:</p>

<ol>
  <li>They do curate their database, though no DOIs are assigned, and you need to know to ask (meh… but OK: ✅)</li>
  <li>While they do not assign DOIs to historical queries, you can (as a user) share a query, see <a href="https://simba.isr.umich.edu/DC/c.aspx">https://simba.isr.umich.edu/DC/c.aspx</a>. ✅</li>
  <li>Which is good, since you are not allowed to share the data itself! ❌ (Actually, you can, via <a href="https://www.openicpsr.org/openicpsr/psid">https://www.openicpsr.org/openicpsr/psid</a>)</li>
</ol>

<h2 id="counter-point">Counter point</h2>

<p>The obvious corollary is:</p>

<ol>
  <li>If a data <strong>provider curates the data</strong> (say, at a trusted repository, or with a credible preservation policy) (for which a DOI is a signal, but not a condition) ✅</li>
  <li>and the <strong>data can be downloaded</strong>, or queried through an API<sup id="fnref:API" role="doc-noteref"><a href="#fn:API" class="footnote" rel="footnote">1</a></sup> or something similar ✅</li>
  <li>regardless of their license and terms of use</li>
</ol>

<p>we will <strong>REJECT</strong> your data deposit - please simply leave it where it is!</p>

<p>But cite it, and provide precise instructions on how to get it (if a simple click is not sufficient).</p>

<h2 id="and-those-analysis-files">And those analysis files?</h2>

<p>So when do we want analysis (intermediate) files?</p>

<ul>
  <li>when we cannot <strong>reliably</strong> get the raw data, and there are no issues with redistributing the analysis files</li>
  <li>when the raw data can be redistributed, but are “<strong>too large</strong>” to acquire (at the AEA, that boundary is around 30GB)</li>
  <li>when the raw data can be redistributed, but the analysis data are already the result of a very <strong>resource</strong> (computer count or time) <strong>intensive</strong> processing</li>
</ul>

<p>In all of those cases, we <strong>want</strong> the analysis data.</p>

<p>When do we <strong>NOT want</strong> the analysis data? Well, if the raw data can be trivially acquired (download, API<sup id="fnref:API:1" role="doc-noteref"><a href="#fn:API" class="footnote" rel="footnote">1</a></sup>), and can be reasonably quickly processed, then we (and future researchers) do not need your copy of the analysis data. But it also doesn’t hurt…</p>

<p>BTW, “reasonably” means we are not using more than maybe 50 compute cores. “Quickly” means that it runs no longer than 2-3 weeks - to produce the analysis data.</p>

<h2 id="and-just-contact-us">And just contact us</h2>

<p>In all cases, if you have questions, concerns, or doubts, do contact me - as many others have already done.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:API" role="doc-endnote">
      <p>P.S. That footnote for API? Well, APIs get deprecated over time, so we actually prefer to have the <strong>raw</strong> data saved, but it’s probably OK to skip the analysis data. <a href="#fnref:API" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:API:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
  </ol>
</div>]]></content><author><name>AEA Data Editor</name></author><category term="FAQ" /><category term="Twitter" /><category term="Data" /><summary type="html"><![CDATA[What do we mean by “data”?]]></summary></entry></feed>