<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="https://aeadataeditor.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://aeadataeditor.github.io/" rel="alternate" type="text/html" /><updated>2022-01-13T19:49:09-05:00</updated><id>https://aeadataeditor.github.io/feed.xml</id><title type="html">Office of the AEA Data Editor</title><subtitle>(current: Lars Vilhuber)</subtitle><author><name>AEA Data Editor</name></author><entry><title type="html">Use of Docker for Reproducibility in Economics</title><link href="https://aeadataeditor.github.io/posts/2021-11-16-docker" rel="alternate" type="text/html" title="Use of Docker for Reproducibility in Economics" /><published>2021-11-21T00:00:00-05:00</published><updated>2021-11-21T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/docker</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-11-16-docker"><![CDATA[<p>In reproducibility verification, a common scenario is the author response “but-it-works-on-my-machine”. Finding common environments is important in such situations, to demonstrate that the error does arise, reproducibly, but also to share with the author the exact environment so that the issue can be fixed. Shipping around laptops probably isn’t the right solution. We illustrate how we addressed some of those cases using container technology throughout this post.</p>

<!-- more -->

<blockquote>
  <p>NOTE: There are probably still errors in this post. It will remain draft until the stream of comments has died down…</p>
</blockquote>

<h2 id="what-are-containers">What are containers</h2>

<p>Containers are “implementations of operating system-level virtualization,” <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> typically on Linux. The most common version is provided by <a href="https://docker.com">Docker</a>, but several other implementations exist, such as <a href="https://singularity.hpcng.org/">Singularity</a>. The use of containers as part of replication packages in economics is extremely low, and yet they have some advantages. This post will explore both pre-submission and post-publication uses of containers, as well as several shortcomings.</p>

<p>In a nutshell,</p>

<blockquote>
  <p>“A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another.” <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></p>
</blockquote>

<p>In particular, this means that all dependencies are handled, and there should be virtually no differences across time, users’ operating system, and software implementation in reproducing the outcomes of software.</p>

<p>Containers also isolate the computation from the host system, so that no user-specific settings (stuff you have configured over the past 10 years of working on a project) are carried through into the container, up to a point. That kind of isolation can also be achieved in various ways: for the cognescenti (also called geeks), <code class="language-plaintext highlighter-rouge">chroot</code> environments on Unix systems go back to the early 1980s <sup id="fnref:chroot" role="doc-noteref"><a href="#fn:chroot" class="footnote" rel="footnote">3</a></sup>, and “virtual machines” probably go back to 1960s IBM mainframes <sup id="fnref:vm" role="doc-noteref"><a href="#fn:vm" class="footnote" rel="footnote">4</a></sup>)</p>

<h2 id="containers-and-reproducibility">Containers and reproducibility</h2>

<p>Containers can, but do not necessarily contribute to reproducibility and replicability. For an excellent introduction, see Boettinger (2015) <sup id="fnref:intro" role="doc-noteref"><a href="#fn:intro" class="footnote" rel="footnote">5</a></sup>. Once created, containers can (should) reliably reproduce the context and output they were designed to handle. Because containers typically use a plain-text script for their creation (so-called <code class="language-plaintext highlighter-rouge">Dockerfile</code>), they can contribute to transparency. However, containers can also be interactively created, or incorporate externally created packages, which may lead to some black-box actions that are not transparent. Thus, containers can generate reproducible output, but not be themselves reproducibly created. Furthermore, if containers rely on external resources – for instance, accessing the internet to download data from an API, or installed “latest” packages – the output generated may not be reproduced, though it may still be considered replicable.</p>

<h2 id="containers-in-computational-social-science">Containers in computational social science</h2>

<p>For the (social science) research environment, this should, in principle, handle many of the common problems that workarounds and READMEs list. In this post, we will explore several such cases, in which a computational issue was encountered, debugged leveraging both locally installed and cloud-based containers, and ultimately solved.</p>

<ul>
  <li>Run R through a container</li>
  <li>Run Intel Fortran (or another complex setup) through container</li>
  <li>Run Gurobi through container with a dynamic license</li>
  <li>The Holy Grail in Economics: Run Stata through a container</li>
</ul>

<p>The examples here are based on personal research experience as well as the experience when attempting to conduct reproducibility verifications on nearly 1,000 economics articles. They are by no means meant to be exhaustive or cover all the possible uses of containers. We should note that many of these examples are retro-actively ported to containers, and may not constitute the optimal setup. In our experience with 1,000 economics articles, as of November 2021, we have encountered only 1 (in words: <strong>one</strong>) that used any Docker in their submission to the AEA journals: Lamadon, Mogstad, and Setzler, “Imperfect Competition, Compensating Differentials and Rent Sharing in the U.S. Labor Market”,<sup id="fnref:lms" role="doc-noteref"><a href="#fn:lms" class="footnote" rel="footnote">6</a></sup> who leveraged 4 different CodeOcean compute capsules to support their analyses (we will return to CodeOcean later).</p>

<h2 id="running-r-julia-python-in-docker">Running R, Julia, Python in Docker</h2>

<p>Many of the examples one can find on the Internet sees container used in conjunction with open-source languages. For most statistical and other languages, in particular open-source languages, progress is continuous. In part what attracts researchers to these environments is the rich eco-system of add-on packages and libraries, most of which are available for free as well. However, combining versions of languages, packages, and dependencies to those packages can be a challenge. Use of these can sometimes be tedious - and not easily reproducible - because of a constantly evolving environment and very active development. Various methods exist to “pin” packages used (see <a href="https://cran.r-project.org/package=renv">renv</a>, <a href="https://cran.r-project.org/package=checkpoint">checkpoint</a> and others in R, “environments”, <a href="https://pip.pypa.io/en/stable/reference/pip_freeze/"><code class="language-plaintext highlighter-rouge">pip freeze</code></a> or <a href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#sharing-an-environment"><code class="language-plaintext highlighter-rouge">conda env export</code></a> in Python, <code class="language-plaintext highlighter-rouge">Manifest.toml</code> files and <a href="https://julia.quantecon.org/more_julia/tools_editors.html#Package-Environments">package environments</a> in Julia). These rely, of course, not just on the ability to install the right packages, but also the right base software. In some cases, it can be challenging for users to install multiple base versions simultaneously on their computers - either because they work on multiple projects on their own at different times, or in collaborations with others. This is sometimes necessitated by changes that create breaks between versions (examples include <a href="https://docs.julialang.org/en/v1.4/NEWS/#Standard-library-changes-1">changes in random number generators in Julia</a> and <a href="https://blog.revolutionanalytics.com/2020/04/r-400-is-released.html">certain breaks in R when version 4.0 was introduced</a>). Programmatic solutions for this exist, of course, but add complexity to an often complex set of programs.</p>

<p>Thankfully, that same open-source community has also provided containers that lock in some of the base software versions, facilitating the simultaneous maintenance of multiple versions of the same software. We illustrate this with an example that we have used in some reproducibility cases with R. It addresses the particular use case of having multiple versions of R, but does not pin the particular package versions. See the tutorials for  <a href="https://cran.r-project.org/package=renv">renv</a> and <a href="https://cran.r-project.org/package=checkpoint">checkpoint</a> for even finer control.</p>

<h3 id="a-really-simple-example-with-r">A Really Simple Example with R</h3>

<p>To start, we identify from instructions provided by the author both the version of R and the required packages. From the required packages, we use a standard <a href="https://github.com/AEADataEditor/docker-r-starter/blob/main/setup.R">setup program</a> and add those libraries to the list of dependencies.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">7</a></sup> We then leverage the <a href="https://hub.docker.com/u/rocker">R Docker images</a> maintained by the <a href="https://github.com/rocker-org/rocker">Rocker group</a>, and build a custom R Docker image that should have all dependencies as articulated by the authors:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Dockerfile</code>:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FROM rocker/r-ver:4.0.1

COPY setup.R .
RUN Rscript setup.R
</code></pre></div></div>
<p>That’s already all there is to creating a Docker image! Of course, it now needs to be built:<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">8</a></sup></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DOCKER_BUILDKIT=1 docker build . -t $MYHUBID/$MYIMG:$TAG
</code></pre></div></div>

<p>where I have previously configured some environment variables for ease of notation and reference:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TAG=v$(date +%F)
MYIMG=aer-9999-8888
MYHUBID=aeadataeditor
</code></pre></div></div>

<p>This locks in our R environment, at the time of building (<code class="language-plaintext highlighter-rouge">$TAG</code>). It is then straightforward to run the authors’ code, reliably, over and over again:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd path/to/code
docker run -it --rm -v $(pwd)/subdir:/code -w /code $MYHUBID/${MYIMG}:$TAG Rscript main.R
</code></pre></div></div>

<p>Note that for each project, we can specify a different R version (<code class="language-plaintext highlighter-rouge">rocker/r-ver:4.0.1</code>), and we can even, for the same project, test the reproducibility with multiple R versions, by building multiple images (we might need to refine our tagging for that to work).</p>

<p>Furthermore, if we run into reproducibility discrepancies, we can share the resulting (public) Docker image and the “very simple” instructions with the authors. In doing so, we reproducibly share the failure to reproduce. We have done so, in fact, in several cases, though we will describe that particular type of interaction in the next section, in somewhat more challenging cases.</p>

<p>All we need is Docker as a software installation on our workstation. Or: in the cloud.</p>

<h2 id="running-docker-the-cloud-way">Running Docker the Cloud way</h2>

<p>Numerous cloud computing providers facilitate running Docker. Some might call it an “app” that you are running, others may require you to boot up a Linux VM before running Docker, the mechanisms vary substantially. In many instances, you may need to worry about how to recover the results once the Docker image has finished running your code, and both data and code will likely need to be embedded in the Docker image, something not addressed here.</p>

<p>One innovation that multiple authors have recently pointed to is the July 2021 release of “Github Codespaces.” Subject to some conditions, anyone can easily run arbitrary Docker images in the cloud. We illustrate this using a <a href="https://github.com/labordynamicsinstitute/reproducibility-confidential">reproducible environment to conduct a tutorial</a> (readers might want to consult the tutorial for several other reasons as well).</p>

<p>The tutorial is programmed in R, leverages R-generated HTML slides (<code class="language-plaintext highlighter-rouge">ioslides</code>). Relevant for the point here is that the tutorial is intended to be conducted interactively. To do that, after having <a href="https://docs.github.com/en/codespaces/managing-codespaces-for-your-organization/enabling-codespaces-for-your-organization">enabled Codespaces for the organization</a>, we select and launch a codespace - essentially, a cloud-computer running our code.</p>

<p><img src="/images/github-codespaces-1.png" alt="Launching Codespaces" /></p>

<p>After choosing a size (which can go up to a 16-core/ 32GB RAM server), the system launches into a simple Linux shell, with the source git repository already checked out</p>

<p><img src="/images/github-codespaces-2.png" alt="Launching Codespaces" /></p>

<p>Docker comes into play here because we want to use a Rstudio instance in the cloud, already set up the way we need it to be. The build script does most of the original legwork for us, and once in the cloud, all we need to do is to launch the pre-configured (reproducible!) Docker instance, loaded with our libraries and code:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run \
   -e PASSWORD=testing \
   -v $WORKSPACE:/home/rstudio \
   --rm -p 8787:8787 $dockerspace/$repo
</code></pre></div></div>
<p>which we do straight from the cloud command line:</p>

<p><img src="/images/github-codespaces-3.png" alt="Launching docker" /></p>

<p>The docker command again downloads the image components from the Docker Hub, and runs the Rstudio instance:</p>

<p><img src="/images/github-codespaces-4.png" alt="Launching docker" /></p>

<p>Codespaces detects that we are running a webserver within the Docker image, and prompts us to connect to it:</p>

<p><img src="/images/github-codespaces-5.png" alt="Launching Rstudio" /></p>

<p>This is an example of reproducibility for interactive uses, but would apply in much the same way if all we wanted to do is run some R code repeatedly, or reproducibly. In fact, that is exactly what a separate functionality (Github Workflow/Actions) does to generate the slides for this particular tutorial, something left for next time (but see the <a href="https://github.com/labordynamicsinstitute/reproducibility-confidential/blob/main/.github/workflows/main.yml">workflow configuration file</a> for the tutorial). We will come back to this later.</p>

<h2 id="compiling-fortran-code-through-a-container">Compiling Fortran code through a container</h2>

<p>Compilers are the workhorses for high-performance computing, and many economists will program compute-intensive routines in Fortran, then compile and run such code. Both open-source <sup id="fnref:osfortran" role="doc-noteref"><a href="#fn:osfortran" class="footnote" rel="footnote">9</a></sup> and commercial<sup id="fnref:commfortran" role="doc-noteref"><a href="#fn:commfortran" class="footnote" rel="footnote">10</a></sup> are available. We describe two use cases for using Fortran in combination with Docker.</p>

<h3 id="ce-fortran">CE Fortran</h3>

<p>In many cases, compilers require the presence of many separate libraries, and installation is traditionally complicated. The <a href="https://www.ce-fortran.com/">CE-Fortran</a> project (“Computational Economics using Fortran”, Hans Fehr and Fabian Kindermann) trains and guides economists using open source <a href="https://gcc.gnu.org/fortran/">GNU Fortran</a>.</p>

<p><img src="/images/ce-fortran-webpage.png" alt="CE Fortran" /></p>

<p>They have traditionally provided detailed installation instructions for all three operation systems, striving to make the development environment as comparable as possible across all three. More recently, the authors have started providing a Docker image to provide a consistent environment, see <a href="https://github.com/fabiankindermann/ce-fortran/tree/main/installation/docker/docker_base">their Github page</a>.</p>

<p>Nevertheless, some of the issues cannot be fully handled in a Docker image. For instance, while the environment in the base Docker image can create images, it cannot be used to provide an IDE or for manipulating images interactively. For this purpose, the authors provide a second, much <a href="https://github.com/fabiankindermann/ce-fortran/tree/main/installation/docker/docker_vnc">larger Docker image</a> that includes a workaround (a VNC server).</p>

<h3 id="intel-fortran">Intel Fortran</h3>

<p>A second scenario is frequently encountered among the AEA’s replication packages. Many authors, particularly in macroeconomics, use Intel Fortran compilers. While installation instructions have been streamlined, they remain onerous: the most recent Windows installation instructions rely on a two installers, and have a dependency on Microsoft Visual Studio - a separate installer - which in turn has multiple additional dependencies. Furthermore, authors rarely use Makefiles, a way to compile code and address dependencies commonly used in the open source community, and only sometimes use Windows-specific Visual Studio Project files. The typical instruction, repeated dozens of times, looks like this:</p>

<p><img src="/images/README_page07.png" alt="Compiler instruction" /></p>

<p>with subsequent instructions to manually run the compiled code. Such instructions are inefficient, and potentially error prone.</p>

<h3 id="a-fortran-docker-example">A Fortran Docker Example</h3>

<p>In reproducing a recent paper, we instead opted to streamline the process, making for a more efficient reproducibility check, and also – if the authors were to adopt this process – a more efficient development process.</p>

<ol>
  <li>Using scripting tools, we extracted all of the <code class="language-plaintext highlighter-rouge">ifort</code> commands from the README PDF (34 lines)</li>
  <li>We manually inserted the relevant directories, and added code to automatically run the compiled binary.</li>
  <li>The resulting script file (<code class="language-plaintext highlighter-rouge">run_all.sh</code>) looks like this (in <code class="language-plaintext highlighter-rouge">bash</code> notation - this could also be done as a Windows <code class="language-plaintext highlighter-rouge">bat</code> file):</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Code to run models 
# Author: Lars Vilhuber
# Based on instructions in the paper's replication package
# NOTE: this should really be a Makefile!
# Capture base folder

BASE=$(pwd)

# Compiler options

IFORTOPTS=" -qopenmp"

# Figure 1A

cd $BASE/rep_agent_models/tc_model_nongrace

time ifort $IFORTOPTS rep_tc_delta_array.f90 rouwenhorst.f90 \
  -o rep_tc_delta_array.exe &amp;&amp; time ./rep_tc_delta_array.exe 

cd $BASE/rep_agent_models/tc_model_grace

time ifort $IFORTOPTS rep_tc_grace_delta_array.f90 rouwenhorst.f90 \
  -o rep_tc_grace_delta_array.exe &amp;&amp; time ./rep_tc_grace_delta_array.exe 

# and so on...
</code></pre></div></div>

<h4 id="simplicity">Simplicity</h4>

<p>Once we had the script, we used the <a href="https://hub.docker.com/r/intel/oneapi-hpckit/tags?page=1&amp;ordering=last_updated">Intel OneAPI-hpckit</a> (required 23GB of disk space, compared to the 24GB that the Windows install would have taken):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker pull intel/oneapi-hpckit:2021.2-devel-ubuntu18.04
</code></pre></div></div>

<ol>
  <li>Ran master script through the docker image
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd PATH/model_codes
docker run --rm -it -w /code \
  -v $(pwd):/code intel/oneapi-hpckit:2021.2-devel-ubuntu18.04 \
  /code/run_all.sh &gt; run_all.output.txt
</code></pre></div>    </div>
  </li>
</ol>

<p>This generated about 100 output files, without any further manual intervention. There is no separate installation process for the Intel compilers, a simple <code class="language-plaintext highlighter-rouge">docker pull</code> command allowed us to run all of the required files, within a few minutes.</p>

<h4 id="flexibility">Flexibility</h4>

<p>When one of the compile steps required a larger memory size (25GB) than our workstation had available (23GB), we simply re-ran the following three steps on a general purpose server we had never before used for this purpose (but which already had Docker installed):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git pull (URL of the reproducibility repository)
cd PATH/model_codes
docker run --rm -it -w /code \
  -v $(pwd):/code \
  intel/oneapi-hpckit:2021.2-devel-ubuntu18.04 \
  /code/run_all.sh &gt; run_all.output.txt
</code></pre></div></div>
<p>(the <code class="language-plaintext highlighter-rouge">docker pull</code> command is automatically executed by the <code class="language-plaintext highlighter-rouge">docker run</code> command if the image is not locally available).</p>

<h4 id="thoughts">Thoughts</h4>

<p>When using a container for the task of running these (fairly standard) types of structural models, we gained robustness and simplicity. Instead of a complex and manual Windows install specific to this type of project, we had a very simple way to run the author-provided code. The “transparency boundary” remains unchanged: the reliance on the proprietary (non-open source) Intel compiler, whether installed as a Windows installer, or obtained via a Intel-provided Docker image, is conceptually similar, and similarly opaque.</p>

<h2 id="running-docker-the-easy-way">Running Docker the Easy Way</h2>

<p>Of course, this may all seem overwhelming and complicated, as any new piece of software. Which is why several services are available that make this all a lot easier. These include <a href="https://codeocean.com/">CodeOcean</a>, <a href="https://wholetale.org/">WholeTale</a>, <a href="https://mybinder.org/">Binder</a>, and others (see Konkol et al, 2020,<sup id="fnref:konkol" role="doc-noteref"><a href="#fn:konkol" class="footnote" rel="footnote">11</a></sup> for a broader overview). Behind the scenes, these use containers as well, sometimes built on the fly, but also able to archive the containers, ensuring persistence of what hopefully are reproducible containers.</p>

<p>We have started to use these services to enable reproducibility verification in an environment which allows us, when the time inevitably arrives, to share the exact environment with the authors in order to debug code. In contrast with the statement “Author, please use this Docker image to reproduce the issue”, the request “Author, please click on this URL to reproduce the issue” is much simpler. Several authors have been offered both options (no RCT…), and have generally preferred the option of an online easy interface to the ability to run Docker or Singularity locally.</p>

<p>And we have started to leverage the ability to also publish these reproducible artifacts. Recent examples include Rossi (2021)<sup id="fnref:rossi" role="doc-noteref"><a href="#fn:rossi" class="footnote" rel="footnote">12</a></sup> and DellaVigna and Pope (2021)<sup id="fnref:stefano" role="doc-noteref"><a href="#fn:stefano" class="footnote" rel="footnote">13</a></sup>. In both cases, we were able to populate the <a href="https://doi.org/10.24433/CO.7940775.v1">CodeOcean</a> <a href="https://doi.org/10.24433/CO.0687784.v1">capsule</a> when we ran into reproducibility issues, sharing it (via a URL) with the authors, and solving the issue that both satisfied the AEA Data Editor, and is likely to satisfy future replicators as well.</p>

<p>We are working with the <a href="https://wholetale.org/">WholeTale</a> on similar usage scenarios, and are open to working with authors’ choices whereever those may lead.</p>

<p>One key aspect here is worthwhile highlighting. In contrast to some other online computational platforms, for instance <a href="https://colab.research.google.com/">Google Colab</a>, the ability to download (nearly) the entire reproducible environment, not just the code, and archive it, are key. That does not mean that they are automatically “fully reproducible”. They may still be missing some key elements that replicators will need to contribute, such as licenses.</p>

<h2 id="licenses">Licenses</h2>

<p>Most examples out there use open source software, not requiring licenses. This is an issue in economics, where the most common software used - Stata, Matlab - are proprietary and require licenses. Luckily, there are many ways to include licenses in Docker images at runtime, or, if using them internally within a research group, embedding licenses within the Docker image, as one would install a license in any “real” computer. The online systems mentioned above sometimes provide access to such licenses as well. We briefly illustrate first the easy, online way to incorporate licenses into container-based workflows, and then two “hard” ways.</p>

<h3 id="an-example-using-stata-licenses-and-the-easy-way">An example using Stata, licenses, and the “Easy Way”</h3>

<p>Bringing many of the issues alluded to earlier together, we have successfully leveraged this “toolkit” to improve the reproducibility and accessibility of Stata-based replication packages. Stata is used by the vast majority of economists, so being able to handle this scenario is important, but it also illustrates how licensed software can be used with containers.</p>

<p><a href="https://aeadataeditor.github.io/aea-supplement-migration/programs/aea201910-migration.html"><img src="https://github.com/AEADataEditor/aea-supplement-migration/raw/530f1e9ad8059e68815b5836db33155c990154b0/programs/figure_software_years_pct.png" alt="Stata usage at AEA journals" /></a></p>

<p>The easiest way is to use an online system that provides such access. The first to our knowledge was <a href="https://codeocean.com/">CodeOcean</a>. Simply choosing one of the configured Stata images will create a Docker image with Stata:</p>

<p><img src="/images/codeocean-choice.png" alt="Stata choice" /></p>

<h3 id="hard-to-nail-down-failure-to-compute">Hard-to-nail down failure to compute</h3>

<p>This is the environment we used to work with the authors to create the reproducible package for DellaVigna and Pope (2021). We were able to work exclusively within CodeOcean’s environment, debugging a tenacious problem that wasn’t easy to diagnose. But we also wanted to make sure that the resulting replication package is not reliant on CodeOcean’s infrastructure. The authors debugged the code on CodeOcean (yielding the <a href="https://doi.org/10.24433/CO.0687784.v1">published capsule</a>). We  then verified the <a href="https://doi.org/10.3886/E135221V1-101800">instructions to re-run the replication package</a> downloaded from CodeOcean on a personal workstation, emulating a somewhat typical economist. We  also populated the official replication package on openICPSR with the same code (<a href="https://doi.org/10.3886/E135221V1">https://doi.org/10.3886/E135221V1</a>). This is strictly speaking not necessary, since CodeOcean is a trusted repository, and assigns DOIs, but for now, we make it easier to discover this way.</p>

<p>After downloading the CodeOcean capsule (<code class="language-plaintext highlighter-rouge">57033059-76d7-422d-8301-d173e3520f07.zip</code>), or equivalently, the openICPSR deposit, the following straightforward code (mostly documented in the CodeOcean-provided <code class="language-plaintext highlighter-rouge">REPRODUCING.md</code>) reproduces the paper’s outputs perfectly:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>unzip 57033059-76d7-422d-8301-d173e3520f07.zip 
cd environment/
# Need the Stata license
cp /path/to/statalicense/stata.lic.16 stata.lic
# Build the image - note, requires CodeOcean provided image. Could be replaced with the dataeditors/stata16 image
DOCKER_BUILDKIT=1 docker build . \
  --tag 57033059-76d7-422d-8301-d173e3520f07
cd ..
# Ensure the script is runnable - this is not documented
chmod a+rx code/run 
docker run --rm   \
  --workdir /code   \
  --volume "$PWD/environment/stata.lic":/usr/local/stata/stata.lic   \
  --volume "$PWD/data":/data   \
  --volume "$PWD/code":/code   \
  --volume "$PWD/results":/results  \ 57033059-76d7-422d-8301-d173e3520f07 \
  ./run
</code></pre></div></div>

<h2 id="challenges">Challenges</h2>

<h3 id="big-data">Big data</h3>

<p>Since a container is meant to package up all necessary dependencies, it would seem logical that one could include all data. However, this breaks down when the data are large, even before getting into “big data” territory. The typical Docker image is no larger than 2-3 GB. Thus, the issues that plague  reproducibility when data are large - delays in downloading or streaming data, availability of local space - are not solved by containers. That being said, satisfying the software dependencies is a first step in making sure that reproducibility can be achieved. Thus, a variant of the above way to run a Docker image could also be used in the presence of big data, by mounting the local storage directory for the data:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run --rm   \
  --workdir /code   \
  --volume "$PWD/data":/data   \
  --volume "/path/to/BIG/DATA:/bigdata \
  --volume "$PWD/code":/code   \
  --volume "$PWD/results":/results  \ 
  researcherhub/papercontainer \
  ./run
</code></pre></div></div>

<h3 id="licenses-not-provided">Licenses not provided</h3>

<p>Most of the “easy” systems are easy because they can accomodate a limited set of customizations. For instance, one can specify some post-install scripts on various platforms, but not choose an unsupported software image. But when the software requires additional licenses, a tension arises between publishing the successfully run image with an embedded license, and providing a template implementation that requires provision of a license.</p>

<p>Mathworks has gone the latter route, providing a <a href="https://hub.docker.com/r/mathworks/matlab">Matlab Docker image</a> without a license, and then providing instructions on how to provision the container with a valid license, for instance within a university’s internal network with a network server. Internally, WholeTale and CodeOcean use a similar mechanism behind the scenes.</p>

<p>Stata does not provide Docker image, but has allowed the AEA Data Editor to provide <a href="https://hub.docker.com/u/dataeditors">license-less Docker images for Stata</a>. The <a href="https://github.com/AEADataEditor/docker-stata">instructions provided</a> identify various ways a license can be provisioned to the image, so that code can be run:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run -it --rm \
  -v ${STATALIC}:/usr/local/stata/stata.lic \
  -v $(pwd)/code:/code \
  -v $(pwd)/data:/data \
  -v $(pwd)/results:/results \
  $MYHUBID/${MYSTATAIMG}:${TAG}
</code></pre></div></div>

<p>In effect, users can simply use their own Stata license to enable a Stata Docker image. Again, WholeTale and CodeOcean use a similar mechanism behind the scenes, but the fact that any Stata user can re-execute such a Docker image with a valid Stata license is no more constraining that having installed Stata on their own computer.</p>

<p>In other circumstances, expiring licenses may be used. In a case where we needed to install <a href="https://www.gurobi.com/academia/academic-program-and-licenses/">Gurobi</a> together with R, we used a new feature provided by Gurobi to provide “<a href="https://www.gurobi.com/web-license-service/">web licenses</a>.” These can be disabled from a dashboard, and naturally expire after a while. Thus, our CodeOcean “postInstall” script installed Gurobi into a R container, then hard-coded a license key:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget -v https://packages.gurobi.com/${GRB_SHORT_VERSION}/gurobi${GRB_VERSION}_linux64.tar.gz \
    &amp;&amp; tar -xvf gurobi${GRB_VERSION}_linux64.tar.gz  \
    &amp;&amp; rm -f gurobi${GRB_VERSION}_linux64.tar.gz \
    &amp;&amp; mv -f gurobi* gurobi \
    &amp;&amp; rm -rf gurobi/linux64/docs


cd /opt/gurobi/linux64
#run the setup
python3.7 setup.py install

# Add the license key
# For replication purposes, this will need to be re-initialized, as post-publication, this key was disabled.
# You will need to provide your own.
echo "
WLSACCESSID=96388c95-2a7f-4195-88af-b167b077c019
WLSSECRET=ef818954-18ed-43f5-84b0-ace17641fd18
LICENSEID=6521234
" &gt; /opt/gurobi/gurobi.lic
</code></pre></div></div>

<p>Once published, simply disabling the key on the Gurobi dashboard would prevent any unauthorized use of the license. Alternatively, of course, the method used for the Stata license above would also work outside of the CodeOcean environment, by using</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run -it --rm \
  -v gurobi.lic:/opt/gurobi/gurobi.lic \
  -v $(pwd)/code:/code \
  -v $(pwd)/data:/data \
  -v $(pwd)/results:/results \
  $MYHUBID/${MYGUROBIIMG}:${TAG}
</code></pre></div></div>
<p>Thus, generically, licensed software can very well be used when the proprietary software provider allows for redistribution of the binary portion of the software in the form of “opaque” containers; however, in many circumstances, the “easy” online providers of such container-based services can make it non-trivial to implement.</p>

<h3 id="complex-interactions-between-software">Complex interactions between software</h3>

<p>Finally, as one example where limitations are hard to address ex-post, we highlight an example where researchers called a separately compiled Fortran binary from within Matlab. While each software could easily be run in its own container, it becomes non-trivial (but not impossible) to use multiple containers in this way.</p>

<p>The solution, as evidenced by the Gurobi example earlier, consists in installing one software into a container provided by the other. This, however, may lose the advantages of using pre-configured containers that avoid complex installation procedures, as in the case of Matlab and Intel compilers. An alternative (not tested) might consist in leveraging <a href="https://docs.docker.com/develop/develop-images/multistage-build/">multi-stage builds</a>, where entire portions are copied from one container into another. This is beyond the scope of the “easy” web-based solutions (though it may be on their development plan). However, precisely because a knowledgeable researcher can handle the (now much more complex) container creation, future users may not have to. By publishing the associated <code class="language-plaintext highlighter-rouge">Dockerfiles</code>, <a href="https://github.com/AEADataEditor/docker-r-starter/blob/main/Dockerfile">simple</a> or more <a href="https://github.com/AEADataEditor/docker-r-gurobi/blob/main/Dockerfile">complex</a>, future users do not need to reinvent the wheel - one of the purposes of the transparency that reproducibility fosters.</p>

<h3 id="continuous-integration">Continuous integration</h3>

<p>Containers are also a tool for continuous integration - the software engineering best practice to test software at every step - but which can also be used to streamline research analyses. Consider the scenario where all data is available in a researcher’s Git repository (because of course, the researcher is using a Git repository). Containers can then be leveraged to create output - a research article, preliminary analyses, or a number of webpages. For instance, many researchers now use R in combination with Markdown to create “dynamic documents”. The (perenially incomplete) <a href="https://labordynamicsinstitute.github.io/replicability-training-curriculum/">training manual for our undergraduate replicators</a> is “built” this way, using the great <a href="https://pkgs.rstudio.com/bookdown/"><code class="language-plaintext highlighter-rouge">bookdown</code> package</a> by Yihui Xie, using a simple preconfigured container:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     - name: Run docker for R 
        uses: docker://larsvilhuber/ideahandbook:latest
        with:
          args: "/github/workspace/_build.sh publish"
</code></pre></div></div>

<p>(see the <a href="https://github.com/labordynamicsinstitute/replicability-training-curriculum/blob/master/.github/workflows/main.yml">Github Action workflow file</a> for full details)</p>

<h3 id="graphical-utilities">Graphical utilities</h3>

<p>Some of the “easy” online systems do not provide the native coding environment that many users are used to, for instance the Matlab or Stata desktop applications. This makes it harder, in fact, for such researchers to adapt to these tools. We regularly observe code or instructions that use visual inspection of the results, or leverage other features only available in a full graphical environment. This is less a concern for more recent (and typically open source) software, such as R (availability of Rstudio as a web service), Python, and Julia (Jupyter notebooks). However, WholeTale is trialling (with assistance from us) a combination of reproducible “tale” combined with a graphical user interface for Stata. The <a href="https://hub.docker.com/r/mathworks/matlab">Matlab Docker image</a> provides a graphical interface, as does one of the <a href="https://github.com/fabiankindermann/ce-fortran/tree/main/installation/docker/docker_vnc">CE-Fortran docker images</a>, so these are not fundamentally problems.</p>

<h2 id="preliminary-conclusion">(Preliminary) Conclusion</h2>

<p>Containers provide a way to share computational environments in an efficient way, to make such environments robust to changes in the underlying software, and to publish the fully transparent methods that lead to such containers. They are, however, underutilized in economics replication packages and by economics researchers. This document has provided a few scenarios that illustrate cases where the use of containers can help improve reproducibility.</p>

<h2 id="resources">Resources</h2>

<p>So is this all rocket science? While I’m sure that the rocket scientists use containers, it isn’t really that complicated. Here is a (almost surely incomplete) list of a few resources to get you started:</p>

<h3 id="economics-articles-and-replication-packages-using-docker">Economics Articles and Replication Packages using Docker</h3>

<ul>
  <li>Rossi (forthcoming in JEL): “Forecasting in the presence of instabilities: How do we know whether models predict”<sup id="fnref:rossi:1" role="doc-noteref"><a href="#fn:rossi" class="footnote" rel="footnote">12</a></sup></li>
  <li>DellaVigna and Pope (<a href="https://www.aeaweb.org/articles?id=10.1257/mic.20200129">forthcoming in American Economic Journal: Microeconomics</a>) “Stability of Experimental Results: Forecasts and Evidence”<sup id="fnref:stefano:1" role="doc-noteref"><a href="#fn:stefano" class="footnote" rel="footnote">13</a></sup></li>
  <li>Bonhomme, Lamadon, and Manresa (forthcoming Econometrica): “A distributional Framework for matched employer-employee data”, <a href="https://github.com/tlamadon/blm-replicate">Github repository</a></li>
  <li>Sergio Firpo, Vitor Possebom. 2018. “Synthetic Control Method: Inference, Sensitivity Analysis and Confidence Sets” Journal of Causal Inference 6.2, <a href="https://doi.org/10.1515/jci-2016-0026">https://doi.org/10.1515/jci-2016-0026</a>. <a href="https://doi.org/10.24433/CO.23bd238f-38c5-4b3e-82f4-3a1624fd8a33">Compute Capsule at CodeOcean</a></li>
  <li>Matias D. Cattaneo, Nicolás Idrobo, Rocío Titiunik. 2018.  “A Practical Introduction to Regression Discontinuity Designs: Volume I” <a href="https://doi.org/10.24433/CO.263b2a1e-bbc1-45c9-af03-23ac11032950">Compute Capsule at CodeOcean</a></li>
</ul>

<h3 id="tutorials">Tutorials</h3>

<ul>
  <li><a href="https://raw.githack.com/uo-ec607/lectures/master/13-docker/13-docker.html#1">Grant McDermott’s EC 607 graduate course, Docker lesson</a></li>
  <li><a href="https://carpentries-incubator.github.io/docker-introduction/index.html">Carpentries tutorial on Docker</a></li>
  <li>Installing Docker on a <em>managed</em> Windows system can be challenging, and my poor colleagues Michael Darisse and Leonel  Borja Plaza have suffered through it for you to bring you <a href="https://github.com/labordynamicsinstitute/replicability-training/blob/master/Docker_Windows.md">this tutorial</a>.
    <ul>
      <li>Installing Docker on a Linux system, on the other hand, can be as simple as <code class="language-plaintext highlighter-rouge">yum install docker</code>.</li>
      <li>The command line can help on  Mac as well: <a href="https://www.cprime.com/resources/blog/docker-on-mac-with-homebrew-a-step-by-step-tutorial/"><code class="language-plaintext highlighter-rouge">brew install docker</code></a>.</li>
    </ul>
  </li>
</ul>

<h3 id="examples-and-images">Examples and Images</h3>

<ul>
  <li><a href="https://github.com/AEADataEditor/docker-stata">Stata as Docker</a></li>
  <li><a href="https://github.com/AEADataEditor/docker-r-gurobi">R and Gurobi as Docker</a></li>
  <li><a href="https://hub.docker.com/r/mathworks/matlab">Matlab Docker image</a></li>
  <li><a href="https://www.rocker-project.org/">Rocker project</a></li>
  <li><a href="https://hub.docker.com/r/intel/oneapi-hpckit/tags?page=1&amp;ordering=last_updated">Intel OneAPI-hpckit</a></li>
</ul>

<h3 id="tools">Tools</h3>

<h4 id="r-centric">R-centric</h4>

<ul>
  <li><a href="https://o2r.info/containerit/">containerit</a></li>
  <li><a href="https://www.rocker-project.org/">Rocker project</a></li>
  <li><a href="https://dirk.eddelbuettel.com/papers/cologneRUG2020.pdf">Dirk Eddelbuettel’s tutorial</a></li>
</ul>

<h4 id="git-centric">Git-centric</h4>

<ul>
  <li><a href="https://repo2docker.readthedocs.io/en/latest/">repo2docker</a></li>
  <li><a href="https://docs.github.com/en/codespaces/managing-codespaces-for-your-organization/enabling-codespaces-for-your-organization">Github Codespaces</a></li>
</ul>

<h3 id="services">Services</h3>

<p>These are the services listed in Konkol et (2020)<sup id="fnref:konkol:1" role="doc-noteref"><a href="#fn:konkol" class="footnote" rel="footnote">11</a></sup> that use Docker</p>

<ul>
  <li><a href="https://codeocean.com">CodeOcean</a></li>
  <li><a href="https://mybinder.org/">Binder</a></li>
  <li><a href="https://wholetale.org/">WholeTale</a></li>
</ul>

<p>as well as more recent</p>

<ul>
  <li><a href="https://docs.github.com/en/codespaces/managing-codespaces-for-your-organization/enabling-codespaces-for-your-organization">Github Codespaces</a></li>
</ul>

<p>and</p>

<ul>
  <li><a href="https://gigantum.com/">Gigantum</a> (not tested)</li>
</ul>

<p>as well as many cloud service providers.</p>

<h2 id="disclosures">Disclosures</h2>

<p>We received a generous compute and storage quota from <a href="https://codeocean.com/">CodeOcean</a>, a free license to use Stata 17 for one year in cloud applications from <a href="https://stata.com">Stata</a>, and a subaward on NSF grant <a href="https://nsf.gov/awardsearch/showAward?AWD_ID=1541450&amp;HistoricalAwards=false">1541450</a> “<em>CC*DNI DIBBS: Merging Science and Cyberinfrastructure Pathways: The Whole Tale</em>” from the University of Illinois to evaluate the platform for the purpose of reproducibility verification. None of the sponsors have reviewed this preliminary assessment, or have had influence on any of the conclusions of this document. <a href="https://codeocean.com/">CodeOcean</a> currently offers academic users a certain number of monthly free compute hours. <a href="https://wholetale.org/">WholeTale</a> is free to use, though the Stata desktop functionality is not yet publicly available as of the writing of this document in November 2021.</p>

<h2 id="notes">Notes</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Wikipedia. 2021. “List of Linux containers.” <a href="hhttps://en.wikipedia.org/w/index.php?title=List_of_Linux_containers&amp;oldid=1015376890">wikipedia.org/wiki/List_of_Linux_containers</a>, accessed on 2021-07-07. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Docker.com. 2021. “What is a Container.” <a href="https://web.archive.org/web/20210609145942/https://www.docker.com/resources/what-container">docker.com/resources/what-container</a>, accessed on 2021-07-07. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:chroot" role="doc-endnote">
      <p>Wikipedia. 2021a. “chroot”. <a href="https://en.wikipedia.org/w/index.php?title=Chroot&amp;oldid=1044767727">https://en.wikipedia.org/w/index.php?title=Chroot&amp;oldid=1044767727</a>, accessed 2021-11-19. <a href="#fnref:chroot" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:vm" role="doc-endnote">
      <p>Wikipedia. 2021b. “Hardware virtualization”. <a href="https://en.wikipedia.org/w/index.php?title=Hardware_virtualization&amp;oldid=1053629506">https://en.wikipedia.org/w/index.php?title=Hardware_virtualization&amp;oldid=1053629506</a>, accessed 2021-11-19 <a href="#fnref:vm" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:intro" role="doc-endnote">
      <p>Boettiger, Carl. “An Introduction to Docker for Reproducible Research.” ACM SIGOPS Operating Systems Review 49, no. 1 (January 20, 2015): 71–79. <a href="https://doi.org/10.1145/2723872.2723882">https://doi.org/10.1145/2723872.2723882</a>. <a href="#fnref:intro" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:lms" role="doc-endnote">
      <p>Lamadon, Thibaut, Magne Mogstad, and Bradley Setzler. forthcoming. “<a href="https://www.aeaweb.org/articles?id=10.1257/aer.20190790">Imperfect Competition, Compensating Differentials and Rent Sharing in the U.S. Labor Market.</a>” <em>American Economic Review</em> with <a href="https://github.com/setzler/LMS">Github repository</a> and <a href="https://doi.org/10.24433/CO.7147919.v1">1</a> <a href="https://doi.org/10.24433/CO.3047157.v1">2</a> <a href="https://doi.org/10.24433/CO.4775581.v1">3</a> <a href="https://doi.org/10.24433/CO.3648033.v1">4</a> compute capsules. <a href="#fnref:lms" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Even without using the <code class="language-plaintext highlighter-rouge">checkpoint</code> package, we might use the <a href="https://cran.microsoft.com/snapshot/">MRAN snapshot server</a>, but a faster method is provided by the binary packages provided by the <a href="https://packagemanager.rstudio.com/">Rstudio Public Package Manager</a> used by the Rocker images. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>For additional steps, and complete instructions, see <a href="https://github.com/AEADataEditor/docker-r-starter">github.com/AEADataEditor/docker-r-starter</a> <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:osfortran" role="doc-endnote">
      <p><a href="https://gcc.gnu.org/fortran/">GNU Fortran</a> and various LLVM-based Fortran front-ends are available, see a list at <a href="https://fortran-lang.org/compilers/">fortran-lang.org/compilers/</a>. <a href="#fnref:osfortran" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:commfortran" role="doc-endnote">
      <p><a href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/all-toolkits.html">Intel</a> and <a href="https://www.nag.com/nag-compiler">NAG</a> are popular. <a href="#fnref:commfortran" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:konkol" role="doc-endnote">
      <p>Konkol, Markus, Daniel Nüst, and Laura Goulier. 2020. “Publishing Computational Research - a Review of Infrastructures for Reproducible and Transparent Scholarly Communication.” Research Integrity and Peer Review 5, no. 1 (July 14, 2020): 10. <a href="https://doi.org/10.1186/s41073-020-00095-y">https://doi.org/10.1186/s41073-020-00095-y</a>. <a href="#fnref:konkol" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:konkol:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:rossi" role="doc-endnote">
      <p>Rossi, Barbara. 2021. “Compute Capsule for: Forecasting in the presence of instabilities: How do we know whether models predict [Source Code].” <em>CodeOcean</em>. https://doi.org/10.24433/CO.7940775.v1, which accompanies a forthcoming article in the Journal of Economic Literature, and which is also archived in the more traditional location as Rossi, Barbara. 2021. “Data and Code for: Forecasting in the Presence of Instabilities.” <em>American Economic Association</em> [publisher], <em>Inter-university Consortium for Political and Social Research</em> [distributor]. https://doi.org/10.3886/E147225V1 <a href="#fnref:rossi" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:rossi:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:stefano" role="doc-endnote">
      <p>DellaVigna, Stefano and Devin Pope. 2021. “Compute Capsule for: Stability of Experimental Results: Forecasts and Evidence” [Source Code]. <em>CodeOcean</em>. https://doi.org/10.24433/CO.0687784.v1, which accompanies a <a href="https://www.aeaweb.org/articles?id=10.1257/mic.20200129">forthcoming article in American Economic Journal: Microeconomics</a>, and which is also archived in the more traditional location as DellaVigna, Stefano, and Devin Pope. 2021. “Data and Code for: Stability of Experimental Results: Forecasts and Evidence.” <em>American Economic Association</em> [publisher], <em>Inter-university Consortium for Political and Social Research</em> [distributor]. https://doi.org/10.3886/E135221V1 <a href="#fnref:stefano" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:stefano:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
  </ol>
</div>]]></content><author><name>AEA Data Editor</name></author><category term="FAQ" /><category term="Twitter" /><category term="Docker" /><category term="Code" /><summary type="html"><![CDATA[In reproducibility verification, a common scenario is the author response “but-it-works-on-my-machine”. Finding common environments is important in such situations, to demonstrate that the error does arise, reproducibly, but also to share with the author the exact environment so that the issue can be fixed. Shipping around laptops probably isn’t the right solution. We illustrate how we addressed some of those cases using container technology throughout this post.]]></summary></entry><entry><title type="html">How to prepare replication packages for papers that used confidential data</title><link href="https://aeadataeditor.github.io/posts/2021-11-08-replication-pkg-confidential" rel="alternate" type="text/html" title="How to prepare replication packages for papers that used confidential data" /><published>2021-11-08T00:00:00-05:00</published><updated>2021-11-08T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/replication-pkg-confidential</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-11-08-replication-pkg-confidential"><![CDATA[<p>On a tangent: we get this question regularly - how to prepare replication packages for papers that used confidential data (here: by statistical agencies). A really <a href="https://twitter.com/AeaData/status/1457815800438562828">short thread</a>.</p>

<!-- more -->

<p><img src="/images/img-2021-11-08-1.png" alt="inquiry" /></p>

<p>The very general answer is: The guidance is the same as for any other paper, including with public data:</p>

<blockquote>
  <p>describe where the data came from, describe how others can get the data, provide all the code, describe how to run code, create README for it all.</p>
</blockquote>

<p>The only part that’s different is that getting access to the data WAS complicated for you, and MIGHT be a tad complicated/long/costly/impossible for others. Details, details…</p>

<p>But concretely, here are a few pointers.</p>

<ol>
  <li>First, start with our <a href="https://social-science-data-editors.github.io/template_README/">fabulous template README</a>. Really, it helps! Available at <a href="https://social-science-data-editors.github.io/template_README/">https://social-science-data-editors.github.io/template_README/</a></li>
</ol>

<p><a href="https://social-science-data-editors.github.io/template_README/"><img src="/images/img-2021-11-08-2.png" alt="README" /></a></p>

<ol>
  <li>In order to describe data availability, split into two:
    <ul>
      <li>how did YOU get access to the data, and</li>
      <li>how can OTHERS get access to the same data.</li>
      <li>The two are not always the same, but are both relevant.</li>
    </ul>
  </li>
</ol>

<p>Examples include <a href="https://social-science-data-editors.github.io/guidance/DCAS_Restricted_data.html#us-census-bureau-and-fsrdc">this excellent description</a> from a paper by <a href="https://faculty.tuck.dartmouth.edu/teresa-fort/">Teresa Fort</a> (<a href="https://twitter.com/Tfpiasecki">@Tfpiasecki</a>). Or <a href="https://social-science-data-editors.github.io/guidance/Requested_information_dcas.html#example-for-confidential-data">this description</a> by Fadlon and Nielsen about Danish data</p>

<p>Note: That’s for the data which you <em>cannot</em> share - because it is not yours to share. In general, the statistical agencies, or other providers, control access. You, the author, can only share information about <em>how</em> to access.</p>

<p>Furthermore,  you should also make an archive <em>WITHIN</em> the secure computing facility - of anything that cannot be shared, to the extent permissible, and as long as possible. And then provide information about it in the README.</p>

<ol>
  <li>Code: <strong>All</strong> code needs to be provided - no exceptions! Redactions for security/privacy are OK. Requesting code is standard practice in most secure computing facilities, but might take some time, so do it as soon as possible if you have not already done so.</li>
</ol>

<p>In the unlikely event that you get push back from whatever agency provided you with the data, contact your favorite data editor.</p>

<ol>
  <li>
    <p>All public use data you might have introduced to the secure computing facility are expected to be provided in the replication package, including where they came from. You probably had to describe the provenance anyway in order to import them (most secure computing facilities, such as the US FSRDC or the Canadian CRDCN, require such documentation).</p>
  </li>
  <li>
    <p>Do not forget to cite data! See our <a href="https://social-science-data-editors.github.io/guidance/Data_citation_guidance.html">Guidance on Data Citation</a></p>
  </li>
</ol>

<p>And if you have questions, contact us!</p>]]></content><author><name>AEA Data Editor</name></author><category term="restricted-access" /><category term="administrative" /><category term="replication package" /><summary type="html"><![CDATA[On a tangent: we get this question regularly - how to prepare replication packages for papers that used confidential data (here: by statistical agencies). A really short thread.]]></summary></entry><entry><title type="html">When a reproducibility check turns into a replication exercise</title><link href="https://aeadataeditor.github.io/posts/2021-10-28-reproducibility-restricted-france" rel="alternate" type="text/html" title="When a reproducibility check turns into a replication exercise" /><published>2021-10-28T00:00:00-04:00</published><updated>2021-10-28T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/reproducibility-restricted-france</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-10-28-reproducibility-restricted-france"><![CDATA[<p>I wanted to highlight a particular interesting article in the latest <a href="https://www.aeaweb.org/journals/mic">AEJ: Microeconomics</a> from the perspective of replicability and reproducibility.</p>

<!-- more -->

<blockquote>
  <p>Piveteau, Paul. 2021. “An Empirical Dynamic Model of Trade with Consumer Accumulation.” <em>American Economic Journal: Microeconomics</em>, 13 (4): 23-63. <a href="https://doi.org/10.1257/mic.20190051">https://doi.org/10.1257/mic.20190051</a></p>
</blockquote>

<p><img src="/images/aejmicro-2021-10-piveteau.png" alt="AEJ:Micro 20190051" /></p>

<p><a href="https://paulpiveteau.com/">Paul</a> uses granular (firm-level) French customs data to estimate a model with trade flows. The detailed but confidential French customs data were obtained by Paul many years ago, directly from the French administration. However, by the time the replication package was sent to the AEA Data Editor (me), the French customs agency had (very recently) signed an agreement with <a href="https://www.casd.eu/">CASD (Centre d’accès sécurisé aux données)</a>, the French system for academic use of restricted-access data, making more generalized access to the customs data feasible for future researchers and replicators.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> Furthermore, several years ago, <a href="https://people.hec.edu/perignon/">Christophe Perignon</a> (HEC Paris, <a href="https://twitter.com/christoperignon">@christoperignon</a>) and <a href="https://sites.google.com/view/christophe-hurlin/home">Christophe Hurlin</a> (Université d’Orléans, <a href="https://twitter.com/churlin1804">@churlin1804</a>) created <a href="https://www.cascad.tech/"><em>cascad</em></a>, an organization dedicated to conducting reproducibility checks, including within the confines of the secure environment at CASD.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></p>

<p>We therefore requested that <em>cascad</em> conduct a reproducibility check for the AEA, using the full confidential French customs data available within CASD.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup> And… the first attempt at reproducing even basic statistics failed. The data deposited by the customs agency at CASD many years later were subtly different in several dimensions. While the replicators worked hard to adapt the code to the data structure available to them, we ultimately turned to Paul for help. In the end, pure computational reproducibility was not possible, but a replication using the more recently extracted customs data was feasible.</p>

<p>Jointly, but mostly through Paul’s efforts, the team succeeded in adapting the cleaning and preparation code to the newer data, and ran most of the code successfully. As should be expected when data are somewhat different, some of the results were different, though generally not in a substantial way.  However, some results were not replicable:</p>

<blockquote>
  <p>However, this replication exercise highlighted some numerical fragilities in the algorithm developed to estimate the dynamic model in the paper. In particular, the estimation of the model on the sample of wood exporters (appendix C) could not be performed.</p>
</blockquote>

<p>But instead of either resolving this via (private) correspondence between editors and authors, or letting future replicators find this out the hard way, Paul adopted what I believe is the best approach: acknowledging the limits of the computational reproducibility.</p>

<p>And you do not need to rely on my hearsay - you can read all about it in the summary in <a href="https://assets.aeaweb.org/asset-server/files/15530.pdf#page=36">Appendix H of the online appendix, page 77</a> (from which the quote above is pulled), with the full replication report and all replicated tables and figures by <em>cascad</em> available at in the “<a href="https://doi.org/10.3886/E120070V1-100007">Replication_Fall20</a>” folder in the public replication package.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup></p>

<p>No future replicator can access the data that Paul originally had obtained. But many future replicators (subject to certain conditions) can access the confidential customs data available through CASD. And can request such access with the assurance that the baseline analysis can be replicated (and the replication reproduced), making such requests - costly in time, effort, and money - worth a researcher’s while.</p>

<p>The final outcome is, in my opinion, more transparent than it would have been in many other scenarios, and verified to be more robust than if we had only relied on Paul’s original materials.</p>

<p>We thank Paul for his patience and assistance, and Christophe, Christophe, and Olivier Akmansoy (the replicator at <em>cascad</em>) for their help in conducting this reproducibility check plus replication exercise.</p>

<p>Authors interested in communicating with us about ways to verify reproducibility when the data are confidential can consult our <a href="https://aeadataeditor.github.io/aea-de-guidance/preparing-for-data-deposit.html#structure-in-the-presence-of-confidential-unpublished-data">step-by-step guide</a>.</p>

<h2 id="notes">Notes</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Full disclosure: I (Lars Vilhuber) happen to serve as <a href="https://www.casd.eu/nomination-de-lars-vilhuber-en-tant-que-president-du-conseil-scientifique-du-casd/">chair of the scientific advisory board</a>. However, access to the customs data, and to the services of <em>cascad</em> are open to anyone, and no privileged access or treatment was necessary to obtain the outcomes of this post. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Pérignon, Christophe, Kamel Gadouche, Christophe Hurlin, Roxane Silberman, and Eric Debonnel. 2019. “Certify Reproducibility with Confidential Data.” Science 365, no. 6449: 127–28. <a href="https://doi.org/10.1126/science.aaw2825">https://doi.org/10.1126/science.aaw2825</a>. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>As of the writing of this post, the customs data are not yet listed in the CASD data catalog at <a href="https://www.casd.eu/les-sources-de-donnees-disponibles-au-casd/">https://www.casd.eu/les-sources-de-donnees-disponibles-au-casd/</a>. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>Piveteau, Paul. 2021. “Data and Code for: An Empirical Dynamic Model of Trade with Consumer Accumulation: Replication_Fall20.” <em>American Economic Association [publisher]</em>,  <em>Inter-university Consortium for Political and Social Research [distributor]</em>. <a href="https://doi.org/10.3886/E120070V1-100007">https://doi.org/10.3886/E120070V1-100007</a>. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>AEA Data Editor</name></author><category term="restricted-access" /><category term="AEJ:Micro" /><category term="CASD" /><category term="cascad" /><summary type="html"><![CDATA[I wanted to highlight a particular interesting article in the latest AEJ: Microeconomics from the perspective of replicability and reproducibility.]]></summary></entry><entry><title type="html">Software, code, and repositories</title><link href="https://aeadataeditor.github.io/posts/2021-06-17-software-citations" rel="alternate" type="text/html" title="Software, code, and repositories" /><published>2021-06-17T00:00:00-04:00</published><updated>2021-06-17T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/software-citations</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-06-17-software-citations"><![CDATA[<p>A short thread on software, code, versioning, citation, and repositories. Only very few AEA articles reference Github/Gitlab/Bitbucket repositories. More should do so. A few notes.</p>

<!-- more -->

<h2 id="replication-packages-and-version-control">Replication packages and version control</h2>

<p>Fact: all replication packages contain code.</p>

<p>Note: sometimes, that’s an Excel file, but that’s still code.</p>

<p>But few seem to stem from version control repositories. The most common version control software these days is <code class="language-plaintext highlighter-rouge">git</code>, though I’ve seen a few uses of <code class="language-plaintext highlighter-rouge">svn</code>. Both are popular because they usually come accompanied by online web services that allow authors to showcase their code, as well as conduct a few other key functions that I will get to.</p>

<p>By far the most popular as of 2021 is <a href="https://github.com">Github</a> - in fact, this <a href="https://github.com/AEADataEditor/aeadataeditor.github.io/blob/main/_posts/2021-06-17-software-citations.md">blog post</a> and website are hosted on Github-provided resources. Others include <a href="https://gitlab.com">Gitlab</a>, <a href="https://bitbucket.org">Bitbucket</a>, and for <code class="language-plaintext highlighter-rouge">svn</code>, <a href="https://sourceforge.net/">SourceForge</a>.</p>

<p>Version control allows for, well, version control. This is particularly relevant for replication packages, since code probably is evolving. Which version was used to generate the tables and figures in the paper is very important information.</p>

<p>While authors are able to “lock in” a version that was used when they submit to the AEA Data Editor (via <a href="https://www.openicpsr.org/openicpsr/search/aea/studies">AEA Data and Code Repository</a>), ideally, that version is locked in <strong>prior</strong> to submitting.</p>

<h2 id="locking-in-versions">Locking in versions</h2>

<p>If using version control, creating a “locked in” version that corresponds to a particular version of the paper is easy. It may be called different things (“releases” on Github and in <code class="language-plaintext highlighter-rouge">svn</code>, “tags” in native <code class="language-plaintext highlighter-rouge">git</code>), but it achieves the same function: It marks a particularly version of code.</p>

<p>That <code class="language-plaintext highlighter-rouge">tag</code> can contain additional “metadata” - an “<a href="https://git-scm.com/docs/git-tag">annotated tag</a>” or a “<a href="https://docs.github.com/en/github/administering-a-repository/releasing-projects-on-github/managing-releases-in-a-repository">Github release</a>” can be quite verbose. But in all cases, the key is to uniquely identify the version of the code that was used to do something, or that corresponds to something.</p>

<p>NOTE: strictly speaking, those <code class="language-plaintext highlighter-rouge">tags</code> are not necessary. Authors could simply point to a particular “commit hash”, e.g. “<code class="language-plaintext highlighter-rouge">https://github.com/&lt;user&gt;/&lt;project&gt;/tree/&lt;hash&gt;</code>” to uniquely point to a particular version as well (similarly on <code class="language-plaintext highlighter-rouge">svn</code>, pointing to revision numbers). But <code class="language-plaintext highlighter-rouge">tags</code> are a tad more human readable than <a href="https://github.com/AEADataEditor/replication-template-development/tree/7634e14ee9a0a433db1ab6f25609dfb4c6876483"><code class="language-plaintext highlighter-rouge">https://github.com/AEADataEditor/replication-template-development/tree/7634e14ee9a0a433db1ab6f25609dfb4c6876483</code></a>.</p>

<h2 id="archiving-versions">Archiving Versions</h2>

<p>Once authors have identified a particular version of the code, there remains of course the issue that Github &amp; Co. are not “trusted repositories”. So authors will still need to somehow archive that particular version.</p>

<p>One convenience of using features like “Github releases” or even tags on Github is that the interface provides a convenient link to download a ZIP or TAR file without all the extra <code class="language-plaintext highlighter-rouge">git</code> information.</p>

<p><img src="/images/github-release-screenshot-assets.png" alt="Screenshot of download links on Github release" /></p>

<p>Once you have the ZIP or TAR, you can manually send this off to a trusted repository. That’s what most authors are or should be doing when submitting to the <a href="https://www.openicpsr.org/openicpsr/search/aea/studies">AEA Data and Code Repository</a>, or for that matter for any journal’s supplementary materials archive.</p>

<p>However, that is tedious, and at least for Github, there is a different (automated) option: <a href="https://guides.github.com/activities/citable-code/">linking it to Zenodo</a>. Authors should consult the (very easy) details in the link, but in a nutshell, this is what happens:</p>

<ul>
  <li>you set up the link. Takes a bit of work the first time, but then it’s done, forever.</li>
  <li>every time a release is made, the ZIP file is sent automatically to Zenodo, and creates an archive, with a DOI and a preservation guarantee.
    <ul>
      <li>The Zenodo deposit links back to the particular release/tag on Github</li>
    </ul>
  </li>
  <li>some cosmetic editing (to Zenodo metadata, to eye candy such as a DOI badge) can make it pretty, but are not needed.</li>
</ul>

<h2 id="example">Example</h2>

<p>For an example see</p>

<ul>
  <li>the <a href="https://github.com/social-science-data-editors/template_README/">source code for template README on Github</a>, including any <a href="https://github.com/social-science-data-editors/template_README/releases">releases</a></li>
  <li>the <a href="https://social-science-data-editors.github.io/template_README/">page generated from the source code on Github.io</a></li>
  <li>the “badge”: <a href="https://doi.org/10.5281/zenodo.4319999"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.4319999.svg" alt="DOI badge" /></a></li>
  <li>the <a href="https://doi.org/10.5281/zenodo.4319999">archived version on Zenodo</a></li>
</ul>

<p><img src="/images/zenodo-readme-v1.png" alt="template README on Zenodo" /></p>

<p>The version - in fact, any future version - is now properly archived at a trusted repository.</p>

<h2 id="citing-software-versions">Citing Software Versions</h2>

<p>Last but not least, but in particular when the code authors generated is of more general utility (a Stata or R package for a new econometric technique), <strong>citing the software</strong> is a must (see <a href="https://www.force11.org/software-citation-principles">FORCE11 Software Citation Principles</a>,<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>)</p>

<p>By creating archived versions, Zenodo, or any other trusted repository, provides a DOI that can then be cited:</p>

<blockquote>
  <p>Smith, A. and J. Wesson. 2021. “15-fold quantum fixed effects, R package.” v0.2-alpha. Zenodo. https://doi.org/10.5281/zen0do.12345</p>
</blockquote>

<p>Naturally, authors could also cite the Github-hosted version, but only with the authority of a (transient, ephemerous) website:</p>

<blockquote>
  <p>Smith, A. and J. Wesson. 2021. “15-fold quantum fixed effects, R package.” v0.2-alpha. Github. Last accessed at https://github.com/smith-wesson/cdqfe/releases/tag/v0.2-alpha on June 17, 2025.</p>
</blockquote>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Smith AM, Katz DS, Niemeyer KE, FORCE11 Software Citation Working Group. 2016. Software Citation Principles. <em>PeerJ Computer Science</em> 2:e86. DOI: <a href="https://doi.org/10.7717/peerj-cs.86">10.7717/peerj-cs.86</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>AEA Data Editor</name></author><category term="FAQ" /><category term="Twitter" /><category term="Software" /><category term="Code" /><summary type="html"><![CDATA[A short thread on software, code, versioning, citation, and repositories. Only very few AEA articles reference Github/Gitlab/Bitbucket repositories. More should do so. A few notes.]]></summary></entry><entry><title type="html">File paths in statistical software</title><link href="https://aeadataeditor.github.io/posts/2021-04-09-paths" rel="alternate" type="text/html" title="File paths in statistical software" /><published>2021-04-09T00:00:00-04:00</published><updated>2021-04-09T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/paths</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-04-09-paths"><![CDATA[<p>A short thread (PSA) on a FOC (frequently occurring problem) that shouldn’t be one: file paths in statistical software.</p>

<!-- more -->

<p>Comment in a recent reply to one of our replication reports (note: this was not actually a problem):</p>

<blockquote>
  <p>“We use a HPC and a Linux environment. Therefore, the folders are separated by / and not \ . This might
create problems if working with Windows.”</p>
</blockquote>

<p>Actually, it does not!</p>

<h2 id="stata">Stata</h2>

<p>Every <strong>Stata</strong> user (but in particular those on Windows) should know 👇. Rule: ALWAYS use “<code class="language-plaintext highlighter-rouge">/</code>”, NEVER “<code class="language-plaintext highlighter-rouge">\</code>” and you should be fine.</p>

<p><img src="/images/stata-technical-note-paths.png" alt="Stata note on paths" /></p>

<h2 id="r">R</h2>

<p>use “<code class="language-plaintext highlighter-rouge">file.path('path','file')</code>” or even use packages <a href="https://cran.r-project.org/web/packages/here/vignettes/here.html"><code class="language-plaintext highlighter-rouge">here</code></a> or <a href="https://cran.r-project.org/web/packages/rprojroot/vignettes/rprojroot.html"><code class="language-plaintext highlighter-rouge">rprojroot</code></a>.</p>

<h2 id="matlab">Matlab</h2>

<p>Use “<code class="language-plaintext highlighter-rouge">/</code>” and it will do the right thing.</p>

<p><img src="/images/matlab-paths.png" alt="Matlab paths" /></p>

<h2 id="python">Python</h2>

<p><code class="language-plaintext highlighter-rouge">os.path.join()</code> is your friend</p>

<p><img src="/images/python-paths.png" alt="Python paths" /></p>

<h2 id="others">Others</h2>

<p>And there are likely similar functions in lots of other programming languages and statistical software.</p>

<h2 id="take-away">Take away</h2>

<p>Be aware of and always use the platform independent coding of paths, either a function or using “<code class="language-plaintext highlighter-rouge">/</code>”. NEVER use “<code class="language-plaintext highlighter-rouge">\</code>”.</p>]]></content><author><name>AEA Data Editor</name></author><category term="FAQ" /><category term="Twitter" /><category term="Data" /><category term="Code" /><summary type="html"><![CDATA[A short thread (PSA) on a FOC (frequently occurring problem) that shouldn’t be one: file paths in statistical software.]]></summary></entry><entry><title type="html">What data to provide</title><link href="https://aeadataeditor.github.io/posts/2021-03-31-what-data" rel="alternate" type="text/html" title="What data to provide" /><published>2021-03-31T00:00:00-04:00</published><updated>2021-03-31T00:00:00-04:00</updated><id>https://aeadataeditor.github.io/posts/what-data</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-03-31-what-data"><![CDATA[<p>What do we mean by “data”?</p>

<!-- more -->

<h2 id="what-data-should-be-provided">What data should be provided?</h2>

<p>One of my data editor colleagues at <a href="https://social-science-data-editors.github.io/">Social Science Data Editors</a> relayed a question to me recently (“asking for a friend…”): “do extract files need to be included in AEA data replication submissions?”</p>

<p>They noted “The closest I could find was <a href="https://www.aeaweb.org/journals/data/data-code-policy#content">https://www.aeaweb.org/journals/data/data-code-policy#content</a> which has a blanket request for “data” but it might help to distinguish between “extracts” and “analysis” files.</p>

<h2 id="the-short-answer">The short answer</h2>

<p>It depends.</p>

<ul>
  <li>extract (raw) data can be reliably re-acquired today?</li>
  <li>extract (raw) data can be reliably re-acquired in the future?</li>
  <li>analysis data can be reproduced with reasonable resources?</li>
</ul>

<h2 id="the-longer-answer">The longer answer</h2>

<p>For the raw input data (which may be an extract - that’s actually not the key criterion), we require that the <strong>acquisition</strong> of the data be reproducible.</p>

<p>You don’t have to provide <strong>any</strong> data, if</p>

<ul>
  <li>the results can be reproduced by downloading precisely specified raw data (reasonableness constraint)</li>
  <li>can reproduce analysis files reliably - subject to a reasonableness constraint.</li>
</ul>

<p>But you might also have to provide <strong>all</strong> the data.</p>

<p>Reproducibility, now and in the future, is key, not whether the data is part of the package or not.</p>

<p>But: this is not always straightforward. Take IPUMS as a (frequent) example.</p>

<ol>
  <li>IPUMS curates its entire database (assign a DOI), so the “reliably in the future” part is OK ✅</li>
  <li>But IPUMS has a purely (as of today) manual data extract system. There is no computer code that can reliably re-acquire an extract today or in the (near) future. ❌
    <ul>
      <li>And even manual extraction is fraught with the potential for error (and can be quite tedious)  ❌</li>
    </ul>
  </li>
  <li>And very importantly: providing extracts is allowed by their <a href="https://ipums.org/about/terms">terms of use</a> for MOST but not all of their datasets. ✅</li>
</ol>

<p>We thus prefer to have a copy of IPUMS extracts - and the read-in code, and the data dictionary that they provide with every extract (if you didn’t grab yours, go back into the IPUMS system and download it now!) The AEA’s Data and Code Repository can curate as well as IPUMS, but make the data more easily available, lowering the cost of reproducibility for all future researchers.</p>

<p>If IPUMS were to allow for sharing or archiving of machine-actionable extract specs (not an easy problem), we would reconsider and NOT request extracts!</p>

<h2 id="problems">Problems?</h2>

<p>Of course, there can be impediments. For instance, we would prefer to curate the data when the data provider does NOT curate the data (has no preservation policy, assigns no DOI). But the third condition (terms of use) is just as important, and often prevents us from taking custody of an extract (or even of the analysis data).</p>

<p>We ask for extracts from various online query systems (WDI, OECD, etc.) because the precise query cannot be saved, or is complicated, etc.</p>

<h2 id="solutions">Solutions?</h2>

<p>One obvious solution is for all data query systems to have some system to save or export query code.</p>

<h3 id="psid">PSID</h3>

<p>A nice (simple, but not perfect) example for such a stored-query system is the PSID:</p>

<ol>
  <li>They do curate their database, though no DOIs are assigned, and you need to know to ask (meh… but OK: ✅)</li>
  <li>While they do not assign DOIs to historical queries, you can (as a user) share a query, see <a href="https://simba.isr.umich.edu/DC/c.aspx">https://simba.isr.umich.edu/DC/c.aspx</a>. ✅</li>
  <li>Which is good, since you are not allowed to share the data itself! ❌ (Actually, you can, via <a href="https://www.openicpsr.org/openicpsr/psid">https://www.openicpsr.org/openicpsr/psid</a>)</li>
</ol>

<h2 id="counter-point">Counter point</h2>

<p>The obvious corollary is:</p>

<ol>
  <li>If a data <strong>provider curates the data</strong> (say, at a trusted repository, or with a credible preservation policy) (for which a DOI is a signal, but not a condition) ✅</li>
  <li>and the <strong>data can be downloaded</strong>, or queried through an API<sup id="fnref:API" role="doc-noteref"><a href="#fn:API" class="footnote" rel="footnote">1</a></sup> or something similar ✅</li>
  <li>regardless of their license and terms of use</li>
</ol>

<p>we will <strong>REJECT</strong> your data deposit - please simply leave it where it is!</p>

<p>But cite it, and provide precise instructions on how to get it (if a simple click is not sufficient).</p>

<h2 id="and-those-analysis-files">And those analysis files?</h2>

<p>So when do we want analysis (intermediate) files?</p>

<ul>
  <li>when we cannot <strong>reliably</strong> get the raw data, and there are no issues with redistributing the analysis files</li>
  <li>when the raw data can be redistributed, but are “<strong>too large</strong>” to acquire (at the AEA, that boundary is around 30GB)</li>
  <li>when the raw data can be redistributed, but the analysis data are already the result of a very <strong>resource</strong> (computer count or time) <strong>intensive</strong> processing</li>
</ul>

<p>In all of those cases, we <strong>want</strong> the analysis data.</p>

<p>When do we <strong>NOT want</strong> the analysis data? Well, if the raw data can be trivially acquired (download, API<sup id="fnref:API:1" role="doc-noteref"><a href="#fn:API" class="footnote" rel="footnote">1</a></sup>), and can be reasonably quickly processed, then we (and future researchers) do not need your copy of the analysis data. But it also doesn’t hurt…</p>

<p>BTW, “reasonably” means we are not using more than maybe 50 compute cores. “Quickly” means that it runs no longer than 2-3 weeks - to produce the analysis data.</p>

<h2 id="and-just-contact-us">And just contact us</h2>

<p>In all cases, if you have questions, concerns, or doubts, do contact me - as many others have already done.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:API" role="doc-endnote">
      <p>P.S. That footnote for API? Well, APIs get deprecated over time, so we actually prefer to have the <strong>raw</strong> data saved, but it’s probably OK to skip the analysis data. <a href="#fnref:API" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:API:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
  </ol>
</div>]]></content><author><name>AEA Data Editor</name></author><category term="FAQ" /><category term="Twitter" /><category term="Data" /><summary type="html"><![CDATA[What do we mean by “data”?]]></summary></entry><entry><title type="html">Reproducible GIS</title><link href="https://aeadataeditor.github.io/posts/2021-02-10-reproducible-gis" rel="alternate" type="text/html" title="Reproducible GIS" /><published>2021-02-10T00:00:00-05:00</published><updated>2021-02-10T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/reproducible-gis</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-02-10-reproducible-gis"><![CDATA[<p>A note on reproducible GIS by economists: it’s mostly absent. Here are some tips.</p>

<!-- more -->

<h2 id="reproducibility-and-gis">Reproducibility and GIS</h2>

<p>Reproducibility means that the inputs and methods can be repeated by a (somewhat) knowledgeable person. For GIS, that <em>might</em> (should) mean code, but it <em>definitely</em> means at least SOME instructions. Even if they are manual….</p>

<p>Maps are data. While your typical Stata/Matlab/R/Julia graph is data projected into Cartesian coordinates, maps are data projected into geographic coordinates. So at a minimum, we need to know what the inputs to the map are, same as we need to know inputs to graphs.</p>

<p>So “data + code” + “<code class="language-plaintext highlighter-rouge">graph twoway scatter x y</code>” -&gt; 📈📉,</p>

<p><img src="https://pbs.twimg.com/media/Et31MkpXcAQg8Nw.png" alt="" /></p>

<p>and “data + code” + “<code class="language-plaintext highlighter-rouge">maptile x, geo(state)</code>” -&gt; 🗺️. Or “data + code” + “<em>instructions(ArcGIS)</em>” -&gt; 🗺️.</p>

<p><img src="https://pbs.twimg.com/media/Et3048TXcAIx20f.png" alt="" /></p>

<p>Note that for a map, “data” includes shapefiles (including provenance of the shapefile)</p>

<h2 id="checklist-for-reproducible-maps">Checklist for reproducible maps</h2>

<ul>
  <li>✅ data (+ provenance)</li>
  <li>✅ code (manipulates data)</li>
  <li>✅ shapefile (provides coordinates)</li>
  <li>✅ code (preferred) or instructions (sufficient)</li>
</ul>

<h2 id="resources">Resources</h2>

<p>A few tentative resources are collected at <a href="https://social-science-data-editors.github.io/guidance/guidance-reproducible-gis-analysis.html">https://social-science-data-editors.github.io/guidance/guidance-reproducible-gis-analysis.html</a> (please suggest improvements!), with some other links below:</p>

<h3 id="stata">Stata</h3>

<p><a href="https://www.stata.com/support/faqs/graphics/spmap-and-maps/">Stata FAQ on maps</a>, including the <a href="https://ideas.repec.org/c/boc/bocode/s456812.html">spmap package</a> and the <a href="https://michaelstepner.com/maptile/">maptile package</a> by <a href="https://twitter.com/michaelstepner">@michaelstepner</a></p>

<h3 id="r">R</h3>

<p>The core <a href="https://r-spatial.github.io/sf/">sf library</a>, <a href="https://staff.washington.edu/phurvitz/r_gis/">reproducible GIS practices in R</a>  and interactions with GIS software (and integrated as a dependency into many great packages)</p>
<h3 id="python">Python</h3>

<p><a href="https://geopandas.org/">GeoPandas</a> and others</p>

<h3 id="arcgis">ArcGIS</h3>

<p>ArcGIS can also be scripted (via python) and now <a href="https://pro.arcgis.com/en/pro-app/latest/arcpy/get-started/pro-notebooks.htm">integrates Jupyter-like notebooks</a></p>

<h3 id="qgis">QGIS</h3>

<p>Staying #opensource: <a href="https://www.qgis.org/">QGIS</a> has “<a href="https://docs.qgis.org/3.10/en/docs/user_manual/processing/modeler.html">Graphical Modeler</a>”, and look for tutorials on “<a href="https://courses.spatialthoughts.com/">Automating GIS Workflows</a>”</p>

<h2 id="summary">Summary</h2>

<p>Please try to create scripted maps, but always describe what data you are mapping, and where you got the shapefiles from (note: copyrights might apply, permissions might need to be obtained!)</p>

<h2 id="ps">PS</h2>

<p>And for those exceptions from scripting: a 2-3 sentence description of what you did would be sufficient. And for the unscripted ArcGIS which you did before you learned how to script stuff: a 4-5 sentence description may be sufficient as well.</p>

<h2 id="follow-the-conversation">Follow the conversation</h2>

<p>Slightly modified from
<a href="https://twitter.com/AeaData/status/1359516297990701057">https://twitter.com/AeaData/status/1359516297990701057</a></p>]]></content><author><name>AEA Data Editor</name></author><category term="FAQ" /><category term="Twitter" /><category term="GIS" /><summary type="html"><![CDATA[A note on reproducible GIS by economists: it’s mostly absent. Here are some tips.]]></summary></entry><entry><title type="html">A Day in the Life of a Data Editor</title><link href="https://aeadataeditor.github.io/posts/2021-01-31-day-in-the-life" rel="alternate" type="text/html" title="A Day in the Life of a Data Editor" /><published>2021-01-31T00:00:00-05:00</published><updated>2021-01-31T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/day-in-the-life</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-01-31-day-in-the-life"><![CDATA[<p>I wanted to illustrate the range of the various topics that a Data Editor might face, by taking a fairly random day (2021-01-29) and listing all the various (distinct) activities that are in-scope for my job at the AEA.</p>

<!-- more -->

<h2 id="a-day-in-the-life">A day in the life…</h2>

<p>All in all, I worked on 15 different papers - some for quite a while, others only briefly. 
Naturally, I signed off on a few reports - some were first round (yes!), some were second round. I’m late on quite a few, because …</p>

<p>I’ve spent a good chunk of the week onboarding a cohort of 11 new RAs. We wrapped up 15 hours of lecture and hands-on training. They did really well!</p>

<p>I sent off a reminder to an author. Deposit was withdrawn, because it contained data in infringement of his DUA. The data provider contacted us (“take down request”), we are waiting for the author to update deposit so we can republish.
<img src="/images/openICPSR-study-unpublished.png" alt="Unpublished study" /></p>

<p>I contacted a commercial data provider to request permission to post a data extract provided by author. Author had not asked for permission. I believe we will not get permission. This avoids a “take down request” later.</p>

<p>Can a Data Editor (or any data-oriented referee) be considered a “consultant” with “material participation/engagement” for the purposes of a confidentiality and data use agreement? Question sent to IRB (thanks to the author for bringing this up early!)</p>

<p>How do you cross-list replication packages or data from a trusted repository that is not the journal’s repository? We would like to be able to search “all the journal’s packages” even when they are legitimately deposited elsewhere? Backend technical.</p>

<p>Identified one new request for replication (with restricted-access data) that I can delegate to a third-party replicator. Handled getting them started. <a href="https://aeadataeditor.github.io/aea-de-guidance/protocol-3rd-party-replication.html">https://aeadataeditor.github.io/aea-de-guidance/protocol-3rd-party-replication.html</a></p>

<p>First paper that uses Google Colab to run and disseminate package - guide RA, and figure out response to authors, since we still need a copy of the Jupyter notebooks in the archive (they did not provide a README). <a href="https://social-science-data-editors.github.io/template_README/">https://social-science-data-editors.github.io/template_README/</a></p>

<p>Assigned additional resources (extended reservation) for the Linux Cluster so the job that another RA is running can finish.  Note that we are skipping the part that uses 2000 nodes (as per README) in the interest of time (and $$).</p>

<p>Assessed whether we need to boot up the (pre-configured) Windows VM to run a Matlab + Dynare job, or whether we can run it on the existing Cornell Windows cluster.</p>

<p>Helped RA debug a problem where Matlab interfaces with an external (Fortran-compiled) binary that is not producing output - the code contained no checks for that situation, and gave a misleading error message several steps later.</p>

<p>Alerted the journal editor to an issue where even the authors’ revision still leads to numerical discrepancies, despite authors’ greatly improved efforts to specify exactly how to run (and our standard setup is fully compliant). Is this another Stata bug?</p>

<p>Used a Docker image to run revised R code from author team. The revised README now specifies exactly the version of R, and Docker happens to be the best way to compartmentalize the whole package (the authors did not use Docker). <a href="https://github.com/AEADataEditor/docker-r-starter">https://github.com/AEADataEditor/docker-r-starter</a></p>

<p>Never a dull day!</p>

<h2 id="on-twitter">On Twitter</h2>

<p><a href="https://twitter.com/AeaData/status/1356106537673089024">https://twitter.com/AeaData/status/1356106537673089024</a></p>]]></content><author><name>AEA Data Editor</name></author><category term="FAQ" /><category term="Twitter" /><category term="Tasks" /><summary type="html"><![CDATA[I wanted to illustrate the range of the various topics that a Data Editor might face, by taking a fairly random day (2021-01-29) and listing all the various (distinct) activities that are in-scope for my job at the AEA.]]></summary></entry><entry><title type="html">Follow-up to Fireside Chat</title><link href="https://aeadataeditor.github.io/posts/2021-01-19-fireside-chat" rel="alternate" type="text/html" title="Follow-up to Fireside Chat" /><published>2021-01-19T00:00:00-05:00</published><updated>2021-01-19T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/Fireside-chat</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-01-19-fireside-chat"><![CDATA[<p>In this post, I’ll pick up questions that have been asked over Twitter or during the <a href="https://aeadataeditor.github.io/talks/2021-01-19-cswep">2021-01-19 Fireside chat</a>, in long form (Twitter is not always the best medium). Over time, you might see some of these questions and answers be migrated to FAQ and/or best practices documents.</p>

<!-- more -->

<h2 id="starting-a-project">Starting a project</h2>

<blockquote>
  <p><a href="https://twitter.com/judy_chevalier/status/1346259253955354624">Judy Chevalier</a> What do I do before I even start the project? What do I do if I am accessing a big public dataset and it is always at risk of being changed or cleaned or updated?</p>
</blockquote>

<p>Answer coming. Short answer: Keep track of what you do. Set up the project correctly. See  <a href="https://aeadataeditor.github.io/aea-de-guidance/step-by-step.html">https://aeadataeditor.github.io/aea-de-guidance/step-by-step.html</a> - in particular the first part <a href="https://aeadataeditor.github.io/aea-de-guidance/preparing-for-data-deposit.html">https://aeadataeditor.github.io/aea-de-guidance/preparing-for-data-deposit.html</a> can be done at any time!</p>

<h2 id="irb-consent-and-distributing-sensitive-data">IRB, consent, and distributing sensitive data</h2>

<blockquote>
  <p><a href="https://twitter.com/Cutler_econ/status/1346261440899018752">David Cutler</a> IRB rules are becoming more complex over time. It would be good for economists to understand them better.</p>
</blockquote>

<blockquote>
  <p><a href="https://twitter.com/asacarny/status/1346262290354614274">Adam Sacarny</a> I strongly second this point! Knowing a bit about the Common Rule and HIPAA has saved me a lot of time. For example, sometimes the IRB requests waivers etc. that are not needed. Or sometimes you can make minor changes to make your research exempt rather than expedited…</p>
</blockquote>

<p>Excellent points. Longish answer during Fireplace Chat.</p>

<h2 id="code-persistence-or-code-rot">Code Persistence or Code Rot</h2>

<blockquote>
  <p><a href="https://twitter.com/johnjhorton/status/1346260871429971970">John Horton</a>: If you are relying on lots of open source packages subject to change, how do we prevent “code rot”? Might it make sense for AEA to collect &amp; store docker images or virtual machines?</p>
</blockquote>

<p>There are two assumptions embedded within the question, which I’ll address at the end. The easy answer to this is: We already have a mechanism to store code, docker images, and virtual machines, it’s called the “<a href="https://www.openicpsr.org/openicpsr/search/aea/studies">AEA Data and Code Repository</a>” where all replication packages are stored.</p>

<p>The two assumptions are: “open source packages” and “researcher-provided docker images/VMs”. Most economics code is written in Stata or Matlab, which are not open-source software, but which often have open-source (or imprecisely licensed) add-ons (packages, etc.) (I will address “packages” later). The best practice we have found is for copies of those packages to be distributed with the replication package, pre-installed, for two key reasons: Stata package repositories (<a href="https://ideas.repec.org/s/boc/bocode.html">SSC</a>) are not versioned (old versions disappear), Matlab has no package repository, and Github (often used as an alternative, in particular for a small subset of Stata packages) is not persistent in the same way the “<a href="https://www.openicpsr.org/openicpsr/search/aea/studies">AEA Data and Code Repository</a>” is. The AEA guidelines may require this in the future, but currently only suggest it.</p>

<p>The second assumption is that researchers provide Docker images and VMS. <strong>They don’t</strong>. Not in the social sciences. It is beyond the scope of what we do to create it for them, at this point (we are looking into ways of doing that, though).</p>

<h2 id="proprietary-data-from-unknown-sources">Proprietary Data from Unknown Sources</h2>

<blockquote>
  <p><a href="https://twitter.com/johnjhorton/status/1346261392983285761">John Horton</a> For proprietary data where the source of the data is not disclosed but known to the authors, is there a way to facilitate access for other researchers to the data without divulging source publicly?</p>
</blockquote>

<p>This is an excellent idea, variants of which we have investigated before. It hinges primarily on the willingness of the original data provider to entertain this. We don’t actually have many cases where the provider is anonymous. I can think of two right now: one has a researcher-mediated access mechanism via a Non-disclosure Agreement - a group of researchers maintains the data, protects anonymity, but is willing to provide access to the data for replication and possibly for research purposes. A second one implemented an email-moderated mechanism that hides the identity of the data provider. In both cases, the persistence of the data, and of the access mechanism is not guaranteed.</p>

<p>The ideal scenario is for researchers to obtain approval from the data provider to deposit data under a restrictive access mechanism mediated by a third party. <a href="https://www.icpsr.umich.edu/web/pages/ICPSR/access/restricted/">ICPSR</a> is one such entity, and there are not many others. A grander scenario are industry-specific restricted-access data centers, such as <a href="http://www.privatecapitalresearchinstitute.org/research.php">PCRI</a>, where access is possible, and the identity of (multiple) data providers is hidden.</p>

<p>The key, however, is the willingness of the data provider to participate. The AEA can mediate and provide guidance to such arrangements, and I am happy to consult with any researcher who wants to go down that path, but will not, in general, become data custodian itself.</p>

<h2 id="data-citations---how-to-do-it">Data citations - how to do it</h2>

<blockquote>
  <p><a href="https://twitter.com/ElizWebHand/status/1347602931210739718">Elizabeth Weber Handwerker</a> I’m trying to create a bibtex entry for a dataset (the journal says to “reference datasets” and can’t find any examples of how to do this.</p>
</blockquote>

<p>Try these examples:</p>

<ul>
  <li><a href="https://zotero.org/groups/2245704/fsrdc">https://zotero.org/groups/2245704/fsrdc</a>, <a href="https://github.com/ncrncornell/cms-to-bib/blob/master/cms.bib">https://github.com/ncrncornell/cms-to-bib/blob/master/cms.bib</a> for confidential data,</li>
  <li><a href="https://github.com/larsvilhuber/MobZ/blob/master/data.bib">https://github.com/larsvilhuber/MobZ/blob/master/data.bib</a> for a variety of different data.</li>
</ul>

<p>Standard AEA bib style does not show URLs properly, use <a href="https://github.com/AEADataEditor/aea-de-guidance/blob/master/citations/aea-mod.bst">https://github.com/AEADataEditor/aea-de-guidance/blob/master/citations/aea-mod.bst</a> or the “econ” style. The quick solution: use @techreport
{} in a Bibtex file. <a href="https://doi.org/10.5281/zenodo.4073995">doi.org/10.5281/zenodo.4073995</a>, starting around pg. 37, discusses the basic ideas. Short take-away: It’s simple. (and @techreport or @misc
 has all the necessary fields).</p>

<p>Some examples:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@techreport{bea_table30_2019,
  title = {Table 30:  {Economic Profile}  by  {County} , 1969-2018},
  author = { {Bureau of Economic Analysis} },
  year = {2019},
  institution = { {U.S. Department of Commerce  [producer]} },
  url = {https://apps.bea.gov/regional/zip/CAINC30.zip},
  timestamp = {2020-09-08T00:42:24Z},
  type = {[Datafile]}
}

@misc{BLS_QCEW_2020,
  title = {Quarterly {Census} of {Employment} and {Wages} -- {Data Files} },
  shorttitle = { {QCEW Data Files} },
  author = { {Bureau of Labor Statistics} },
  year = {2020},
  publisher = { {Department of Labor [distributor]} },
  url = {https://www.bls.gov/cew/downloadable-data-files.htm},
  urldate = {2020-09-20},
  abstract = {Quarterly Census of Employment and Wages -- Data Files},
  language = {en},
  number = {1990-2019},
  timestamp = {2020-09-20T19:26:12Z},
  type = {[Datafiles]}
}
</code></pre></div></div>

<h2 id="how-to-bring-solved-problems-to-the-next-generation">How to bring solved problems to the next generation?</h2>

<blockquote>
  <p><a href="https://twitter.com/johnjhorton/status/1346262118904029184">John Horton</a> Many of the code &amp; data problems are essentially solved software engineering problems (version control, makefiles, unit tests, etc) - how do we incorporate these practices into PhD education so next generation is better than us?</p>
</blockquote>

<p>Good question… Efforts at <a href="https://bitss.github.io/ACRE/">BITSS</a>, <a href="https://carpentries.org/">Carpentries</a>, various data-science oriented classes, <a href="https://labordynamicsinstitute.github.io/computing4economists/web/#/">my own efforts at Cornell</a> only scratch the surface. They train a minority of volunteering students. I would actually argue that these best practices should be taught at the undergraduate level, and should be a compulsory part of graduate education the same way we require math proficiency. But we are a long way off of that.</p>

<h2 id="time-capsules-and-other-data-access-options">Time capsules and other data access options</h2>

<blockquote>
  <p><a href="https://twitter.com/johnjhorton/status/1346263273432354816">John Horton</a> Could AEA help credibly create “time capsule” data agreements where it will release a public dataset X years in the future? Some companies are willing to share data but not until it has lost its competitive value. A long lived institution like AEA is well positioned for this.</p>
</blockquote>

<p>Answer coming soon.</p>

<h2 id="accessing-data">Accessing data</h2>

<blockquote>
  <p><a href="https://twitter.com/conlon_chris/status/1346473098518773760">Chris Conlon</a> Several boilerplate data agreements that meet AEA requirements?</p>
</blockquote>

<blockquote>
  <p><a href="https://twitter.com/conlon_chris/status/1346474319283593218">Chris Conlon</a> negotiate terms with some of the commonly used data ACADEMIC data providers (WRDS? Kilts?).</p>
</blockquote>

<p>Ongoing (<a href="https://marketingdata.chicagobooth.edu/Anonymous/Welcome">Kilts</a>, <a href="https://www.diw.de/en/diw_02.c.238223.en/soep_conditions.html#614607">German SOEP</a>, <a href="https://fdz.iab.de/en/FDZ_Data_Access/FDZ_Scientific_Use_Files.aspx">German Scientific Use Files</a>). Repeatedly requesting (<a href="https://dhsprogram.com/data/">DHS</a>, <a href="https://www.afrobarometer.org/">Afrobarometer</a>) One issue is that data providers tend to have project-specific permissions, and none have a blanket approval for replicators at academic journals (not just AEA).</p>

<p>Typical answer: “We have not had a request like yours. I will need to speak with the director and potentially [data provider/counsel/lawyers].”</p>

<h2 id="gazillion-files">Gazillion files</h2>

<blockquote>
  <p>(via email) We have 26,000 files in our deposit. How should we proceed (openICPSR only handles up to 1,000 files)?</p>
</blockquote>

<p>We get this question regularly. There are multiple partial answers:</p>

<ul>
  <li>When the data provider has assigned a DOI, no need to provide the data. An example is the TERRA/MODIS climate data is such an example, see <a href="https://dx.doi.org/10.5067/MODIS/MOD08_M3.061">https://dx.doi.org/10.5067/MODIS/MOD08_M3.061</a>.</li>
  <li>If the data provider has not assigned a DOI, we encourage authors to ask their data provider to do so. This is the right approach… but it is unlikely to yield a result prior to publication. Fallback solutions below.</li>
  <li>If you have the interest and time to provide a public good, deposit the data separately, thus creating a DOI. While the AEA uses openICPSR to handle its replication packages, you can deposit the pure data deposit anywhere. A good option (as of January 2021) is <a href="https://zenodo.org">Zenodo</a>, which has an excellent API allowing to download metadata and large quantities of files. You would describe the data, and publish a deposit, thus creating a DOI. No need to then provide the data as part of the AEA Replication package - just cite it. Bonus: use the API to read-in the data for your own research.</li>
  <li>If all else fails, it is acceptable to ZIP up files by sub-directory (e.g., “zip -rp weather_CPCG.zip weather_CPCG/*” and then describe, as part of setup/processing, how and where to unzip the files. Caution: ZIP files on different platforms include addtional directory levels sometimes, so be precise about the directory structure you want. Also, the default Windows and Linux zip utilities can only handle ZIP archives up to 2GB, whereas modern macOS archives can handle larger ZIP packages. We suggest using 7zip, which is free and cross-platform.</li>
</ul>

<h2 id="verifying-papers-with-restricted-access-data">Verifying papers with restricted-access data</h2>

<blockquote>
  <p>(via email) It would be great to know more about best practice for papers based on administrative data that cannot be made available publicly. What are the AEAs recommendations – is there a planned “standard way” of doing things in this case? One way would be to require an independent review of national colleagues (eg in DK) to review the code and provide comments/run the analyses on their/similar data.</p>
</blockquote>

<p>Longish answer coming in the Fireside Chat. Short answer: we already do this on a regular basis (successful in the past year: Washington State data, Wisconsin state data, French customs data, Brazilian firm and worker admin data (3x), Swedish register data (2x), IRS tax data (2x), etc.) in more or less the way you describe it. That being said, we do not yet have a mechanism on soliciting / finding replicators - but are working on that. For now, that mechanism is called “my memory” and a database of data citations.</p>

<blockquote>
  <p><a href="https://twitter.com/ElizWebHand/status/1346258970827218946">Elizabeth Weber Handwerker</a> I’m a government economist, working with some data outside researchers can access only through an application process, and some data they can’t access at all (Massachusetts QCEW, etc.). What do AEA requirements for data &amp; code look like in each case?</p>
</blockquote>

<p>Answer coming live during Fireside Chat. Short answer: The same.</p>

<p>See talk at the <a href="https://doi.org/10.5281/zenodo.4250890">University of Waterloo / Canadian Research Data Center</a>. I have also had talks with Census Bureau folks, and have ongoing private and public talks with institutions that have access to restricted-data.</p>

<h2 id="replicability-and-reproducibility-in-institutions">Replicability and Reproducibility in Institutions</h2>

<blockquote>
  <p><a href="https://twitter.com/fibbyccino/status/1346262249854275585">@fibbyccino</a> What would you recommend to an organisation looking to introduce internal replicability standards for code and data for the first time?</p>
</blockquote>

<p>Requires a longish answer (live), but is something I have been talking to various organizations about, see slides for my talk at <a href="https://doi.org/10.5281/zenodo.4311917">Brookings</a> and <a href="https://doi.org/10.5281/zenodo.4281633">St. Louis Fed</a> (also <a href="https://research.stlouisfed.org/conferences/beyond-the-numbers/">video</a>.</p>]]></content><author><name>AEA Data Editor</name></author><category term="FAQ" /><category term="Twitter" /><category term="Fireside Chat" /><summary type="html"><![CDATA[In this post, I’ll pick up questions that have been asked over Twitter or during the 2021-01-19 Fireside chat, in long form (Twitter is not always the best medium). Over time, you might see some of these questions and answers be migrated to FAQ and/or best practices documents.]]></summary></entry><entry><title type="html">A discussion about various things</title><link href="https://aeadataeditor.github.io/posts/2021-01-05-answers-to-questions" rel="alternate" type="text/html" title="A discussion about various things" /><published>2021-01-05T00:00:00-05:00</published><updated>2021-01-05T00:00:00-05:00</updated><id>https://aeadataeditor.github.io/posts/Answers-to-questions</id><content type="html" xml:base="https://aeadataeditor.github.io/posts/2021-01-05-answers-to-questions"><![CDATA[<p>Moved to later post.</p>]]></content><author><name>AEA Data Editor</name></author><summary type="html"><![CDATA[Moved to later post.]]></summary></entry></feed>